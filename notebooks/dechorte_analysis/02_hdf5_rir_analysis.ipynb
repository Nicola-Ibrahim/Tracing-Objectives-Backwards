{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1804954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b835c2f",
   "metadata": {},
   "source": [
    "# 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df76bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) User config (EDIT THESE)\n",
    "METADATA_PATH = Path(\"../../data/dEchorate/raw/dEchorate_database.csv\")\n",
    "PROCESSED_METADATA_PATH = Path(\"../../data/dEchorate/processed/dEchorate_database_cleaned.csv\")\n",
    "\n",
    "# Shared settings used by the HDF5 notebook cache\n",
    "H5_PATH = Path(\"../../data/dEchorate/raw/dEchorate_rirs_gzip7.hdf5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66003a33",
   "metadata": {},
   "source": [
    "# 2) Read metadata and Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0171412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cleaned metadata from ../../data/dEchorate/processed/dEchorate_database_cleaned.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "room_code",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "src_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "src_signal",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mic_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mic_pos_x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mic_pos_y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mic_pos_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_west",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_east",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_north",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_south",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_ceiling",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "room_rfl_floor",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9245c492-12c2-4f43-aa74-ba42fe37f997",
       "rows": [
        [
         "0",
         "0.0",
         "0.0",
         "chirp",
         "0.0",
         "0.8031609",
         "3.8314145",
         "1.0439153",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "0.0",
         "2.0",
         "chirp",
         "0.0",
         "0.8031609",
         "3.8314145",
         "1.0439153",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "1.0",
         "0.0",
         "chirp",
         "0.0",
         "0.8031609",
         "3.8314145",
         "1.0439153",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "0.0",
         "1.0",
         "chirp",
         "0.0",
         "0.8031609",
         "3.8314145",
         "1.0439153",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "1.0",
         "2.0",
         "chirp",
         "0.0",
         "0.8031609",
         "3.8314145",
         "1.0439153",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_code</th>\n",
       "      <th>src_id</th>\n",
       "      <th>src_signal</th>\n",
       "      <th>mic_id</th>\n",
       "      <th>mic_pos_x</th>\n",
       "      <th>mic_pos_y</th>\n",
       "      <th>mic_pos_z</th>\n",
       "      <th>room_rfl_west</th>\n",
       "      <th>room_rfl_east</th>\n",
       "      <th>room_rfl_north</th>\n",
       "      <th>room_rfl_south</th>\n",
       "      <th>room_rfl_ceiling</th>\n",
       "      <th>room_rfl_floor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chirp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>3.831415</td>\n",
       "      <td>1.043915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>chirp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>3.831415</td>\n",
       "      <td>1.043915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chirp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>3.831415</td>\n",
       "      <td>1.043915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chirp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>3.831415</td>\n",
       "      <td>1.043915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>chirp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803161</td>\n",
       "      <td>3.831415</td>\n",
       "      <td>1.043915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   room_code  src_id src_signal  mic_id  mic_pos_x  mic_pos_y  mic_pos_z  \\\n",
       "0        0.0     0.0      chirp     0.0   0.803161   3.831415   1.043915   \n",
       "1        0.0     2.0      chirp     0.0   0.803161   3.831415   1.043915   \n",
       "2        1.0     0.0      chirp     0.0   0.803161   3.831415   1.043915   \n",
       "3        0.0     1.0      chirp     0.0   0.803161   3.831415   1.043915   \n",
       "4        1.0     2.0      chirp     0.0   0.803161   3.831415   1.043915   \n",
       "\n",
       "   room_rfl_west  room_rfl_east  room_rfl_north  room_rfl_south  \\\n",
       "0            0.0            0.0             0.0             0.0   \n",
       "1            0.0            0.0             0.0             0.0   \n",
       "2            0.0            0.0             1.0             0.0   \n",
       "3            0.0            0.0             0.0             0.0   \n",
       "4            0.0            0.0             1.0             0.0   \n",
       "\n",
       "   room_rfl_ceiling  room_rfl_floor  \n",
       "0               0.0             0.0  \n",
       "1               0.0             0.0  \n",
       "2               0.0             0.0  \n",
       "3               0.0             0.0  \n",
       "4               0.0             0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(PROCESSED_METADATA_PATH)\n",
    "print(f\"Loaded cleaned metadata from {PROCESSED_METADATA_PATH}\")\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a63d2",
   "metadata": {},
   "source": [
    "## Metadata selection\n",
    "Select room/source/signal and build mic indices + positions for HDF5 lookup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42d963",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Missing required variables: mic_indices, use_positions, X_design, ROOM_CODE, SRC_ID, SIGNAL_NAME. Run `notebooks/dechorte_analysis/01_metadata_csv_analysis.ipynb` and optionally save a cache: np.savez('dechorate_metadata_cache.npz', ...).\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m missing = [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m required \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMissing required variables: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(missing)\n\u001b[32m     28\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m. Run `notebooks/dechorte_analysis/01_metadata_csv_analysis.ipynb` and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33moptionally save a cache: np.savez(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdechorate_metadata_cache.npz\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, ...).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m     )\n",
      "\u001b[31mKeyError\u001b[39m: \"Missing required variables: mic_indices, use_positions, X_design, ROOM_CODE, SRC_ID, SIGNAL_NAME. Run `notebooks/dechorte_analysis/01_metadata_csv_analysis.ipynb` and optionally save a cache: np.savez('dechorate_metadata_cache.npz', ...).\""
     ]
    }
   ],
   "source": [
    "# 3) Metadata selection + design matrix\n",
    "T0 = 4096\n",
    "\n",
    "# mic-position normalization constants (approx room size used in dEchorate)\n",
    "ROOM_DIMS = np.array([6.0, 6.0, 2.4], dtype=np.float32)\n",
    "ID_BASE_OFFSET = 0  # typical is 0, but some datasets use 1\n",
    "\n",
    "# Select a single room/src/signal for extraction\n",
    "ROOM_CODE = 0\n",
    "SRC_ID = 0\n",
    "SIGNAL_NAME = \"chirp\"\n",
    "\n",
    "required_cols = [\n",
    "    \"room_code\",\n",
    "    \"src_id\",\n",
    "    \"src_signal\",\n",
    "    \"mic_id\",\n",
    "    \"mic_pos_x\",\n",
    "    \"mic_pos_y\",\n",
    "    \"mic_pos_z\",\n",
    "]\n",
    "missing = [c for c in required_cols if c not in metadata_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "subset_df = metadata_df.query(\n",
    "    \"room_code == @ROOM_CODE and src_id == @SRC_ID and \"\n",
    "    \"src_signal.str.lower() == @SIGNAL_NAME.lower()\"\n",
    ").copy()\n",
    "\n",
    "mic_meta = (\n",
    "    subset_df.dropna(subset=[\"mic_id\", \"mic_pos_x\", \"mic_pos_y\", \"mic_pos_z\"])\n",
    "    .drop_duplicates(subset=[\"mic_id\"])\n",
    "    .sort_values(\"mic_id\")\n",
    ")\n",
    "\n",
    "mic_indices = mic_meta[\"mic_id\"].astype(int).to_numpy()\n",
    "use_positions = True\n",
    "X_design = (\n",
    "    mic_meta[[\"mic_pos_x\", \"mic_pos_y\", \"mic_pos_z\"]].to_numpy().astype(np.float32)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Filtered rows: {len(subset_df)} | mics: {len(mic_indices)} | \"\n",
    "    f\"ROOM_CODE={ROOM_CODE} SRC_ID={SRC_ID} SIGNAL_NAME={SIGNAL_NAME}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ca61d",
   "metadata": {},
   "source": [
    "## Explore HDF5 contents\n",
    "List dataset candidates and infer axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Quick HDF5 overview (datasets + shapes)\n",
    "with h5py.File(H5_PATH, \"r\") as f:\n",
    "    print(f\"Top-level keys: {list(f.keys())}\")\n",
    "    datasets = []\n",
    "\n",
    "    def _collect(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            datasets.append({\"path\": name, \"shape\": obj.shape, \"dtype\": str(obj.dtype)})\n",
    "\n",
    "    f.visititems(_collect)\n",
    "    if datasets:\n",
    "        ds_df = pd.DataFrame(datasets).sort_values(\"path\")\n",
    "        print(f\"Found {len(ds_df)} datasets\")\n",
    "        print(ds_df.head(20).to_string(index=False))\n",
    "        first_path = ds_df.iloc[0][\"path\"]\n",
    "        sample_ds = f[first_path]\n",
    "        sample = sample_ds[tuple(slice(0, 1) for _ in range(sample_ds.ndim))]\n",
    "        print(f\"Sample from {first_path}: shape={sample.shape}\")\n",
    "    else:\n",
    "        print(\"No datasets found in HDF5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076e3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) HDF5: inspect keys, find RIR dataset, infer axis order\n",
    "def list_h5_tree(h5obj, prefix=\"\"):\n",
    "    \"\"\"Recursively list groups/datasets (short).\"\"\"\n",
    "    for k in h5obj.keys():\n",
    "        item = h5obj[k]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"H5 dataset: {prefix}{k} shape={item.shape} dtype={item.dtype}\")\n",
    "        else:\n",
    "            print(f\"H5 group:   {prefix}{k}/\")\n",
    "            list_h5_tree(item, prefix=prefix + k + \"/\")\n",
    "\n",
    "\n",
    "def find_candidate_rir_datasets(h5obj):\n",
    "    \"\"\"Return list of dataset paths that look like RIR tensors (>=3 dims).\"\"\"\n",
    "    cands = []\n",
    "\n",
    "    def _walk(obj, path=\"\"):\n",
    "        for k in obj.keys():\n",
    "            item = obj[k]\n",
    "            p = f\"{path}/{k}\" if path else k\n",
    "            if isinstance(item, h5py.Dataset):\n",
    "                name = k.lower()\n",
    "                if (\"rir\" in name or \"rirs\" in name or \"ir\" == name) and item.ndim >= 3:\n",
    "                    cands.append(p)\n",
    "            else:\n",
    "                _walk(item, p)\n",
    "\n",
    "    _walk(h5obj)\n",
    "    return cands\n",
    "\n",
    "\n",
    "def infer_axes(shape, expected_mics=(30,), expected_srcs=(6,), expected_rooms=(11,)):\n",
    "    \"\"\"\n",
    "    Heuristic inference: identify axes by dimension sizes.\n",
    "    Returns dict with keys: time, mic, src, room\n",
    "    \"\"\"\n",
    "    shape = list(shape)\n",
    "    # time axis = largest dimension (RIR length)\n",
    "    time_ax = int(np.argmax(shape))\n",
    "\n",
    "    remaining = [i for i in range(len(shape)) if i != time_ax]\n",
    "\n",
    "    # helper: pick axis whose size matches any of expected sizes\n",
    "    def pick_axis(expected_sizes):\n",
    "        for i in remaining:\n",
    "            if shape[i] in expected_sizes:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    mic_ax = pick_axis(expected_mics)\n",
    "    if mic_ax is not None:\n",
    "        remaining.remove(mic_ax)\n",
    "\n",
    "    src_ax = pick_axis(expected_srcs)\n",
    "    if src_ax is not None:\n",
    "        remaining.remove(src_ax)\n",
    "\n",
    "    room_ax = pick_axis(expected_rooms)\n",
    "    if room_ax is not None:\n",
    "        remaining.remove(room_ax)\n",
    "\n",
    "    return {\"time\": time_ax, \"mic\": mic_ax, \"src\": src_ax, \"room\": room_ax}\n",
    "\n",
    "\n",
    "def extract_rir_segment(rirs_ds, axes, room_idx, src_idx, mic_idx, T0):\n",
    "    \"\"\"Slice a single RIR and return first T0 samples as 1D float32.\"\"\"\n",
    "    sl = [slice(None)] * rirs_ds.ndim\n",
    "    if axes[\"room\"] is not None:\n",
    "        sl[axes[\"room\"]] = int(room_idx)\n",
    "    if axes[\"src\"] is not None:\n",
    "        sl[axes[\"src\"]] = int(src_idx)\n",
    "    if axes[\"mic\"] is not None:\n",
    "        sl[axes[\"mic\"]] = int(mic_idx)\n",
    "\n",
    "    x = rirs_ds[tuple(sl)]\n",
    "    # Move time axis to front, flatten any leftovers\n",
    "    x = np.moveaxis(x, axes[\"time\"], 0)\n",
    "    x = np.asarray(x).reshape(x.shape[0], -1)\n",
    "    x = x[:, 0]  # pick first if extra singleton dims remain\n",
    "    x = x[:T0].astype(np.float32, copy=False)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d626c3a",
   "metadata": {},
   "source": [
    "## Load HDF5 and extract early RIRs\n",
    "Pick a dataset, infer axes, and build `Y_echo` for all mics in the subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737e1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened HDF5: dEchorate_rirs_gzip7.hdf5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to get group info (addr overflow, addr = 2536, size = 328, eoa = 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOpened HDF5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH5_PATH.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# optional: uncomment if you want a full tree log\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# list_h5_tree(f)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m candidates = \u001b[43mfind_candidate_rir_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# fallback: list top-level to help debugging\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo obvious RIR datasets found (by name). Top-level keys are:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mfind_candidate_rir_datasets\u001b[39m\u001b[34m(h5obj)\u001b[39m\n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     26\u001b[39m             _walk(item, p)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43m_walk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cands\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mfind_candidate_rir_datasets.<locals>._walk\u001b[39m\u001b[34m(obj, path)\u001b[39m\n\u001b[32m     24\u001b[39m         cands.append(p)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43m_walk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mfind_candidate_rir_datasets.<locals>._walk\u001b[39m\u001b[34m(obj, path)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_walk\u001b[39m(obj, path=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen _collections_abc>:869\u001b[39m, in \u001b[36m__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization/.venv/lib/python3.12/site-packages/h5py/_hl/group.py:509\u001b[39m, in \u001b[36mGroup.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    508\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Iterate over member names \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    510\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._d(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5g.pyx:476\u001b[39m, in \u001b[36mh5py.h5g.GroupID.__iter__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5g.pyx:477\u001b[39m, in \u001b[36mh5py.h5g.GroupID.__iter__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5g.pyx:109\u001b[39m, in \u001b[36mh5py.h5g.GroupIter.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5g.pyx:343\u001b[39m, in \u001b[36mh5py.h5g.GroupID.get_num_objs\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to get group info (addr overflow, addr = 2536, size = 328, eoa = 2048)"
     ]
    }
   ],
   "source": [
    "# 4) Open HDF5, find RIR dataset, infer axes\n",
    "with h5py.File(H5_PATH, \"r\") as f:\n",
    "    print(f\"Opened HDF5: {H5_PATH.name}\")\n",
    "    # optional: uncomment if you want a full tree log\n",
    "    # list_h5_tree(f)\n",
    "\n",
    "    candidates = find_candidate_rir_datasets(f)\n",
    "    if not candidates:\n",
    "        # fallback: list top-level to help debugging\n",
    "        print(\"No obvious RIR datasets found (by name). Top-level keys are:\")\n",
    "        print(list(f.keys()))\n",
    "        raise KeyError(\n",
    "            \"Could not auto-detect RIR dataset. Inspect keys and set it manually.\"\n",
    "        )\n",
    "\n",
    "    print(\"Candidate RIR datasets:\")\n",
    "    for p in candidates:\n",
    "        ds = f[p]\n",
    "        print(f\"  - {p} shape={ds.shape} dtype={ds.dtype}\")\n",
    "\n",
    "    # Choose the first candidate by default\n",
    "    RIR_PATH = candidates[0]\n",
    "    rirs_ds = f[RIR_PATH]\n",
    "    print(f\"Selected RIR dataset: {RIR_PATH} | shape={rirs_ds.shape}\")\n",
    "\n",
    "    axes = infer_axes(\n",
    "        rirs_ds.shape, expected_mics=(30,), expected_srcs=(6,), expected_rooms=(11,)\n",
    "    )\n",
    "    print(f\"Inferred axes: {axes} (None means 'not detected')\")\n",
    "\n",
    "    # If src/room axes weren't detected, we can still try slicing by assuming axis order,\n",
    "    # but simplest is to print shape and set axes manually.\n",
    "    if axes[\"mic\"] is None or axes[\"src\"] is None or axes[\"room\"] is None:\n",
    "        print(\"Could not infer all axes reliably.\")\n",
    "        print(\"Print rirs_ds.shape and set axes manually if needed.\")\n",
    "        print(f\"rirs_ds.shape={rirs_ds.shape}\")\n",
    "\n",
    "    # 5) Extract Y_echo: early RIR segments for each mic\n",
    "    room_idx = ROOM_CODE - ID_BASE_OFFSET\n",
    "    src_idx = SRC_ID - ID_BASE_OFFSET\n",
    "\n",
    "    Y_list = []\n",
    "    for m in mic_indices:\n",
    "        seg = extract_rir_segment(\n",
    "            rirs_ds, axes, room_idx=room_idx, src_idx=src_idx, mic_idx=m, T0=T0\n",
    "        )\n",
    "        Y_list.append(seg)\n",
    "\n",
    "    Y_echo = np.stack(Y_list, axis=0)  # (N, T0)\n",
    "    print(f\"Extracted Y_echo (raw) | shape={Y_echo.shape} dtype={Y_echo.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d7572",
   "metadata": {},
   "source": [
    "## Inspect raw RIRs\n",
    "Quick waveform plots and basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting a few raw RIR segments...\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(min(5, Y_echo.shape[0])):\n",
    "    plt.plot(Y_echo[i], alpha=0.8)\n",
    "plt.title(\"Raw RIR segments (first few mics)\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Y_echo summary:\")\n",
    "print(f\"  shape: {Y_echo.shape}\")\n",
    "print(f\"  min/max: {Y_echo.min():.4g} / {Y_echo.max():.4g}\")\n",
    "print(f\"  mean/std: {Y_echo.mean():.4g} / {Y_echo.std():.4g}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5895cd5",
   "metadata": {},
   "source": [
    "## Normalize Y and X\n",
    "Normalize the RIR segments and the microphone design matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024220ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Normalization (simple, consistent)\n",
    "# 6.1 Normalize Y_echo (waveform features)\n",
    "# - remove per-sample DC offset per RIR segment\n",
    "Y_echo = Y_echo - Y_echo.mean(axis=1, keepdims=True)\n",
    "\n",
    "# - global standardization across the entire subset (recommended)\n",
    "mu = float(Y_echo.mean())\n",
    "sigma = float(Y_echo.std() + 1e-8)\n",
    "Y_echo_norm = (Y_echo - mu) / sigma\n",
    "\n",
    "# optional clipping for stability\n",
    "Y_echo_norm = np.clip(Y_echo_norm, -5.0, 5.0).astype(np.float32)\n",
    "\n",
    "print(f\"Y_echo normalization: mu={mu:.6g}, sigma={sigma:.6g}\")\n",
    "print(\n",
    "    \"Y_echo_norm stats: mean=%.4f, std=%.4f\" % (Y_echo_norm.mean(), Y_echo_norm.std())\n",
    ")\n",
    "\n",
    "# 6.2 Normalize X_design\n",
    "if use_positions:\n",
    "    X_design = X_design.astype(np.float32)\n",
    "    # simple room-dimension scaling\n",
    "    X_design_norm = X_design / ROOM_DIMS.reshape(1, 3)\n",
    "    print(f\"X_design_norm (positions/ROOM_DIMS) | shape={X_design_norm.shape}\")\n",
    "else:\n",
    "    # discrete labels\n",
    "    X_design_norm = X_design\n",
    "    print(\"X_design is discrete mic indices; no normalization applied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bd14f",
   "metadata": {},
   "source": [
    "## Inspect mic positions\n",
    "Ranges and a 3D scatter when positions are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_positions:\n",
    "    print(\"Mic position ranges (meters):\")\n",
    "    print(f\"  x: [{X_design[:,0].min():.3f}, {X_design[:,0].max():.3f}]\")\n",
    "    print(f\"  y: [{X_design[:,1].min():.3f}, {X_design[:,1].max():.3f}]\")\n",
    "    print(f\"  z: [{X_design[:,2].min():.3f}, {X_design[:,2].max():.3f}]\")\n",
    "\n",
    "    # simple 3D scatter (matplotlib default colors)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(X_design[:, 0], X_design[:, 1], X_design[:, 2], s=30)\n",
    "    ax.set_title(\"Mic positions (meters) for the selected room+source\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No mic positions available; using discrete mic indices.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e196d",
   "metadata": {},
   "source": [
    "## Final tensors\n",
    "Ready to train inverse models. Optionally save to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e144372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"READY FOR TRAINING:\")\n",
    "print(f\"  Inverse input  (Y_echo_norm): {Y_echo_norm.shape}\")\n",
    "print(f\"  Inverse output (X_design_norm): {np.shape(X_design_norm)}\")\n",
    "\n",
    "# Optional: save for reuse\n",
    "# np.save(\"Y_echo_norm.npy\", Y_echo_norm)\n",
    "# np.save(\"X_design_norm.npy\", X_design_norm)\n",
    "# print(\"Saved: Y_echo_norm.npy, X_design_norm.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pareto-Optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
