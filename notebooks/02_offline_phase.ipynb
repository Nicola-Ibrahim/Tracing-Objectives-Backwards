{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "BMotfZgYgP9h",
      "metadata": {
        "id": "BMotfZgYgP9h"
      },
      "source": [
        "# Autoencoder Formulation for Pareto Front Analysis\n",
        "\n",
        "Some of considerd limitations:\n",
        "1. Defining the optimal point (energy/time -> acceleration) at the beginning of the system. The user has the ability to select that.\n",
        "\n",
        "2. All data features should be taken into account, e.g. (Decision variables + problem parameters + objectives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "nqxWtmAw9qmU",
      "metadata": {
        "id": "nqxWtmAw9qmU"
      },
      "outputs": [],
      "source": [
        "# === Standard Library ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === PyTorch Core ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "# import torch.distributions\n",
        "\n",
        "# === PyTorch Utils / Vision ===\n",
        "# import torchvision\n",
        "\n",
        "# === Other Libraries ===\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# === Configuration ===\n",
        "torch.manual_seed(0)\n",
        "plt.rcParams[\"figure.dpi\"] = 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hr8T5ZsM-nCz",
      "metadata": {
        "id": "Hr8T5ZsM-nCz"
      },
      "source": [
        "## Date reading\n",
        "\n",
        "**Input Data Structure**:\n",
        "- Let $X = \\{\\mathbf{x}_i\\}_{i=1}^N \\subset \\mathbb{R}^2$ be the set of Pareto-optimal solutions\n",
        "- Each solution $\\mathbf{x}_i = (f_1^{(i)}, f_2^{(i)}, ...,f_n^{(i)})$ represents a trade-off between:\n",
        "  - $f_1$: Travel time (minutes)\n",
        "  - $f_2$: Energy consumption (kWh)\n",
        "  - $f_n$: Other data variables\n",
        "\n",
        "Then, filter out the needed data for trainig purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Tp5dTiMflpDK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp5dTiMflpDK",
        "outputId": "7b9f3029-a08e-46b1-bdd2-53691060e227"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './pareto_data.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pareto_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./pareto_data.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(pareto_data)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m4    4    9\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m excs_to_catch = (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './pareto_data.pkl'"
          ]
        }
      ],
      "source": [
        "pareto_data = pd.read_pickle(\"./pareto_data.pkl\")\n",
        "print(pareto_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T7CaJUAe4drS",
      "metadata": {
        "id": "T7CaJUAe4drS"
      },
      "source": [
        "\n",
        "## Data preparation\n",
        "**Normalization**: Scale objectives to $[0,1]$ range for training stability:\n",
        "$$\n",
        "\\hat{f}_k = \\frac{f_k - f_{k}^{min}}{f_{k}^{max} - f_{k}^{min}}, \\quad \\text{for } k=1,2\n",
        "$$\n",
        "\n",
        "**Standardization**:\n",
        "$$\n",
        "\\hat{f}_k^{(i)} = \\frac{f_k^{(i)} - \\mu_k}{\\sigma_k}, \\quad \\text{for } k=1,2\n",
        "$$\n",
        "where $\\mu_k$, $\\sigma_k$ are the mean and standard deviation of each objective.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V56ab8Tlmy0J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "V56ab8Tlmy0J",
        "outputId": "83e1e13d-1cf5-4817-cb4b-3c57618ced9e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pareto_data\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"travel_time_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.14105031360019,\n        \"min\": 40.83670245156898,\n        \"max\": 111.7468558366941,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          111.7468558366941,\n          40.83670245156898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_consumption_kWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07722695119362646,\n        \"min\": 0.11146828110982653,\n        \"max\": 0.22068368286857815,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.22068368286857815,\n          0.11146828110982653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-54dc8d04-bbb4-4347-9860-8e31904aeb23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>travel_time_min</th>\n",
              "      <th>energy_consumption_kWh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.836702</td>\n",
              "      <td>0.111468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>111.746856</td>\n",
              "      <td>0.220684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54dc8d04-bbb4-4347-9860-8e31904aeb23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54dc8d04-bbb4-4347-9860-8e31904aeb23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54dc8d04-bbb4-4347-9860-8e31904aeb23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-93ea0aee-1c5a-473f-8223-d0207608aa83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93ea0aee-1c5a-473f-8223-d0207608aa83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-93ea0aee-1c5a-473f-8223-d0207608aa83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     travel_time_min  energy_consumption_kWh\n",
              "min        40.836702                0.111468\n",
              "max       111.746856                0.220684"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if the the data need to be normalized\n",
        "pareto_data.aggregate(\n",
        "    {\"travel_time_min\": [\"min\", \"max\"], \"energy_consumption_kWh\": [\"min\", \"max\"]}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc9ba7a8",
      "metadata": {
        "id": "bc9ba7a8"
      },
      "outputs": [],
      "source": [
        "# Normalize to [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(\n",
        "    pareto_data[[\"travel_time_min\", \"energy_consumption_kWh\"]]\n",
        ")\n",
        "\n",
        "# Split data (80% train, 20% validation)\n",
        "X_train, X_val = train_test_split(X_normalized, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HGrqXafj-W1n",
      "metadata": {
        "id": "HGrqXafj-W1n"
      },
      "source": [
        "## Conditional VAE Architecture\n",
        "\n",
        "### Why to use?\n",
        "In traditional autoencoders, inputs are mapped deterministically to a latent vector\n",
        "$z=e(x)$. In variational autoencoders, inputs are mapped to a probability distribution over latent vectors, and a latent vector is then sampled from that distribution. The decoder becomes more robust at decoding latent vectors as a result.\n",
        "\n",
        "### Variational Autoencoder (VAE) Latent Space Mapping\n",
        "\n",
        "                     Input Conditions\n",
        "                      (SOC, Distance,\n",
        "                      Velocity Profile)\n",
        "                           │\n",
        "                           ▼\n",
        "                ┌───────────────────────┐\n",
        "                │      Conditioner      │\n",
        "                │  (MLP Transformer)    │\n",
        "                └───────────────────────┘\n",
        "                           │\n",
        "                           ├──────────────────────┐\n",
        "                           ▼                      ▼\n",
        "                ┌───────────────────────┐ ┌───────────────────────┐\n",
        "                │       Encoder         │ │      Decoder          │\n",
        "                │  (q(z|x,c))           │ │  (p(x|z,c))           │\n",
        "                └───────────────────────┘ └───────────────────────┘\n",
        "                           │                      ▲\n",
        "                           └───────► z ◄─────────┘\n",
        "                                  Latent Space\n",
        "\n",
        "\n",
        "Instead of directly mapping the input **$ x $** to a latent vector **$ z = e(x) $**, we instead map it to:\n",
        "\n",
        "- **Mean vector**: **$ \\mu(x) $**\n",
        "- **Standard deviation vector**: **$ \\sigma(x) $**\n",
        "\n",
        "These parameters define a **diagonal Gaussian distribution** $ N(\\mu(x), \\sigma(x)) $, from which we sample the latent vector $ z $:\n",
        "\n",
        "$$\n",
        "z \\sim N(\\mu(x), \\sigma(x))\n",
        "$$\n",
        "\n",
        "This formulation allows the model to learn a probabilistic latent space representation where each input $ x $ defines its own distribution over latent codes rather than a single deterministic point.\n",
        "\n",
        "\n",
        "### 1. Problem Definition\n",
        "Let:\n",
        "- **x** ∈ ℝ² : Solution vector (time_min, energy_kwh)\n",
        "- **c** ∈ ℝ⁵ : Condition vector (SOC, distance_ratio, avg_velocity, max_accel, energy_variance)\n",
        "- **z** ∈ ℝᴸ : Latent representation (L=8)\n",
        "\n",
        "### 2. Probabilistic Model\n",
        "**Objective**: Learn conditional distribution \n",
        "$$p_\\theta(x|z,c) \\quad \\text{where} \\quad z \\sim q_\\phi(z|x,c)$$\n",
        "\n",
        "**Evidence Lower Bound (ELBO)**:\n",
        "$$\n",
        "\\mathcal{L}(\\theta,\\phi;x,c) = \\mathbb{E}_{q_\\phi(z|x,c)}[\\log p_\\theta(x|z,c)] - \\beta D_{KL}(q_\\phi(z|x,c) \\| p(z))\n",
        "$$\n",
        "\n",
        " \n",
        "### Encoder Network (Compression)\n",
        "$$\n",
        "\\mathbf{z} = g_\\phi(\\mathbf{x}) = \\text{LeakyReLU}(\\mathbf{W}_2 \\cdot \\text{ELU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "### Decoder Network (Reconstruction)\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = f_\\theta(\\mathbf{z}) = \\text{Sigmoid}(\\mathbf{W}_4 \\cdot \\text{ELU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "**Dimensionality**:\n",
        "- Input/Output: $\\mathbb{R}^2$ (normalized objectives)\n",
        "- Latent space: $\\mathbb{R}^1$ (bottleneck)\n",
        "- Hidden layers: 32 neurons with ELU activation\n",
        "\n",
        "\n",
        "## Architecture\n",
        "Sigmoid ensures outputs stay in normalized $[0,1]$ range\n",
        "\n",
        "### Encoder\n",
        "Maps 2D Pareto solutions to a 1D latent space:\n",
        "$$\n",
        "\\mathbf{z} = \\text{Encoder}(\\mathbf{x}) = \\sigma(\\mathbf{W}_2 \\cdot \\text{ReLU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\mathbf{W}_1 \\in \\mathbb{R}^{h \\times 2}$, $\\mathbf{W}_2 \\in \\mathbb{R}^{1 \\times h}$ are weight matrices\n",
        "- $\\mathbf{b}_1 \\in \\mathbb{R}^h$, $\\mathbf{b}_2 \\in \\mathbb{R}^1$ are bias terms\n",
        "- $h$ is hidden layer size\n",
        "- $\\sigma$ is sigmoid activation\n",
        "\n",
        "### Decoder\n",
        "Reconstructs solutions from latent space:\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = \\text{Decoder}(\\mathbf{z}) = \\sigma(\\mathbf{W}_4 \\cdot \\text{ReLU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "With:\n",
        "- $\\mathbf{W}_3 \\in \\mathbb{R}^{h \\times 1}$, $\\mathbf{W}_4 \\in \\mathbb{R}^{2 \\times h}$\n",
        "- $\\mathbf{b}_3 \\in \\mathbb{R}^h$, $\\mathbf{b}_4 \\in \\mathbb{R}^2$\n",
        "\n",
        "\n",
        "### Activation function\n",
        "\n",
        "### Loss Function\n",
        "Mean Squared Error (MSE) reconstruction loss:\n",
        "$$\n",
        "\\mathcal{L}_{recon} = \\frac{1}{N}\\sum_{i=1}^N \\|\\mathbf{x}_i - \\hat{\\mathbf{x}}_i\\|^2_2\n",
        "$$\n",
        "\n",
        "## 1. Composite Loss Components\n",
        "The total optimization objective combines three critical elements:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{total} = \\mathcal{L}_{recon} + \\beta\\mathcal{L}_{KL} + \\mathcal{L}_{phys}\n",
        "$$\n",
        "\n",
        "#### 1.1 Weighted Reconstruction Loss\n",
        "Domain-prioritized MSE accounting for operational criticality:\n",
        "$$\n",
        "\\mathcal{L}_{recon} = \\frac{1}{N}\\sum_{i=1}^N \\left[w_t\\left(\\frac{\\hat{t}_i - t_i}{t_{max}}\\right)^2 + w_e\\left(\\frac{\\hat{e}_i - e_i}{e_{max}}\\right)^2\\right]\n",
        "$$\n",
        "\n",
        "| Parameter | Value | Rationale |\n",
        "|-----------|-------|-----------|\n",
        "| $w_t$     | 0.7   | Time minimization priority |\n",
        "| $w_e$     | 0.3   | Energy conservation importance |\n",
        "| $t_{max}$ | 120 min | Maximum allowable trip time |\n",
        "| $e_{max}$ | 10 kWh | Battery capacity limit |\n",
        "\n",
        "#### 1.2 KL Divergence Regularization\n",
        "Gaussian constraint for latent space organization:\n",
        "$$\n",
        "\\mathcal{L}_{KL} = \\frac{1}{2}\\sum_{j=1}^8 \\left[\\exp(\\log\\sigma_j^2) + \\mu_j^2 - 1 - \\log\\sigma_j^2\\right]\n",
        "$$\n",
        "\n",
        "#### 1.3 Physics-Informed Penalty\n",
        "Hard constraint enforcement through soft penalties:\n",
        "$$\n",
        "\\mathcal{L}_{phys} = \\lambda_1\\max(0, \\hat{e} - e_{max})^2 + \\lambda_2\\max(0, t_{min} - \\hat{t})^2\n",
        "$$\n",
        "\n",
        "| Constraint | Formula | Weight $\\lambda$ |\n",
        "|------------|---------|-------|\n",
        "| Energy Cap | $\\hat{e} \\leq 10\\text{kWh}$ | 1.5 |\n",
        "| Time Floor | $\\hat{t} \\geq \\frac{d}{v_{max}}$ | 0.8 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i2FwHEmrCkA1",
      "metadata": {
        "id": "i2FwHEmrCkA1"
      },
      "source": [
        "### Input features\n",
        "\n",
        "[\n",
        "    target_distance,        # Scalar (e.g., 7.5 km)\n",
        "    time_weight,            # 0.0 (min) ↔ 1.0 (max)\n",
        "    energy_weight,          # 0.0 (min) ↔ 1.0 (max)\n",
        "    constraints_vector      # [max_jerk, battery_limit, ...]\n",
        "]\n",
        "\n",
        "### Output Features\n",
        "[\n",
        "    acceleration_profile,   # Time-series (100 steps)\n",
        "    deceleration_profile    # Time-series (100 steps)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SNpMGhcmCm34",
      "metadata": {
        "id": "SNpMGhcmCm34"
      },
      "outputs": [],
      "source": [
        "# Example Training Batch\n",
        "batch = {\n",
        "    \"input_conditions\": torch.tensor(\n",
        "        [\n",
        "            # [distance, time_weight, energy_weight, max_jerk]\n",
        "            [7.5, 0.9, 0.1, 0.3],  # Minimum time\n",
        "            [10.0, 0.5, 0.5, 0.3],  # Balanced\n",
        "            [15.0, 0.1, 0.9, 0.3],  # Minimum energy\n",
        "        ],\n",
        "        dtype=torch.float32,\n",
        "    ),\n",
        "    \"output_profiles\": torch.tensor(\n",
        "        [\n",
        "            # [accel_profile (100 steps), decel_profile (100 steps)]\n",
        "            [0.8, 0.82, ..., 1.2, 0.5, 0.48, ..., 0.1],  # Aggressive accel\n",
        "            [0.5, 0.52, ..., 0.6, 0.4, 0.38, ..., 0.2],  # Moderate\n",
        "            [0.3, 0.31, ..., 0.4, 0.6, 0.62, ..., 0.8],  # Conservative\n",
        "        ],\n",
        "        dtype=torch.float32,\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XWIuq5uJDlVE",
      "metadata": {
        "id": "XWIuq5uJDlVE"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "loss = reconstruction_loss + α*physics_loss + β*constraint_penalty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5yU0xujtFFJl",
      "metadata": {
        "id": "5yU0xujtFFJl"
      },
      "source": [
        "### Training process\n",
        "Filter out the non-dominated solutions as resemble pareto front\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4l1PS1uJXbVI",
      "metadata": {
        "id": "4l1PS1uJXbVI"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Tabular CVAE Encoder\n",
        "\n",
        "    Encodes a 4-dimensional feature vector (accel1, accel2, time, energy)\n",
        "    concatenated with a 5-dimensional condition vector\n",
        "    (current_speed, remaining_battery, distance_to_pass, energy_weight, time_weight)\n",
        "    into latent distribution parameters (mean and log-variance).\n",
        "\n",
        "    Architecture:\n",
        "    - Input layer: 9 -> 32\n",
        "    - Hidden layer: 32 -> 16\n",
        "    - Output heads: 16 -> latent_dim (for both mean and log-variance)\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input features (4)\n",
        "        condition_dim (int): Dimensionality of the condition vector (5)\n",
        "        latent_dim (int): Dimensionality of the latent space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int = 4, condition_dim: int = 5, latent_dim: int = 8):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.condition_dim = condition_dim\n",
        "        hidden_dim1 = 32\n",
        "        hidden_dim2 = 16\n",
        "\n",
        "        # Shared MLP to extract latent statistics\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim + condition_dim, hidden_dim1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim1),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim2),\n",
        "        )\n",
        "        # Output layers for mean and log-variance\n",
        "        self.mu_layer = nn.Linear(hidden_dim2, latent_dim)\n",
        "        self.logvar_layer = nn.Linear(hidden_dim2, latent_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cond: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Feature tensor [batch_size, 4]\n",
        "            cond (Tensor): Condition tensor [batch_size, 5]\n",
        "\n",
        "        Returns:\n",
        "            mu (Tensor): Predicted latent means [batch_size, latent_dim]\n",
        "            logvar (Tensor): Predicted latent log-variances [batch_size, latent_dim]\n",
        "        \"\"\"\n",
        "        assert x.shape[1] == self.input_dim\n",
        "        assert cond.shape[1] == self.condition_dim\n",
        "        # concatenate features and conditions\n",
        "        h = torch.cat([x, cond], dim=1)\n",
        "        h = self.shared(h)\n",
        "        mu = self.mu_layer(h)\n",
        "        logvar = self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "        Tabular CVAE Decoder\n",
        "\n",
        "        Decodes a latent vector and 5-dimensional condition\n",
        "    to reconstruct the original 4-dimensional features.\n",
        "\n",
        "        Architecture:\n",
        "        - Input layer: latent_dim + 5 -> 16\n",
        "        - Hidden layer: 16 -> 32\n",
        "        - Output layer: 32 -> 4\n",
        "\n",
        "        Args:\n",
        "            latent_dim (int): Dimensionality of the latent space\n",
        "            condition_dim (int): Dimensionality of the condition vector (5)\n",
        "            output_dim (int): Dimensionality of reconstructed features (4)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, latent_dim: int = 8, condition_dim: int = 5, output_dim: int = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        hidden_dim1 = 16\n",
        "        hidden_dim2 = 32\n",
        "\n",
        "        self.decoder_net = nn.Sequential(\n",
        "            nn.Linear(latent_dim + condition_dim, hidden_dim1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim1),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim2),\n",
        "            nn.Linear(hidden_dim2, output_dim),\n",
        "        )\n",
        "        # initialize output layer for stability\n",
        "        nn.init.xavier_uniform_(self.decoder_net[-1].weight)\n",
        "        nn.init.zeros_(self.decoder_net[-1].bias)\n",
        "\n",
        "    def forward(self, z: torch.Tensor, cond: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            z (Tensor): Latent tensor [batch_size, latent_dim]\n",
        "            cond (Tensor): Condition tensor [batch_size, condition_dim]\n",
        "\n",
        "        Returns:\n",
        "            recon (Tensor): Reconstructed features [batch_size, output_dim]\n",
        "        \"\"\"\n",
        "        assert z.dim() == 2 and cond.dim() == 2\n",
        "        # concatenate latent and conditions\n",
        "        h = torch.cat([z, cond], dim=1)\n",
        "        recon = self.decoder_net(h)\n",
        "        return recon\n",
        "\n",
        "\n",
        "class PhysicsModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Model for Vehicle Dynamics and Constraints\n",
        "\n",
        "    This module computes physical metrics from acceleration profiles,\n",
        "    including energy consumption, travel time estimation, and jerk statistics.\n",
        "    It encapsulates fundamental equations of motion and resistive forces,\n",
        "    enabling integration into CVAE training and real-time inference pipelines.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuration dictionary with keys:\n",
        "            - vehicle_mass (float): Vehicle mass in kg\n",
        "            - air_density (float): Air density in kg/m^3\n",
        "            - drag_coeff (float): Aerodynamic drag coefficient\n",
        "            - rolling_res (float): Rolling resistance coefficient\n",
        "            - motor_eff (float): Motor efficiency (0 < eff <= 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "        # Vehicle physical parameters\n",
        "        self.vehicle_mass = config.get(\"vehicle_mass\", 1500.0)  # kg\n",
        "        self.air_density = config.get(\"air_density\", 1.225)  # kg/m^3\n",
        "        self.drag_coeff = config.get(\"drag_coeff\", 0.3)  # unitless\n",
        "        self.rolling_res = config.get(\"rolling_res\", 0.01)  # rolling resistance coeff\n",
        "        self.motor_eff = config.get(\"motor_eff\", 0.9)  # motor efficiency fraction\n",
        "\n",
        "    def calculate_energy(\n",
        "        self,\n",
        "        accel_profile: torch.Tensor,\n",
        "        time_profile: torch.Tensor,\n",
        "        remaining_battery: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute total energy consumption over a trip using an acceleration profile.\n",
        "\n",
        "        Args:\n",
        "            accel_profile (Tensor): [batch, time_steps] acceleration in m/s^2\n",
        "            time_profile (Tensor): [batch, time_steps] timestamps in seconds\n",
        "            remaining_battery (Tensor): [batch] current battery state-of-charge (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Tensor: energy used in kWh [batch]\n",
        "        \"\"\"\n",
        "        # Integrate acceleration to velocity\n",
        "        velocity = torch.cumsum(\n",
        "            accel_profile * (time_profile[:, 1] - time_profile[:, 0]), dim=1\n",
        "        )\n",
        "        # Compute resistive forces\n",
        "        drag_force = 0.5 * self.air_density * self.drag_coeff * velocity**2\n",
        "        rolling_force = self.rolling_res * self.vehicle_mass * 9.81\n",
        "        # Mechanical power: (mass*a + drag + rolling) * v\n",
        "        mech_power = (\n",
        "            self.vehicle_mass * accel_profile + drag_force + rolling_force\n",
        "        ) * velocity\n",
        "        # Account for motor efficiency: electrical power drawn\n",
        "        elec_power = mech_power / self.motor_eff\n",
        "        # Integrate power over time to get energy (Ws to Wh)\n",
        "        energy_Wh = torch.trapz(elec_power, time_profile, dim=1) / 3600.0\n",
        "        # Convert to kWh and clamp to remaining battery\n",
        "        return torch.clamp(energy_Wh / 1000.0, max=remaining_battery)\n",
        "\n",
        "    def calculate_jerk(\n",
        "        self, accel_profile: torch.Tensor, dt: float = 0.1\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Compute mean and maximum jerk (rate of change of acceleration).\n",
        "\n",
        "        Args:\n",
        "            accel_profile (Tensor): [batch, time_steps] acceleration in m/s^2\n",
        "            dt (float): time step between acceleration measurements\n",
        "\n",
        "        Returns:\n",
        "            mean_jerk (Tensor): mean absolute jerk [batch]\n",
        "            max_jerk (Tensor): maximum absolute jerk [batch]\n",
        "        \"\"\"\n",
        "        # Jerk: derivative of acceleration\n",
        "        jerk = (accel_profile[:, 1:] - accel_profile[:, :-1]) / dt\n",
        "        # Compute metrics\n",
        "        mean_jerk = torch.mean(torch.abs(jerk), dim=1)\n",
        "        max_jerk = torch.max(torch.abs(jerk), dim=1)\n",
        "        return mean_jerk, max_jerk\n",
        "\n",
        "    def forward(\n",
        "        self, profiles: torch.Tensor, conditions: torch.Tensor\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass: compute time, energy, average jerk, and max jerk.\n",
        "\n",
        "        Args:\n",
        "            profiles (Tensor): [batch, time_steps] acceleration profiles\n",
        "            conditions (Tensor): [batch, condition_dim] includes remaining_battery at idx 1\n",
        "\n",
        "        Returns:\n",
        "            time (Tensor): estimated travel time in seconds [batch]\n",
        "            energy (Tensor): energy consumption in kWh [batch]\n",
        "            mean_jerk (Tensor): mean absolute jerk [batch]\n",
        "            max_jerk (Tensor): maximum absolute jerk [batch]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = profiles.shape\n",
        "        # Create uniform time vector if not provided\n",
        "        dt = conditions.new_full((1,), 0.1).item()\n",
        "        t = torch.linspace(0.0, dt * (seq_len - 1), seq_len, device=profiles.device)\n",
        "        time_profile = t.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # Compute energy based on current battery\n",
        "        remaining_batt = conditions[:, 1]\n",
        "        energy = self.calculate_energy(profiles, time_profile, remaining_batt)\n",
        "\n",
        "        # Velocity integration for time estimation\n",
        "        velocity = torch.cumsum(profiles * dt, dim=1)\n",
        "        # Distance traveled\n",
        "        distance = torch.trapz(velocity, time_profile, dim=1)\n",
        "        # Time to cover distance: distance / avg speed\n",
        "        time_est = distance / (torch.mean(velocity, dim=1) + 1e-6)\n",
        "\n",
        "        # Compute jerk metrics\n",
        "        mean_jerk, max_jerk = self.calculate_jerk(profiles, dt)\n",
        "\n",
        "        return time_est, energy, mean_jerk, max_jerk\n",
        "\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Variational Autoencoder (CVAE) integrating a physics-based loss.\n",
        "\n",
        "    The CVAE learns a mapping from input acceleration profiles (tabular features)\n",
        "    and condition vectors (vehicle state and user preferences) to a latent space,\n",
        "    then reconstructs profiles via a conditional decoder.\n",
        "    Physics-informed constraints (time, energy, jerk) are incorporated into the loss\n",
        "    to enforce feasibility of generated profiles.\n",
        "\n",
        "    Components:\n",
        "    - Encoder: Produces μ and logσ² for qϕ(z|x,c)\n",
        "    - Reparameterizer: Samples z deterministically via z=μ+σ·ε\n",
        "    - Decoder: Generates reconstructed profiles pθ(x̂|z,c)\n",
        "    - PhysicsModel: Computes time, energy, and jerk for constraint losses\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuration with keys:\n",
        "            input_dim (int): Dimensionality of raw features (4)\n",
        "            latent_dim (int): Dimensionality of latent vector z\n",
        "            condition_dim (int): Dimensionality of condition vector (5)\n",
        "            device (str or torch.device): Compute device\n",
        "            max_jerk (float): Maximum allowable jerk for comfort\n",
        "            max_energy (float): Battery capacity (kWh)\n",
        "            max_time (float): Maximum allowable travel time (s)\n",
        "            base_time_weight (float): Base weight for time loss\n",
        "            base_energy_weight (float): Base weight for energy loss\n",
        "            base_jerk_weight (float): Base weight for jerk loss\n",
        "            adaptive_weighting (bool): Use dynamic weights from conditions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "        # Save config and device\n",
        "        self.device = torch.device(config.get(\"device\", \"cpu\"))\n",
        "\n",
        "        # Instantiate encoder, decoder, and physics model\n",
        "        self.encoder = Encoder(\n",
        "            input_dim=config[\"input_dim\"],\n",
        "            condition_dim=config.get(\"condition_dim\", 5),\n",
        "            latent_dim=config[\"latent_dim\"],\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            latent_dim=config[\"latent_dim\"],\n",
        "            condition_dim=config.get(\"condition_dim\", 5),\n",
        "            output_dim=config[\"input_dim\"],\n",
        "        )\n",
        "        self.physics_model = PhysicsModel(config)\n",
        "\n",
        "        # Physics/constraint parameters\n",
        "        self.max_jerk = config.get(\"max_jerk\", 2.5)\n",
        "        self.max_energy = config.get(\"max_energy\", 10.0)\n",
        "        self.max_time = config.get(\"max_time\", 120.0)\n",
        "\n",
        "        # Loss weights\n",
        "        self.adaptive = config.get(\"adaptive_weighting\", True)\n",
        "        self.base_time_w = config.get(\"base_time_weight\", 0.5)\n",
        "        self.base_energy_w = config.get(\"base_energy_weight\", 0.5)\n",
        "        self.base_jerk_w = config.get(\"base_jerk_weight\", 0.2)\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Apply the reparameterization trick to sample z ~ N(mu, sigma^2) in a differentiable way.\n",
        "\n",
        "        Args:\n",
        "            mu (Tensor): Mean of latent Gaussian [batch, latent_dim]\n",
        "            logvar (Tensor): Log-variance of latent Gaussian [batch, latent_dim]\n",
        "        Returns:\n",
        "            z (Tensor): Sampled latent vectors [batch, latent_dim]\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std, device=self.device)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cond: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass through CVAE: encode, sample, and decode.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Original feature profiles [batch, input_dim]\n",
        "            cond (Tensor): Condition vectors [batch, condition_dim]\n",
        "        Returns:\n",
        "            recon (Tensor): Reconstructed profiles [batch, input_dim]\n",
        "            mu (Tensor), logvar (Tensor): Latent distribution parameters\n",
        "        \"\"\"\n",
        "        # Encode to latent distribution parameters\n",
        "        mu, logvar = self.encoder(x, cond)\n",
        "        # Sample latent vectors via reparameterization\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        # Decode conditioned on z and conditions\n",
        "        recon = self.decoder(z, cond)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "    def loss(\n",
        "        self,\n",
        "        recon: torch.Tensor,\n",
        "        x: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "        cond: torch.Tensor,\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Compute the composite loss combining reconstruction, KL divergence,\n",
        "        and physics-based constraint penalties.\n",
        "\n",
        "        Steps:\n",
        "        1. Weighted MSE reconstruction loss based on time/energy weights\n",
        "        2. KL divergence term to regularize latent space\n",
        "        3. Physics model computes time, energy, jerk from recon\n",
        "        4. Compute huber losses for time and energy targets\n",
        "        5. Jerk penalty for exceeding comfort threshold\n",
        "\n",
        "        Args:\n",
        "            recon (Tensor): Decoded profiles [batch, input_dim]\n",
        "            x (Tensor): Original profiles [batch, input_dim]\n",
        "            mu, logvar (Tensor): Latent params [batch, latent_dim]\n",
        "            cond (Tensor): Conditions [batch, condition_dim]\n",
        "        Returns:\n",
        "            dict: {\"total\": Tensor, \"recon\":, \"kld\":, \"time\":, \"energy\":, \"jerk\":}\n",
        "        \"\"\"\n",
        "        # Extract dynamic weights if adaptive, else use base\n",
        "        tw = cond[:, -1] if self.adaptive else self.base_time_w\n",
        "        ew = cond[:, -2] if self.adaptive else self.base_energy_w\n",
        "\n",
        "        # Reconstruction loss (MSE) weighted by time and energy preferences\n",
        "        mse = F.mse_loss(recon, x, reduction=\"none\")  # [batch, features]\n",
        "        recon_loss = (mse * torch.stack([tw, ew, tw, ew], dim=1)).mean()\n",
        "\n",
        "        # KL divergence\n",
        "        kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "\n",
        "        # Physics-based metrics on reconstructions\n",
        "        time_pred, energy_pred, mean_jerk, max_jerk = self.physics_model(recon, cond)\n",
        "\n",
        "        # Targets: ideal time and energy based on conditions\n",
        "        speed, batt, dist, _, _ = cond.T\n",
        "        ideal_time = dist / (speed + 1e-6)\n",
        "        ideal_energy = batt * dist * 0.001  # placeholder conversion\n",
        "\n",
        "        time_loss = F.huber_loss(time_pred, ideal_time)\n",
        "        energy_loss = F.huber_loss(energy_pred, ideal_energy)\n",
        "        jerk_loss = F.relu(max_jerk - self.max_jerk).mean()\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = (\n",
        "            recon_loss\n",
        "            + kld\n",
        "            + tw.mean() * time_loss\n",
        "            + ew.mean() * energy_loss\n",
        "            + self.base_jerk_w * jerk_loss\n",
        "        )\n",
        "        return {\n",
        "            \"total\": total_loss,\n",
        "            \"recon\": recon_loss,\n",
        "            \"kld\": kld,\n",
        "            \"time\": time_loss,\n",
        "            \"energy\": energy_loss,\n",
        "            \"jerk\": jerk_loss,\n",
        "        }\n",
        "\n",
        "\n",
        "def train(model: nn.Module, dataloader, config: dict) -> None:\n",
        "    \"\"\"\n",
        "    Train a Conditional Variational Autoencoder (CVAE) model with physics-informed loss.\n",
        "\n",
        "    This routine runs the full training loop, including:\n",
        "      1. Moving the model to the specified device.\n",
        "      2. Iterating over epochs and batches.\n",
        "      3. Performing forward and backward passes.\n",
        "      4. Updating model parameters via AdamW.\n",
        "      5. Scheduling the learning rate based on validation loss.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The CVAE instance to train.\n",
        "        dataloader (DataLoader): Provides batches of dicts with keys:\n",
        "            - \"profile\": Tensor of shape [batch, input_dim]\n",
        "            - \"conditions\": Tensor of shape [batch, condition_dim]\n",
        "        config (dict): Training configuration with entries:\n",
        "            - \"device\": torch.device or string, e.g., \"cuda\" or \"cpu\"\n",
        "            - \"epochs\": int, total number of epochs\n",
        "            - \"lr\": float, initial learning rate\n",
        "            - \"weight_decay\": float, L2 regularization coefficient\n",
        "            - \"batch_size\": int, number of samples per batch\n",
        "            - \"scheduler_patience\": int, epochs to wait for LR plateau\n",
        "            - \"scheduler_factor\": float, LR reduction factor on plateau\n",
        "\n",
        "    Returns:\n",
        "        None: The function trains the model in place and prints progress.\n",
        "    \"\"\"\n",
        "    # Move model to the requested compute device\n",
        "    device = torch.device(config[\"device\"])\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Set up optimizer with weight decay for regularization\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config[\"lr\"],\n",
        "        weight_decay=config.get(\"weight_decay\", 1e-5),\n",
        "    )\n",
        "\n",
        "    # Reduce LR when total loss has plateaued\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        patience=config.get(\"scheduler_patience\", 5),\n",
        "        factor=config.get(\"scheduler_factor\", 0.5),\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, config[\"epochs\"] + 1):\n",
        "        epoch_loss = 0.0\n",
        "        progress = tqdm(dataloader, desc=f\"[Epoch {epoch}/{config['epochs']}]\")\n",
        "\n",
        "        for batch in progress:\n",
        "            # Unpack and move inputs to device\n",
        "            x = batch[\"profile\"].to(device)  # [batch, input_dim]\n",
        "            cond = batch[\"conditions\"].to(device)  # [batch, condition_dim]\n",
        "\n",
        "            # Zero gradients from previous step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through CVAE\n",
        "            recon, mu, logvar = model(x, cond)\n",
        "\n",
        "            # Compute all loss components\n",
        "            losses = model.loss_function(recon, x, mu, logvar, cond)\n",
        "\n",
        "            # Backward pass: gradients flow through reparameterization\n",
        "            losses[\"total\"].backward()\n",
        "\n",
        "            # Gradient clipping for stability\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Parameter update\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate and display per-batch loss\n",
        "            batch_loss = losses[\"total\"].item()\n",
        "            epoch_loss += batch_loss\n",
        "            progress.set_postfix(total_loss=batch_loss / x.size(0))\n",
        "\n",
        "        # Step the scheduler based on epoch’s total loss\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader.dataset)\n",
        "        print(f\"Epoch {epoch:>3}: Avg Loss = {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Utility to select the compute device.\n",
        "\n",
        "    Returns:\n",
        "        torch.device: 'cuda' if available, otherwise 'cpu'.\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1431b8e8",
      "metadata": {
        "id": "1431b8e8"
      },
      "outputs": [],
      "source": [
        "def plot_latent(autoencoder, data, num_batches=100):\n",
        "    for i, (x, y) in enumerate(data):\n",
        "        z = autoencoder.encoder(x.to(get_device()))\n",
        "        z = z.to(\"cpu\").detach().numpy()\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap=\"tab10\")\n",
        "        if i > num_batches:\n",
        "            plt.colorbar()\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KG2S6vOU98qu",
      "metadata": {
        "id": "KG2S6vOU98qu"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "# Configuration Example\n",
        "config = {\n",
        "    # —— Model dimensions ——————————————————————————————————\n",
        "    \"input_dim\": 200,  # length of accel+decel profile vector\n",
        "    \"output_dim\": 200,  # same as input_dim\n",
        "    \"latent_dim\": 32,  # size of z\n",
        "    \"condition_dim\": 5,  # number of condition features (e.g. [speed, soc, distance, energy_w, time_w])\n",
        "    # —— Training settings ——————————————————————————————\n",
        "    \"device\": get_device(),\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 64,\n",
        "    \"weight_decay\": 1e-5,  # for AdamW\n",
        "    \"beta\": 1.0,  # KLD annealing coefficient (if you use a β–VAE schedule)\n",
        "    \"adaptive_weighting\": True,  # enable condition‐driven time/energy weighting\n",
        "    # —— Physics & Constraint hyperparameters —————————————\n",
        "    \"max_jerk\": 2.5,  # m/s³ comfort threshold\n",
        "    \"max_energy\": 10.0,  # kWh battery capacity\n",
        "    \"max_time\": 120.0,  # minutes or seconds consistent with your loss\n",
        "    # —— Loss base weights (if not adaptive) —————————————\n",
        "    \"base_time_weight\": 0.5,\n",
        "    \"base_energy_weight\": 0.5,\n",
        "    \"base_jerk_weight\": 0.2,\n",
        "    # —— Scheduler & Seed ——————————————————————————————\n",
        "    \"seed\": 42,  # reproducibility\n",
        "    \"scheduler_patience\": 5,  # for ReduceLROnPlateau\n",
        "    \"scheduler_factor\": 0.5,  # LR reduction factor\n",
        "}\n",
        "\n",
        "cvae = CVAE(config)\n",
        "\n",
        "# Create synthetic dataset\n",
        "train_data = [...]  # Implement proper Dataset class\n",
        "dataloader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "# Train model\n",
        "train(cvae, dataloader, config)\n",
        "\n",
        "# Save model\n",
        "torch.save(cvae.state_dict(), \"monocap_cvae.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GKt8rSalw_j3",
      "metadata": {
        "id": "GKt8rSalw_j3"
      },
      "source": [
        "## Visualize latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PHvc2W0oxGOa",
      "metadata": {
        "id": "PHvc2W0oxGOa"
      },
      "outputs": [],
      "source": [
        "def plot_latent(autoencoder, data, num_batches=100):\n",
        "    for i, (x, y) in enumerate(data):\n",
        "        z = autoencoder.encoder(x.to(get_device()))\n",
        "        z = z.to(\"cpu\").detach().numpy()\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap=\"tab10\")\n",
        "        if i > num_batches:\n",
        "            plt.colorbar()\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c47fae3",
      "metadata": {},
      "source": [
        "## Anchor Extraction & Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7786a9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AnchorBuilder:\n",
        "    def __init__(self, cvae: CVAE, dataset: Dataset):\n",
        "        self.cvae = cvae.eval()\n",
        "        self.dataset = dataset\n",
        "        self.anchors = []  # list of (cond, mu)\n",
        "\n",
        "    def build(self, device=\"cpu\"):\n",
        "        for batch in DataLoader(self.dataset, batch_size=64):\n",
        "            x = batch[\"profile\"].to(device)\n",
        "            c = batch[\"conditions\"].to(device)\n",
        "            with torch.no_grad():\n",
        "                mu, _ = self.cvae.encoder(x, c)\n",
        "            for cond_vec, mu_vec in zip(c.cpu().numpy(), mu.cpu().numpy()):\n",
        "                self.anchors.append((cond_vec, mu_vec))\n",
        "        # Save anchors to disk for reuse\n",
        "        np.save(\"anchors.npy\", self.anchors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70730bee",
      "metadata": {},
      "source": [
        "## KD-Tree for Fast NN Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b671ffa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "\n",
        "class ConditionIndex:\n",
        "    def __init__(self, anchors_path=\"anchors.npy\"):\n",
        "        self.anchors = np.load(anchors_path, allow_pickle=True)\n",
        "        conds = np.stack([a[0] for a in self.anchors])\n",
        "        self.tree = KDTree(conds)  # leaf_size defaults to 40\n",
        "\n",
        "    def query(self, c_new, k=3):\n",
        "        dists, idxs = self.tree.query([c_new], k=k)\n",
        "        return [(self.anchors[i][1], dists[0][j]) for j, i in enumerate(idxs[0])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d1ad84",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalPrior(nn.Module):\n",
        "    \"\"\"Train a lightweight MLP to predict encoder means directly from conditions, avoiding NN lookups\"\"\"\n",
        "\n",
        "    def __init__(self, condition_dim, latent_dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(condition_dim, hidden), nn.ReLU(), nn.Linear(hidden, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, c):\n",
        "        return self.net(c)\n",
        "\n",
        "\n",
        "prior = ConditionalPrior(cond_dim, latent_dim).to(device)\n",
        "opt = torch.optim.Adam(prior.parameters(), lr=1e-3)\n",
        "for epoch in range(50):\n",
        "    for cond_vec, mu_vec in DataLoader(anchors_dataset, batch_size=64):\n",
        "        pred = prior(cond_vec.to(device))\n",
        "        loss = F.mse_loss(pred, mu_vec.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0TceaapCtx05",
      "metadata": {
        "id": "0TceaapCtx05"
      },
      "source": [
        "# Resources\n",
        "\n",
        "- [1] [Autoencoder implementation in Pytorch](https://avandekleut.github.io/vae/)\n",
        "- [2] [Deep dive into Conditional VAE](https://beckham.nz/2023/04/27/conditional-vaes.html?utm_source=chatgpt.com#sec_derivation)\n",
        "- [3] [How to implement conditional VAE](https://www.linkedin.com/advice/1/how-do-you-implement-conditional-vae-what-benefits?utm_source=chatgpt.com)\n",
        "- [4] [What about the conditional variational autoencoder?](https://creatis-myriad.github.io/tutorials/2022-09-12-tutorial-cvae.html?utm_source=chatgpt.com)\n",
        "\n",
        "- [5] [Youtub : Variational Auto Encoder (VAE) - Theory](https://www.youtube.com/watch?v=vJo7hiMxbQ8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pareto-optimization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
