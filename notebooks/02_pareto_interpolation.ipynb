{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicola-Ibrahim/Pareto-Optimization/blob/main/notebooks/02_pareto_interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder Formulation for Pareto Front Analysis\n",
        "\n",
        "Some of considerd limitations:\n",
        "1. Defining the optimal point (energy/time -> acceleration) at the beginning of the system. The user has the ability to select that.\n",
        "\n",
        "2. All data features should be taken into account, e.g. (Decision variables + problem parameters + objectives)"
      ],
      "metadata": {
        "id": "BMotfZgYgP9h"
      },
      "id": "BMotfZgYgP9h"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "nqxWtmAw9qmU",
      "metadata": {
        "id": "nqxWtmAw9qmU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hr8T5ZsM-nCz",
      "metadata": {
        "id": "Hr8T5ZsM-nCz"
      },
      "source": [
        "## Date reading\n",
        "\n",
        "**Input Data Structure**:\n",
        "- Let $X = \\{\\mathbf{x}_i\\}_{i=1}^N \\subset \\mathbb{R}^2$ be the set of Pareto-optimal solutions\n",
        "- Each solution $\\mathbf{x}_i = (f_1^{(i)}, f_2^{(i)}, ...,f_n^{(i)})$ represents a trade-off between:\n",
        "  - $f_1$: Travel time (minutes)\n",
        "  - $f_2$: Energy consumption (kWh)\n",
        "  - $f_n$: Other data variables\n",
        "\n",
        "Then, filter out the needed data for trainig purpose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pareto_data = pd.read_pickle(\"./pareto_data.pkl\")\n",
        "print(pareto_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp5dTiMflpDK",
        "outputId": "7b9f3029-a08e-46b1-bdd2-53691060e227"
      },
      "id": "Tp5dTiMflpDK",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     accel_phase1  accel_phase2  travel_time_min  energy_consumption_kWh\n",
            "0        0.320633      0.320324       111.746856                0.111468\n",
            "1        3.999286      3.997122        40.836702                0.220684\n",
            "2        0.475870      0.459985        93.265481                0.148673\n",
            "3        0.369715      0.362149       105.101609                0.123231\n",
            "4        0.300027      3.913528        77.547350                0.152288\n",
            "..            ...           ...              ...                     ...\n",
            "195      0.334531      3.990467        74.527048                0.157926\n",
            "196      0.654983      3.994694        59.414347                0.210287\n",
            "197      0.673767      3.990258        58.882757                0.213357\n",
            "198      0.398851      3.970569        70.094236                0.168436\n",
            "199      0.500042      3.989768        64.902046                0.184970\n",
            "\n",
            "[200 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T7CaJUAe4drS",
      "metadata": {
        "id": "T7CaJUAe4drS"
      },
      "source": [
        "\n",
        "## Data preparation\n",
        "**Normalization**: Scale objectives to $[0,1]$ range for training stability:\n",
        "$$\n",
        "\\hat{f}_k = \\frac{f_k - f_{k}^{min}}{f_{k}^{max} - f_{k}^{min}}, \\quad \\text{for } k=1,2\n",
        "$$\n",
        "\n",
        "**Standardization**:\n",
        "$$\n",
        "\\hat{f}_k^{(i)} = \\frac{f_k^{(i)} - \\mu_k}{\\sigma_k}, \\quad \\text{for } k=1,2\n",
        "$$\n",
        "where $\\mu_k$, $\\sigma_k$ are the mean and standard deviation of each objective.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the the data need to be normalized\n",
        "pareto_data.aggregate({'travel_time_min': ['min', 'max'], 'energy_consumption_kWh': ['min', 'max']})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "V56ab8Tlmy0J",
        "outputId": "83e1e13d-1cf5-4817-cb4b-3c57618ced9e"
      },
      "id": "V56ab8Tlmy0J",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     travel_time_min  energy_consumption_kWh\n",
              "min        40.836702                0.111468\n",
              "max       111.746856                0.220684"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54dc8d04-bbb4-4347-9860-8e31904aeb23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>travel_time_min</th>\n",
              "      <th>energy_consumption_kWh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.836702</td>\n",
              "      <td>0.111468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>111.746856</td>\n",
              "      <td>0.220684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54dc8d04-bbb4-4347-9860-8e31904aeb23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54dc8d04-bbb4-4347-9860-8e31904aeb23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54dc8d04-bbb4-4347-9860-8e31904aeb23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-93ea0aee-1c5a-473f-8223-d0207608aa83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93ea0aee-1c5a-473f-8223-d0207608aa83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-93ea0aee-1c5a-473f-8223-d0207608aa83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pareto_data\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"travel_time_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.14105031360019,\n        \"min\": 40.83670245156898,\n        \"max\": 111.7468558366941,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          111.7468558366941,\n          40.83670245156898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_consumption_kWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07722695119362646,\n        \"min\": 0.11146828110982653,\n        \"max\": 0.22068368286857815,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.22068368286857815,\n          0.11146828110982653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "bc9ba7a8",
      "metadata": {
        "id": "bc9ba7a8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Normalize to [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(pareto_data[['travel_time_min', 'energy_consumption_kWh']])\n",
        "\n",
        "# Split data (80% train, 20% validation)\n",
        "X_train, X_val = train_test_split(X_normalized, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HGrqXafj-W1n",
      "metadata": {
        "id": "HGrqXafj-W1n"
      },
      "source": [
        "## Conditional VAE Architecture\n",
        "\n",
        "### Why to use?\n",
        "In traditional autoencoders, inputs are mapped deterministically to a latent vector\n",
        "$z=e(x)$. In variational autoencoders, inputs are mapped to a probability distribution over latent vectors, and a latent vector is then sampled from that distribution. The decoder becomes more robust at decoding latent vectors as a result.\n",
        "\n",
        "### Variational Autoencoder (VAE) Latent Space Mapping\n",
        "\n",
        "Instead of directly mapping the input **$ x $** to a latent vector **$ z = e(x) $**, we instead map it to:\n",
        "\n",
        "- **Mean vector**: **$ \\mu(x) $**\n",
        "- **Standard deviation vector**: **$ \\sigma(x) $**\n",
        "\n",
        "These parameters define a **diagonal Gaussian distribution** $ N(\\mu(x), \\sigma(x)) $, from which we sample the latent vector $ z $:\n",
        "\n",
        "$$\n",
        "z \\sim N(\\mu(x), \\sigma(x))\n",
        "$$\n",
        "\n",
        "This formulation allows the model to learn a probabilistic latent space representation where each input $ x $ defines its own distribution over latent codes rather than a single deterministic point.\n",
        "\n",
        "\n",
        "### Encoder Network (Compression)\n",
        "$$\n",
        "\\mathbf{z} = g_\\phi(\\mathbf{x}) = \\text{LeakyReLU}(\\mathbf{W}_2 \\cdot \\text{ELU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "### Decoder Network (Reconstruction)\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = f_\\theta(\\mathbf{z}) = \\text{Sigmoid}(\\mathbf{W}_4 \\cdot \\text{ELU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "**Dimensionality**:\n",
        "- Input/Output: $\\mathbb{R}^2$ (normalized objectives)\n",
        "- Latent space: $\\mathbb{R}^1$ (bottleneck)\n",
        "- Hidden layers: 32 neurons with ELU activation\n",
        "\n",
        "\n",
        "## Architecture\n",
        "Sigmoid ensures outputs stay in normalized $[0,1]$ range\n",
        "\n",
        "### Encoder\n",
        "Maps 2D Pareto solutions to a 1D latent space:\n",
        "$$\n",
        "\\mathbf{z} = \\text{Encoder}(\\mathbf{x}) = \\sigma(\\mathbf{W}_2 \\cdot \\text{ReLU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\mathbf{W}_1 \\in \\mathbb{R}^{h \\times 2}$, $\\mathbf{W}_2 \\in \\mathbb{R}^{1 \\times h}$ are weight matrices\n",
        "- $\\mathbf{b}_1 \\in \\mathbb{R}^h$, $\\mathbf{b}_2 \\in \\mathbb{R}^1$ are bias terms\n",
        "- $h$ is hidden layer size\n",
        "- $\\sigma$ is sigmoid activation\n",
        "\n",
        "### Decoder\n",
        "Reconstructs solutions from latent space:\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = \\text{Decoder}(\\mathbf{z}) = \\sigma(\\mathbf{W}_4 \\cdot \\text{ReLU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "With:\n",
        "- $\\mathbf{W}_3 \\in \\mathbb{R}^{h \\times 1}$, $\\mathbf{W}_4 \\in \\mathbb{R}^{2 \\times h}$\n",
        "- $\\mathbf{b}_3 \\in \\mathbb{R}^h$, $\\mathbf{b}_4 \\in \\mathbb{R}^2$\n",
        "\n",
        "\n",
        "### Activation function\n",
        "\n",
        "### Loss Function\n",
        "Mean Squared Error (MSE) reconstruction loss:\n",
        "$$\n",
        "\\mathcal{L}_{recon} = \\frac{1}{N}\\sum_{i=1}^N \\|\\mathbf{x}_i - \\hat{\\mathbf{x}}_i\\|^2_2\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input features\n",
        "\n",
        "[\n",
        "    target_distance,        # Scalar (e.g., 7.5 km)\n",
        "    time_weight,            # 0.0 (min) ↔ 1.0 (max)\n",
        "    energy_weight,          # 0.0 (min) ↔ 1.0 (max)\n",
        "    constraints_vector      # [max_jerk, battery_limit, ...]\n",
        "]\n",
        "\n",
        "### Output Features\n",
        "[\n",
        "    acceleration_profile,   # Time-series (100 steps)\n",
        "    deceleration_profile    # Time-series (100 steps)\n",
        "]\n"
      ],
      "metadata": {
        "id": "i2FwHEmrCkA1"
      },
      "id": "i2FwHEmrCkA1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Training Batch\n",
        "batch = {\n",
        "    'input_conditions': torch.tensor([\n",
        "        # [distance, time_weight, energy_weight, max_jerk]\n",
        "        [7.5, 0.9, 0.1, 0.3],    # Minimum time\n",
        "        [10.0, 0.5, 0.5, 0.3],    # Balanced\n",
        "        [15.0, 0.1, 0.9, 0.3]     # Minimum energy\n",
        "    ], dtype=torch.float32),\n",
        "\n",
        "    'output_profiles': torch.tensor([\n",
        "        # [accel_profile (100 steps), decel_profile (100 steps)]\n",
        "        [0.8, 0.82, ..., 1.2, 0.5, 0.48, ..., 0.1],  # Aggressive accel\n",
        "        [0.5, 0.52, ..., 0.6, 0.4, 0.38, ..., 0.2],  # Moderate\n",
        "        [0.3, 0.31, ..., 0.4, 0.6, 0.62, ..., 0.8]   # Conservative\n",
        "    ], dtype=torch.float32)\n",
        "}\n"
      ],
      "metadata": {
        "id": "SNpMGhcmCm34"
      },
      "id": "SNpMGhcmCm34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function\n",
        "\n",
        "loss = reconstruction_loss + α*physics_loss + β*constraint_penalty\n"
      ],
      "metadata": {
        "id": "XWIuq5uJDlVE"
      },
      "id": "XWIuq5uJDlVE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training process\n",
        "Filter out the non-dominated solutions as resemble pareto front\n",
        "\n"
      ],
      "metadata": {
        "id": "5yU0xujtFFJl"
      },
      "id": "5yU0xujtFFJl"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, condition_dim):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.condition_dim = condition_dim\n",
        "        self.shared_encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim + condition_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.mu = nn.Linear(256, latent_dim)\n",
        "        self.logvar = nn.Linear(256, latent_dim)\n",
        "\n",
        "    def forward(self, x, conditions):\n",
        "        x = torch.cat([x, conditions], dim=1)\n",
        "        h = self.shared_encoder(x)\n",
        "        return self.mu(h), self.logvar(h)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, latent_dim, condition_dim):\n",
        "        super().__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim + condition_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.Tanh()  # Constrain output to [-1,1] for stability\n",
        "        )\n",
        "\n",
        "    def forward(self, z, conditions):\n",
        "        z = torch.cat([z, conditions], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "class PhysicsModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Replace with actual physics simulation layers\n",
        "        self.simulation_network = nn.Sequential(\n",
        "            nn.Linear(200, 128),  # Input: 100-step accel + 100-step decel\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(128, 2)  # Output: time, energy\n",
        "        )\n",
        "\n",
        "    def calculate_jerk(self, profiles):\n",
        "        # Implement actual jerk calculation\n",
        "        return torch.norm(profiles[:,1:] - profiles[:,:-1], dim=1)\n",
        "\n",
        "    def forward(self, profiles):\n",
        "        simulated = self.simulation_network(profiles)\n",
        "        jerk = self.calculate_jerk(profiles)\n",
        "        return simulated[:,0], simulated[:,1], jerk\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(config['input_dim'],\n",
        "                             config['latent_dim'],\n",
        "                             config['condition_dim'])\n",
        "        self.decoder = Decoder(config['output_dim'],\n",
        "                             config['latent_dim'],\n",
        "                             config['condition_dim'])\n",
        "        self.physics_model = PhysicsModel()\n",
        "        self.device = torch.device(config['device'])\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def forward(self, x, conditions):\n",
        "        mu, logvar = self.encoder(x, conditions)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z, conditions), mu, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar, conditions):\n",
        "        # Reconstruction loss\n",
        "        BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
        "\n",
        "        # KL divergence\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        # Physics constraints\n",
        "        time_pred, energy_pred, jerk = self.physics_model(recon_x)\n",
        "\n",
        "        # Time and energy targets from conditions\n",
        "        time_target = conditions[:,0] * MAX_TIME\n",
        "        energy_target = conditions[:,1] * MAX_ENERGY\n",
        "\n",
        "        # Physics-based losses\n",
        "        time_loss = F.l1_loss(time_pred, time_target)\n",
        "        energy_loss = F.l1_loss(energy_pred, energy_target)\n",
        "        jerk_loss = F.relu(jerk - MAX_JERK).mean()\n",
        "\n",
        "        return {\n",
        "            'loss': BCE + KLD + time_loss + energy_loss + jerk_loss,\n",
        "            'BCE': BCE,\n",
        "            'KLD': KLD,\n",
        "            'time_loss': time_loss,\n",
        "            'energy_loss': energy_loss,\n",
        "            'jerk_loss': jerk_loss\n",
        "        }\n",
        "\n",
        "def train(model, dataloader, config):\n",
        "    model.to(config['device'])\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                                lr=config['lr'],\n",
        "                                weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in progress:\n",
        "            x = batch['profile'].to(config['device'])\n",
        "            conditions = batch['conditions'].to(config['device'])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            recon_x, mu, logvar = model(x, conditions)\n",
        "            losses = model.loss_function(recon_x, x, mu, logvar, conditions)\n",
        "\n",
        "            losses['loss'].backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += losses['loss'].item()\n",
        "            progress.set_postfix(loss=losses['loss'].item()/x.size(0))\n",
        "\n",
        "        scheduler.step(total_loss)\n",
        "        print(f\"Epoch {epoch+1} Avg Loss: {total_loss/len(dataloader.dataset)}\")\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "4l1PS1uJXbVI"
      },
      "id": "4l1PS1uJXbVI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "1431b8e8",
        "outputId": "878daa68-af91-48e8-cc56-16cf073fe52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:1387: UserWarning: Layer 'transformer_encoder' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling Softmax.call().\n",
            "\n",
            "\u001b[1mtuple index out of range\u001b[0m\n",
            "\n",
            "Arguments received by Softmax.call():\n",
            "  • inputs=tf.Tensor(shape=(None, 2), dtype=float32)\n",
            "  • mask=None''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Exception encountered when calling TransformerEncoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_encoder' (of type TransformerEncoder). Either the `TransformerEncoder.call()` method is incorrect, or you need to implement the `TransformerEncoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling Softmax.call().\n\n\u001b[1mtuple index out of range\u001b[0m\n\nArguments received by Softmax.call():\n  • inputs=tf.Tensor(shape=(None, 2), dtype=float32)\n  • mask=None\u001b[0m\n\nArguments received by TransformerEncoder.call():\n  • args=('<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_1>',)\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1d471b47dfc0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1d471b47dfc0>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling TransformerEncoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_encoder' (of type TransformerEncoder). Either the `TransformerEncoder.call()` method is incorrect, or you need to implement the `TransformerEncoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling Softmax.call().\n\n\u001b[1mtuple index out of range\u001b[0m\n\nArguments received by Softmax.call():\n  • inputs=tf.Tensor(shape=(None, 2), dtype=float32)\n  • mask=None\u001b[0m\n\nArguments received by TransformerEncoder.call():\n  • args=('<KerasTensor shape=(None, 32), dtype=float32, sparse=False, name=keras_tensor_1>',)\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.norm = LayerNormalization()\n",
        "        self.dense = Dense(embed_dim, activation='gelu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.attention(inputs, inputs)\n",
        "        x = self.norm(inputs + attn_output)\n",
        "        return self.dense(x)\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.norm = LayerNormalization()\n",
        "        self.dense = Dense(embed_dim, activation='gelu')\n",
        "\n",
        "    def call(self, inputs, context):\n",
        "        attn_output = self.attention(inputs, context)\n",
        "        x = self.norm(inputs + attn_output)\n",
        "        return self.dense(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom loss with reconstruction and latent regularization\n",
        "def total_loss(y_true, y_pred):\n",
        "    recon_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "    latent_reg = tf.reduce_mean(tf.square(latent))\n",
        "    return recon_loss + 0.1 * latent_reg\n",
        "\n",
        "# Transformer Autoencoder\n",
        "input_dim = 2\n",
        "latent_dim = 1\n",
        "embed_dim = 32\n",
        "num_heads = 2\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=(input_dim,))\n",
        "x = Dense(embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, num_heads)(x)\n",
        "latent = Dense(latent_dim, name='latent')(x)\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "x = Dense(embed_dim)(decoder_input)\n",
        "x = TransformerDecoder(embed_dim, num_heads)(x, x)\n",
        "outputs = Dense(input_dim, activation='sigmoid')(x)\n",
        "\n",
        "# Models\n",
        "encoder = Model(inputs, latent)\n",
        "decoder = Model(decoder_input, outputs)\n",
        "autoencoder = Model(inputs, decoder(encoder(inputs)))\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=hybrid_loss)\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=500,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_val, X_val),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
        "    ]\n",
        ")"
      ],
      "id": "1431b8e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KG2S6vOU98qu",
      "metadata": {
        "id": "KG2S6vOU98qu"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "# Configuration Example\n",
        "config = {\n",
        "    'input_dim': 200,       # 100-step accel + 100-step decel\n",
        "    'output_dim': 200,\n",
        "    'latent_dim': 32,\n",
        "    'condition_dim': 4,     # [distance, time_w, energy_w, max_jerk]\n",
        "    'device': get_device(),\n",
        "    'epochs': 100,\n",
        "    'lr': 1e-4,\n",
        "    'batch_size': 64\n",
        "}\n",
        "\n",
        "cvae = CVAE(config)\n",
        "\n",
        "# Create synthetic dataset\n",
        "train_data = [...]  # Implement proper Dataset class\n",
        "dataloader = DataLoader(train_data,\n",
        "                        batch_size=config['batch_size'],\n",
        "                        shuffle=True)\n",
        "\n",
        "# Train model\n",
        "train(cvae, dataloader, config)\n",
        "\n",
        "# Save model\n",
        "torch.save(cvae.state_dict(), 'monocap_cvae.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A8km8d2E-ANE",
      "metadata": {
        "id": "A8km8d2E-ANE"
      },
      "source": [
        "## Interpolation in Latent Space\n",
        "\n",
        "Since the autoencoder help to transform the space into more representive, less feature complexity, and clustering the paretor solutions depending on similarity. We can utilize it to query new pareto solution for arabitrary defined distance by the user (7.5km)\n",
        "Since the optimum pareto solution could not be the best choice we can interpolate it for better result\n",
        "\n",
        "\n",
        "### Interploation tactics:\n",
        "- Linear Interploation:\n",
        "    1. search for the optimum solution in the closest cluster, e.g. if the request is something like (14Km, 0.8 time, 0.2 energy), then the autoencoder should know to narrow down the search for better pareto front accessibility.\n",
        "\n",
        "    2. apply linear interpolation, taking the one of the optimal point in the pareto front. e.g if the time is more improtant then we have to shift the searching to area wher the time is more important and then select the opmtimum point, then we apply the interpolation on it.\n",
        "\n",
        "    3. decoded the point to get the corrosponding $u_t$ input\n",
        "\n",
        "    4. check the feasibilty and validity of the generated new input and deploy to MonoCap\n",
        "    \n",
        "- Linear Interpolation\n",
        "For solutions $\\mathbf{x}_A$, $\\mathbf{x}_B$:\n",
        "    1. Encode two solutions:\n",
        "    $$\n",
        "    \\mathbf{z}_A = \\text{Encoder}(\\mathbf{x}_A), \\quad \\mathbf{z}_B = \\text{Encoder}(\\mathbf{x}_B)\n",
        "    $$\n",
        "\n",
        "    2. Linear interpolation:\n",
        "    $$\n",
        "    \\mathbf{z}_{new} = \\alpha\\mathbf{z}_A + (1-\\alpha)\\mathbf{z}_B, \\quad \\alpha \\in [0,1]\n",
        "    $$\n",
        "\n",
        "    3. Decode to generate new solution:\n",
        "    $$\n",
        "    \\mathbf{x}_{new} = \\text{Decoder}(\\mathbf{z}_{new})\n",
        "    $$\n",
        "\n",
        "\n",
        "- Geodesic Interpolation\n",
        "    For solutions $\\mathbf{x}_A$, $\\mathbf{x}_B$:\n",
        "    1. Encode: $\\mathbf{z}_A = g_\\phi(\\mathbf{x}_A)$, $\\mathbf{z}_B = g_\\phi(\\mathbf{x}_B)$\n",
        "    2. Spherical interpolation:\n",
        "    $$\n",
        "    \\mathbf{z}_{\\text{new}} = \\frac{\\sin[(1-\\alpha)\\Omega]}{\\sin\\Omega}\\mathbf{z}_A + \\frac{\\sin[\\alpha\\Omega]}{\\sin\\Omega}\\mathbf{z}_B\n",
        "    $$\n",
        "    where $\\Omega = \\arccos(\\mathbf{z}_A^\\top \\mathbf{z}_B)$\n",
        "\n",
        "    3. Decode:\n",
        "    $$\n",
        "    \\mathbf{x}_{\\text{new}} = f_\\theta(\\mathbf{z}_{\\text{new}})\n",
        "    $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jntdH5Hj-CLo",
      "metadata": {
        "id": "jntdH5Hj-CLo"
      },
      "outputs": [],
      "source": [
        "# Interpolation with geodesic sampling\n",
        "def geodesic_interpolate(z1, z2, alpha):\n",
        "    omega = np.arccos(np.clip(np.dot(z1.T, z2)[0,0], -1, 1))\n",
        "    return (np.sin((1-alpha)*omega)/np.sin(omega))*z1 + (np.sin(alpha*omega)/np.sin(omega))*z2\n",
        "\n",
        "z_A = encoder.predict(X_train[0:1])\n",
        "z_B = encoder.predict(X_train[1:2])\n",
        "\n",
        "for alpha in np.linspace(0, 1, 5):\n",
        "    z_new = geodesic_interpolate(z_A, z_B, alpha)\n",
        "    J_new = decoder.predict(z_new)\n",
        "    J_original = scaler.inverse_transform(J_new)\n",
        "    print(f\"α={alpha:.1f}: Time={J_original[0,0]:.2f}s, Energy={J_original[0,1]:.2f}kWh\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16d24cc",
      "metadata": {
        "id": "b16d24cc"
      },
      "outputs": [],
      "source": [
        "# Interpolation with linear sampling\n",
        "\n",
        "# Encode two Pareto solutions\n",
        "z_A = encoder.predict(X_train[0:1])  # Solution A\n",
        "z_B = encoder.predict(X_train[1:2])  # Solution B\n",
        "\n",
        "# Linear interpolation\n",
        "alpha = 0.5\n",
        "z_new = alpha * z_A + (1 - alpha) * z_B\n",
        "\n",
        "# Decode to generate new solution\n",
        "J_new = decoder.predict(z_new)\n",
        "\n",
        "# Denormalize\n",
        "J_new_original = scaler.inverse_transform(J_new)\n",
        "print(f\"Interpolated Solution: Time = {J_new_original[0, 0]:.2f} s, Energy = {J_new_original[0, 1]:.2f} kWh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "r3W9yz2vBv9m"
      },
      "id": "r3W9yz2vBv9m"
    },
    {
      "cell_type": "code",
      "source": [
        "class MonocapOptimizer:\n",
        "    def __init__(self, vae_model):\n",
        "        self.model = vae_model\n",
        "        self.scaler = load_scaler()  # Trained data normalizer\n",
        "\n",
        "    def query(self, distance_km, time_preference=0.5, energy_preference=0.5):\n",
        "        # Normalize inputs\n",
        "        conditions = self.scaler.transform([\n",
        "            [distance_km, time_preference, energy_preference, 0.3]\n",
        "        ])\n",
        "\n",
        "        # Generate latent sample\n",
        "        z = torch.randn(1, 32)\n",
        "\n",
        "        # Decode with conditions\n",
        "        with torch.no_grad():\n",
        "            profile = self.model.decoder(torch.cat([\n",
        "                z,\n",
        "                torch.tensor(conditions, dtype=torch.float32)\n",
        "            ]))\n",
        "\n",
        "        # Post-process\n",
        "        return self._clamp_profile(profile.numpy())"
      ],
      "metadata": {
        "id": "5-DTmBXSB5_C"
      },
      "id": "5-DTmBXSB5_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = MonocapOptimizer(trained_vae)\n",
        "\n",
        "# Get minimum time solution for 10km\n",
        "fast_profile = optimizer.query(\n",
        "    distance_km=10,\n",
        "    time_preference=0.9,\n",
        "    energy_preference=0.1\n",
        ")\n",
        "\n",
        "# Get balanced solution for 15km\n",
        "balanced_profile = optimizer.query(\n",
        "    distance_km=15,\n",
        "    time_preference=0.5,\n",
        "    energy_preference=0.5\n",
        ")\n",
        "\n",
        "# Get energy-efficient solution for 20km\n",
        "efficient_profile = optimizer.query(\n",
        "    distance_km=20,\n",
        "    time_preference=0.2,\n",
        "    energy_preference=0.8\n",
        ")"
      ],
      "metadata": {
        "id": "KBm1B2H8Bvpz"
      },
      "id": "KBm1B2H8Bvpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "GaxxlDqA-d_q",
      "metadata": {
        "id": "GaxxlDqA-d_q"
      },
      "source": [
        "## Solution Validation Protocol\n",
        "\n",
        "### Dominance Verification\n",
        "$$\n",
        "\\mathbf{x}_{\\text{new}} \\text{ is non-dominated iff } \\nexists \\mathbf{x}_i \\in X :\n",
        "\\begin{cases}\n",
        "f_1^{(i)} \\leq f_1^{\\text{(new)}} \\\\\n",
        "f_2^{(i)} \\leq f_2^{\\text{(new)}} \\\\\n",
        "\\|\\mathbf{x}_i - \\mathbf{x}_{\\text{new}}\\|_2 > \\delta\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "### Feasibility Check\n",
        "$$\n",
        "\\mathbf{x}_{\\text{new}} \\in \\mathcal{F} \\iff\n",
        "\\begin{cases}\n",
        "g_1(\\mathbf{x}_{\\text{new}}) \\leq 0 \\\\\n",
        "g_2(\\mathbf{x}_{\\text{new}}) \\leq 0 \\\\\n",
        "\\vdots \\\\\n",
        "g_k(\\mathbf{x}_{\\text{new}}) \\leq 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Ensure:\n",
        "$$\n",
        "f_1^{new} \\geq 0, \\quad f_2^{new} \\geq 0\n",
        "$$\n",
        "And any problem-specific constraints (e.g., $g(\\mathbf{x}_{new}) \\leq 0$)\n",
        "\n",
        "### Check mapping back to decision space (acceleratio, decelereation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2qlcpfob9yai",
      "metadata": {
        "id": "2qlcpfob9yai"
      },
      "outputs": [],
      "source": [
        "# Create Pareto Validator class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "[1] [Autoencoder implementation in Pytorch](https://avandekleut.github.io/vae/)\n",
        "\n"
      ],
      "metadata": {
        "id": "0TceaapCtx05"
      },
      "id": "0TceaapCtx05"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}