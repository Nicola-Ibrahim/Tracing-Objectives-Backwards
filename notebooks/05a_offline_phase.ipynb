{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "BMotfZgYgP9h",
      "metadata": {
        "id": "BMotfZgYgP9h"
      },
      "source": [
        "# Autoencoder Formulation for Pareto Front Analysis\n",
        "\n",
        "Some of considerd limitations:\n",
        "1. Defining the optimal point (energy/time -> acceleration) at the beginning of the system. The user has the ability to select that.\n",
        "2. All data features should be taken into account, e.g. (Decision variables + problem parameters + objectives)\n",
        "\n",
        "\n",
        "Offline:\n",
        "1. Train CVAE on Pareto profiles & conditions $c_i$.\n",
        "2. For each training sample, compute anchor pairs:\n",
        "   $ (c_i, μ_i) $ ← Encoder $(x_i,c_i)$.\n",
        "3. Train conditional prior $f_ψ: c_i → μ_i$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "nqxWtmAw9qmU",
      "metadata": {
        "id": "nqxWtmAw9qmU"
      },
      "outputs": [],
      "source": [
        "# === Standard Library ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === PyTorch Core ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "# import torch.distributions\n",
        "\n",
        "# === PyTorch Utils / Vision ===\n",
        "# import torchvision\n",
        "\n",
        "# === Other Libraries ===\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Configuration ===\n",
        "torch.manual_seed(0)\n",
        "plt.rcParams[\"figure.dpi\"] = 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hr8T5ZsM-nCz",
      "metadata": {
        "id": "Hr8T5ZsM-nCz"
      },
      "source": [
        "## Date reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "Tp5dTiMflpDK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp5dTiMflpDK",
        "outputId": "7b9f3029-a08e-46b1-bdd2-53691060e227"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accel_ms2</th>\n",
              "      <th>decel_ms2</th>\n",
              "      <th>time_min</th>\n",
              "      <th>energy_kwh</th>\n",
              "      <th>weighted_time</th>\n",
              "      <th>weighted_energy</th>\n",
              "      <th>distance_km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>0.021956</td>\n",
              "      <td>0.868852</td>\n",
              "      <td>0.675099</td>\n",
              "      <td>0.654848</td>\n",
              "      <td>0.037219</td>\n",
              "      <td>0.962781</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>0.263490</td>\n",
              "      <td>0.990406</td>\n",
              "      <td>0.327851</td>\n",
              "      <td>0.340762</td>\n",
              "      <td>0.887128</td>\n",
              "      <td>0.112872</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>0.166521</td>\n",
              "      <td>0.986375</td>\n",
              "      <td>0.649817</td>\n",
              "      <td>0.663206</td>\n",
              "      <td>0.705583</td>\n",
              "      <td>0.294417</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>0.497278</td>\n",
              "      <td>0.996336</td>\n",
              "      <td>0.636558</td>\n",
              "      <td>0.671084</td>\n",
              "      <td>0.977346</td>\n",
              "      <td>0.022654</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>0.094652</td>\n",
              "      <td>0.908151</td>\n",
              "      <td>0.658117</td>\n",
              "      <td>0.660406</td>\n",
              "      <td>0.379313</td>\n",
              "      <td>0.620687</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.216862</td>\n",
              "      <td>0.865053</td>\n",
              "      <td>0.961821</td>\n",
              "      <td>0.990308</td>\n",
              "      <td>0.831446</td>\n",
              "      <td>0.168554</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.006263</td>\n",
              "      <td>0.982190</td>\n",
              "      <td>0.997049</td>\n",
              "      <td>0.978252</td>\n",
              "      <td>0.014206</td>\n",
              "      <td>0.985794</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.025989</td>\n",
              "      <td>0.865614</td>\n",
              "      <td>0.673712</td>\n",
              "      <td>0.655410</td>\n",
              "      <td>0.047202</td>\n",
              "      <td>0.952798</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0.094725</td>\n",
              "      <td>0.912358</td>\n",
              "      <td>0.026695</td>\n",
              "      <td>0.009812</td>\n",
              "      <td>0.381008</td>\n",
              "      <td>0.618992</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.475045</td>\n",
              "      <td>0.999299</td>\n",
              "      <td>0.952692</td>\n",
              "      <td>0.995598</td>\n",
              "      <td>0.972300</td>\n",
              "      <td>0.027700</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>640 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     accel_ms2  decel_ms2  time_min  energy_kwh  weighted_time  \\\n",
              "264   0.021956   0.868852  0.675099    0.654848       0.037219   \n",
              "615   0.263490   0.990406  0.327851    0.340762       0.887128   \n",
              "329   0.166521   0.986375  0.649817    0.663206       0.705583   \n",
              "342   0.497278   0.996336  0.636558    0.671084       0.977346   \n",
              "394   0.094652   0.908151  0.658117    0.660406       0.379313   \n",
              "..         ...        ...       ...         ...            ...   \n",
              "71    0.216862   0.865053  0.961821    0.990308       0.831446   \n",
              "106   0.006263   0.982190  0.997049    0.978252       0.014206   \n",
              "270   0.025989   0.865614  0.673712    0.655410       0.047202   \n",
              "435   0.094725   0.912358  0.026695    0.009812       0.381008   \n",
              "102   0.475045   0.999299  0.952692    0.995598       0.972300   \n",
              "\n",
              "     weighted_energy  distance_km  \n",
              "264         0.962781     0.666667  \n",
              "615         0.112872     0.333333  \n",
              "329         0.294417     0.666667  \n",
              "342         0.022654     0.666667  \n",
              "394         0.620687     0.666667  \n",
              "..               ...          ...  \n",
              "71          0.168554     1.000000  \n",
              "106         0.985794     1.000000  \n",
              "270         0.952798     0.666667  \n",
              "435         0.618992     0.000000  \n",
              "102         0.027700     1.000000  \n",
              "\n",
              "[640 rows x 7 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pareto_data = pd.read_pickle(\"../data/processed/pareto_data.pkl\")\n",
        "train_df = pd.DataFrame(pareto_data[\"train\"])\n",
        "test_df = pd.DataFrame(pareto_data[\"test\"])\n",
        "\n",
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HGrqXafj-W1n",
      "metadata": {
        "id": "HGrqXafj-W1n"
      },
      "source": [
        "## Conditional VAE Architecture\n",
        "\n",
        "### Why to use?\n",
        "In traditional autoencoders, inputs are mapped deterministically to a latent vector\n",
        "$z=e(x)$. In variational autoencoders, inputs are mapped to a probability distribution over latent vectors, and a latent vector is then sampled from that distribution. The decoder becomes more robust at decoding latent vectors as a result.\n",
        "\n",
        "### Variational Autoencoder (VAE) Latent Space Mapping\n",
        "\n",
        "                     Input Conditions\n",
        "                      (SOC, Distance,\n",
        "                      Velocity Profile)\n",
        "                           │\n",
        "                           ▼\n",
        "                ┌───────────────────────┐\n",
        "                │      Conditioner      │\n",
        "                │  (MLP Transformer)    │\n",
        "                └───────────────────────┘\n",
        "                           │\n",
        "                           ├──────────────────────┐\n",
        "                           ▼                      ▼\n",
        "                ┌───────────────────────┐ ┌───────────────────────┐\n",
        "                │       Encoder         │ │      Decoder          │\n",
        "                │  (q(z|x,c))           │ │  (p(x|z,c))           │\n",
        "                └───────────────────────┘ └───────────────────────┘\n",
        "                           │                      ▲\n",
        "                           └───────► z ◄─────────┘\n",
        "                                  Latent Space\n",
        "\n",
        "\n",
        "Instead of directly mapping the input **$ x $** to a latent vector **$ z = e(x) $**, we instead map it to:\n",
        "\n",
        "- **Mean vector**: **$ \\mu(x) $**\n",
        "- **Standard deviation vector**: **$ \\sigma(x) $**\n",
        "\n",
        "These parameters define a **diagonal Gaussian distribution** $ N(\\mu(x), \\sigma(x)) $, from which we sample the latent vector $ z $:\n",
        "\n",
        "$$\n",
        "z \\sim N(\\mu(x), \\sigma(x))\n",
        "$$\n",
        "\n",
        "This formulation allows the model to learn a probabilistic latent space representation where each input $ x $ defines its own distribution over latent codes rather than a single deterministic point.\n",
        "\n",
        "\n",
        "### 1. Problem Definition\n",
        "Let:\n",
        "- **x** ∈ ℝ² : Solution vector (time_min, energy_kwh)\n",
        "- **c** ∈ ℝ⁵ : Condition vector (SOC, distance, avg_velocity, max_accel, energy_weight, time_weight)\n",
        "- **z** ∈ ℝᴸ : Latent representation (L=8)\n",
        "\n",
        "### 2. Probabilistic Model\n",
        "**Objective**: Learn conditional distribution \n",
        "$$p_\\theta(x|z,c) \\quad \\text{where} \\quad z \\sim q_\\phi(z|x,c)$$\n",
        "\n",
        "**Evidence Lower Bound (ELBO)**:\n",
        "$$\n",
        "\\mathcal{L}(\\theta,\\phi;x,c) = \\mathbb{E}_{q_\\phi(z|x,c)}[\\log p_\\theta(x|z,c)] - \\beta D_{KL}(q_\\phi(z|x,c) \\| p(z))\n",
        "$$\n",
        "\n",
        " \n",
        "### Encoder Network (Compression)\n",
        "$$\n",
        "\\mathbf{z} = g_\\phi(\\mathbf{x}) = \\text{LeakyReLU}(\\mathbf{W}_2 \\cdot \\text{ELU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "### Decoder Network (Reconstruction)\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = f_\\theta(\\mathbf{z}) = \\text{Sigmoid}(\\mathbf{W}_4 \\cdot \\text{ELU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "**Dimensionality**:\n",
        "- Input/Output: $\\mathbb{R}^2$ (normalized objectives)\n",
        "- Latent space: $\\mathbb{R}^1$ (bottleneck)\n",
        "- Hidden layers: 32 neurons with ELU activation\n",
        "\n",
        "\n",
        "## Architecture\n",
        "Sigmoid ensures outputs stay in normalized $[0,1]$ range\n",
        "\n",
        "### Encoder\n",
        "Maps 2D Pareto solutions to a 1D latent space:\n",
        "$$\n",
        "\\mathbf{z} = \\text{Encoder}(\\mathbf{x}) = \\sigma(\\mathbf{W}_2 \\cdot \\text{ReLU}(\\mathbf{W}_1\\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\mathbf{W}_1 \\in \\mathbb{R}^{h \\times 2}$, $\\mathbf{W}_2 \\in \\mathbb{R}^{1 \\times h}$ are weight matrices\n",
        "- $\\mathbf{b}_1 \\in \\mathbb{R}^h$, $\\mathbf{b}_2 \\in \\mathbb{R}^1$ are bias terms\n",
        "- $h$ is hidden layer size\n",
        "- $\\sigma$ is sigmoid activation\n",
        "\n",
        "### Decoder\n",
        "Reconstructs solutions from latent space:\n",
        "$$\n",
        "\\hat{\\mathbf{x}} = \\text{Decoder}(\\mathbf{z}) = \\sigma(\\mathbf{W}_4 \\cdot \\text{ReLU}(\\mathbf{W}_3\\mathbf{z} + \\mathbf{b}_3) + \\mathbf{b}_4)\n",
        "$$\n",
        "\n",
        "With:\n",
        "- $\\mathbf{W}_3 \\in \\mathbb{R}^{h \\times 1}$, $\\mathbf{W}_4 \\in \\mathbb{R}^{2 \\times h}$\n",
        "- $\\mathbf{b}_3 \\in \\mathbb{R}^h$, $\\mathbf{b}_4 \\in \\mathbb{R}^2$\n",
        "\n",
        "\n",
        "### Activation function\n",
        "\n",
        "### Loss Function\n",
        "Mean Squared Error (MSE) reconstruction loss:\n",
        "$$\n",
        "\\mathcal{L}_{recon} = \\frac{1}{N}\\sum_{i=1}^N \\|\\mathbf{x}_i - \\hat{\\mathbf{x}}_i\\|^2_2\n",
        "$$\n",
        "\n",
        "## 1. Composite Loss Components\n",
        "The total optimization objective combines three critical elements:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{total} = \\mathcal{L}_{recon} + \\beta\\mathcal{L}_{KL} + \\mathcal{L}_{phys}\n",
        "$$\n",
        "\n",
        "#### 1.1 Weighted Reconstruction Loss\n",
        "Domain-prioritized MSE accounting for operational criticality:\n",
        "$$\n",
        "\\mathcal{L}_{recon} = \\frac{1}{N}\\sum_{i=1}^N \\left[w_t\\left(\\frac{\\hat{t}_i - t_i}{t_{max}}\\right)^2 + w_e\\left(\\frac{\\hat{e}_i - e_i}{e_{max}}\\right)^2\\right]\n",
        "$$\n",
        "\n",
        "| Parameter | Value | Rationale |\n",
        "|-----------|-------|-----------|\n",
        "| $w_t$     | 0.7   | Time minimization priority |\n",
        "| $w_e$     | 0.3   | Energy conservation importance |\n",
        "| $t_{max}$ | 120 min | Maximum allowable trip time |\n",
        "| $e_{max}$ | 10 kWh | Battery capacity limit |\n",
        "\n",
        "#### 1.2 KL Divergence Regularization\n",
        "Gaussian constraint for latent space organization:\n",
        "$$\n",
        "\\mathcal{L}_{KL} = \\frac{1}{2}\\sum_{j=1}^8 \\left[\\exp(\\log\\sigma_j^2) + \\mu_j^2 - 1 - \\log\\sigma_j^2\\right]\n",
        "$$\n",
        "\n",
        "#### 1.3 Physics-Informed Penalty\n",
        "Hard constraint enforcement through soft penalties:\n",
        "$$\n",
        "\\mathcal{L}_{phys} = \\lambda_1\\max(0, \\hat{e} - e_{max})^2 + \\lambda_2\\max(0, t_{min} - \\hat{t})^2\n",
        "$$\n",
        "\n",
        "| Constraint | Formula | Weight $\\lambda$ |\n",
        "|------------|---------|-------|\n",
        "| Energy Cap | $\\hat{e} \\leq 10\\text{kWh}$ | 1.5 |\n",
        "| Time Floor | $\\hat{t} \\geq \\frac{d}{v_{max}}$ | 0.8 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i2FwHEmrCkA1",
      "metadata": {
        "id": "i2FwHEmrCkA1"
      },
      "source": [
        "### Input features\n",
        "\n",
        "[\n",
        "    target_distance,        # Scalar (e.g., 7.5 km)\n",
        "    time_weight,            # 0.0 (min) ↔ 1.0 (max)\n",
        "    energy_weight,          # 0.0 (min) ↔ 1.0 (max)\n",
        "    constraints_vector      # [max_jerk, battery_limit, ...]\n",
        "]\n",
        "\n",
        "### Output Features\n",
        "[\n",
        "    acceleration_profile,   # Time-series (100 steps)\n",
        "    deceleration_profile    # Time-series (100 steps)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "SNpMGhcmCm34",
      "metadata": {
        "id": "SNpMGhcmCm34"
      },
      "outputs": [],
      "source": [
        "# # Example Training Batch\n",
        "# batch = {\n",
        "#     \"input_conditions\": torch.tensor(\n",
        "#         [\n",
        "#             # [distance, time_weight, energy_weight, max_jerk]\n",
        "#             [7.5, 0.9, 0.1, 0.3],  # Minimum time\n",
        "#             [10.0, 0.5, 0.5, 0.3],  # Balanced\n",
        "#             [15.0, 0.1, 0.9, 0.3],  # Minimum energy\n",
        "#         ],\n",
        "#         dtype=torch.float32,\n",
        "#     ),\n",
        "#     \"output_profiles\": torch.tensor(\n",
        "#         [\n",
        "#             # [accel_profile (100 steps), decel_profile (100 steps)]\n",
        "#             [0.8, 0.82, ..., 1.2, 0.5, 0.48, ..., 0.1],  # Aggressive accel\n",
        "#             [0.5, 0.52, ..., 0.6, 0.4, 0.38, ..., 0.2],  # Moderate\n",
        "#             [0.3, 0.31, ..., 0.4, 0.6, 0.62, ..., 0.8],  # Conservative\n",
        "#         ],\n",
        "#         dtype=torch.float32,\n",
        "#     ),\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XWIuq5uJDlVE",
      "metadata": {
        "id": "XWIuq5uJDlVE"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "loss = reconstruction_loss + α*physics_loss + β*constraint_penalty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5yU0xujtFFJl",
      "metadata": {
        "id": "5yU0xujtFFJl"
      },
      "source": [
        "### Training process\n",
        "Filter out the non-dominated solutions as resemble pareto front\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "4l1PS1uJXbVI",
      "metadata": {
        "id": "4l1PS1uJXbVI"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Tabular CVAE Encoder\n",
        "\n",
        "    Encodes a 4-dimensional feature vector (accel1, accel2, time, energy)\n",
        "    concatenated with a 5-dimensional condition vector\n",
        "    (current_speed, remaining_battery, distance_to_pass, energy_weight, time_weight)\n",
        "    into latent distribution parameters (mean and log-variance).\n",
        "\n",
        "    Architecture:\n",
        "    - Input layer: 9 -> 32\n",
        "    - Hidden layer: 32 -> 16\n",
        "    - Output heads: 16 -> latent_dim (for both mean and log-variance)\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input features (4)\n",
        "        condition_dim (int): Dimensionality of the condition vector (5)\n",
        "        latent_dim (int): Dimensionality of the latent space\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int = 4, condition_dim: int = 5, latent_dim: int = 8):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.condition_dim = condition_dim\n",
        "        hidden_dim1 = 32\n",
        "        hidden_dim2 = 16\n",
        "\n",
        "        # Shared MLP to extract latent statistics\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim + condition_dim, hidden_dim1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim1),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim2),\n",
        "        )\n",
        "        # Output layers for mean and log-variance\n",
        "        self.mu_layer = nn.Linear(hidden_dim2, latent_dim)\n",
        "        self.logvar_layer = nn.Linear(hidden_dim2, latent_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cond: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Feature tensor [batch_size, 4]\n",
        "            cond (Tensor): Condition tensor [batch_size, 5]\n",
        "\n",
        "        Returns:\n",
        "            mu (Tensor): Predicted latent means [batch_size, latent_dim]\n",
        "            logvar (Tensor): Predicted latent log-variances [batch_size, latent_dim]\n",
        "        \"\"\"\n",
        "        assert x.shape[1] == self.input_dim\n",
        "        assert cond.shape[1] == self.condition_dim\n",
        "        # concatenate features and conditions\n",
        "        h = torch.cat([x, cond], dim=1)\n",
        "        h = self.shared(h)\n",
        "        mu = self.mu_layer(h)\n",
        "        logvar = self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "        Tabular CVAE Decoder\n",
        "\n",
        "        Decodes a latent vector and 5-dimensional condition\n",
        "    to reconstruct the original 4-dimensional features.\n",
        "\n",
        "        Architecture:\n",
        "        - Input layer: latent_dim + 5 -> 16\n",
        "        - Hidden layer: 16 -> 32\n",
        "        - Output layer: 32 -> 4\n",
        "\n",
        "        Args:\n",
        "            latent_dim (int): Dimensionality of the latent space\n",
        "            condition_dim (int): Dimensionality of the condition vector (5)\n",
        "            output_dim (int): Dimensionality of reconstructed features (4)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, latent_dim: int = 8, condition_dim: int = 5, output_dim: int = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        hidden_dim1 = 16\n",
        "        hidden_dim2 = 32\n",
        "\n",
        "        self.decoder_net = nn.Sequential(\n",
        "            nn.Linear(latent_dim + condition_dim, hidden_dim1),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim1),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.BatchNorm1d(hidden_dim2),\n",
        "            nn.Linear(hidden_dim2, output_dim),\n",
        "        )\n",
        "        # initialize output layer for stability\n",
        "        nn.init.xavier_uniform_(self.decoder_net[-1].weight)\n",
        "        nn.init.zeros_(self.decoder_net[-1].bias)\n",
        "\n",
        "    def forward(self, z: torch.Tensor, cond: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            z (Tensor): Latent tensor [batch_size, latent_dim]\n",
        "            cond (Tensor): Condition tensor [batch_size, condition_dim]\n",
        "\n",
        "        Returns:\n",
        "            recon (Tensor): Reconstructed features [batch_size, output_dim]\n",
        "        \"\"\"\n",
        "        assert z.dim() == 2 and cond.dim() == 2\n",
        "        # concatenate latent and conditions\n",
        "        h = torch.cat([z, cond], dim=1)\n",
        "        recon = self.decoder_net(h)\n",
        "        return recon\n",
        "\n",
        "\n",
        "class PhysicsModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Model for Vehicle Dynamics and Constraints\n",
        "\n",
        "    This module computes physical metrics from acceleration profiles,\n",
        "    including energy consumption, travel time estimation, and jerk statistics.\n",
        "    It encapsulates fundamental equations of motion and resistive forces,\n",
        "    enabling integration into CVAE training and real-time inference pipelines.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuration dictionary with keys:\n",
        "            - vehicle_mass (float): Vehicle mass in kg\n",
        "            - air_density (float): Air density in kg/m^3\n",
        "            - drag_coeff (float): Aerodynamic drag coefficient\n",
        "            - rolling_res (float): Rolling resistance coefficient\n",
        "            - motor_eff (float): Motor efficiency (0 < eff <= 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "        # Vehicle physical parameters\n",
        "        self.vehicle_mass = config.get(\"vehicle_mass\", 1500.0)  # kg\n",
        "        self.air_density = config.get(\"air_density\", 1.225)  # kg/m^3\n",
        "        self.drag_coeff = config.get(\"drag_coeff\", 0.3)  # unitless\n",
        "        self.rolling_res = config.get(\"rolling_res\", 0.01)  # rolling resistance coeff\n",
        "        self.motor_eff = config.get(\"motor_eff\", 0.9)  # motor efficiency fraction\n",
        "\n",
        "    def calculate_energy(\n",
        "        self,\n",
        "        accel_profile: torch.Tensor,\n",
        "        time_profile: torch.Tensor,\n",
        "        remaining_battery: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute total energy consumption over a trip using an acceleration profile.\n",
        "\n",
        "        Args:\n",
        "            accel_profile (Tensor): [batch, time_steps] acceleration in m/s^2\n",
        "            time_profile (Tensor): [batch, time_steps] timestamps in seconds\n",
        "            remaining_battery (Tensor): [batch] current battery state-of-charge (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Tensor: energy used in kWh [batch]\n",
        "        \"\"\"\n",
        "        # Integrate acceleration to velocity\n",
        "        velocity = torch.cumsum(\n",
        "            accel_profile * (time_profile[:, 1] - time_profile[:, 0]), dim=1\n",
        "        )\n",
        "        # Compute resistive forces\n",
        "        drag_force = 0.5 * self.air_density * self.drag_coeff * velocity**2\n",
        "        rolling_force = self.rolling_res * self.vehicle_mass * 9.81\n",
        "        # Mechanical power: (mass*a + drag + rolling) * v\n",
        "        mech_power = (\n",
        "            self.vehicle_mass * accel_profile + drag_force + rolling_force\n",
        "        ) * velocity\n",
        "        # Account for motor efficiency: electrical power drawn\n",
        "        elec_power = mech_power / self.motor_eff\n",
        "        # Integrate power over time to get energy (Ws to Wh)\n",
        "        energy_Wh = torch.trapz(elec_power, time_profile, dim=1) / 3600.0\n",
        "        # Convert to kWh and clamp to remaining battery\n",
        "        return torch.clamp(energy_Wh / 1000.0, max=remaining_battery)\n",
        "\n",
        "    def calculate_jerk(\n",
        "        self, accel_profile: torch.Tensor, dt: float = 0.1\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Compute mean and maximum jerk (rate of change of acceleration).\n",
        "\n",
        "        Args:\n",
        "            accel_profile (Tensor): [batch, time_steps] acceleration in m/s^2\n",
        "            dt (float): time step between acceleration measurements\n",
        "\n",
        "        Returns:\n",
        "            mean_jerk (Tensor): mean absolute jerk [batch]\n",
        "            max_jerk (Tensor): maximum absolute jerk [batch]\n",
        "        \"\"\"\n",
        "        # Jerk: derivative of acceleration\n",
        "        jerk = (accel_profile[:, 1:] - accel_profile[:, :-1]) / dt\n",
        "        # Compute metrics\n",
        "        mean_jerk = torch.mean(torch.abs(jerk), dim=1)\n",
        "        max_jerk = torch.max(torch.abs(jerk), dim=1)\n",
        "        return mean_jerk, max_jerk\n",
        "\n",
        "    def forward(\n",
        "        self, profiles: torch.Tensor, conditions: torch.Tensor\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass: compute time, energy, average jerk, and max jerk.\n",
        "\n",
        "        Args:\n",
        "            profiles (Tensor): [batch, time_steps] acceleration profiles\n",
        "            conditions (Tensor): [batch, condition_dim] includes remaining_battery at idx 1\n",
        "\n",
        "        Returns:\n",
        "            time (Tensor): estimated travel time in seconds [batch]\n",
        "            energy (Tensor): energy consumption in kWh [batch]\n",
        "            mean_jerk (Tensor): mean absolute jerk [batch]\n",
        "            max_jerk (Tensor): maximum absolute jerk [batch]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = profiles.shape\n",
        "        # Create uniform time vector if not provided\n",
        "        dt = conditions.new_full((1,), 0.1).item()\n",
        "        t = torch.linspace(0.0, dt * (seq_len - 1), seq_len, device=profiles.device)\n",
        "        time_profile = t.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # Compute energy based on current battery\n",
        "        remaining_batt = conditions[:, 1]\n",
        "        energy = self.calculate_energy(profiles, time_profile, remaining_batt)\n",
        "\n",
        "        # Velocity integration for time estimation\n",
        "        velocity = torch.cumsum(profiles * dt, dim=1)\n",
        "        # Distance traveled\n",
        "        distance = torch.trapz(velocity, time_profile, dim=1)\n",
        "        # Time to cover distance: distance / avg speed\n",
        "        time_est = distance / (torch.mean(velocity, dim=1) + 1e-6)\n",
        "\n",
        "        # Compute jerk metrics\n",
        "        mean_jerk, max_jerk = self.calculate_jerk(profiles, dt)\n",
        "\n",
        "        return time_est, energy, mean_jerk, max_jerk\n",
        "\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Variational Autoencoder (CVAE) integrating a physics-based loss.\n",
        "\n",
        "    The CVAE learns a mapping from input acceleration profiles (tabular features)\n",
        "    and condition vectors (vehicle state and user preferences) to a latent space,\n",
        "    then reconstructs profiles via a conditional decoder.\n",
        "    Physics-informed constraints (time, energy, jerk) are incorporated into the loss\n",
        "    to enforce feasibility of generated profiles.\n",
        "\n",
        "    Components:\n",
        "    - Encoder: Produces μ and logσ² for qϕ(z|x,c)\n",
        "    - Reparameterizer: Samples z deterministically via z=μ+σ·ε\n",
        "    - Decoder: Generates reconstructed profiles pθ(x̂|z,c)\n",
        "    - PhysicsModel: Computes time, energy, and jerk for constraint losses\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuration with keys:\n",
        "            input_dim (int): Dimensionality of raw features (4)\n",
        "            latent_dim (int): Dimensionality of latent vector z\n",
        "            condition_dim (int): Dimensionality of condition vector (5)\n",
        "            device (str or torch.device): Compute device\n",
        "            max_jerk (float): Maximum allowable jerk for comfort\n",
        "            max_energy (float): Battery capacity (kWh)\n",
        "            max_time (float): Maximum allowable travel time (s)\n",
        "            base_time_weight (float): Base weight for time loss\n",
        "            base_energy_weight (float): Base weight for energy loss\n",
        "            base_jerk_weight (float): Base weight for jerk loss\n",
        "            adaptive_weighting (bool): Use dynamic weights from conditions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "        # Save config and device\n",
        "        self.device = torch.device(config.get(\"device\", \"cpu\"))\n",
        "\n",
        "        # Instantiate encoder, decoder, and physics model\n",
        "        self.encoder = Encoder(\n",
        "            input_dim=config[\"input_dim\"],\n",
        "            condition_dim=config.get(\"condition_dim\", 5),\n",
        "            latent_dim=config[\"latent_dim\"],\n",
        "        )\n",
        "        self.decoder = Decoder(\n",
        "            latent_dim=config[\"latent_dim\"],\n",
        "            condition_dim=config.get(\"condition_dim\", 5),\n",
        "            output_dim=config[\"input_dim\"],\n",
        "        )\n",
        "        self.physics_model = PhysicsModel(config)\n",
        "\n",
        "        # Physics/constraint parameters\n",
        "        self.max_jerk = config.get(\"max_jerk\", 2.5)\n",
        "        self.max_energy = config.get(\"max_energy\", 10.0)\n",
        "        self.max_time = config.get(\"max_time\", 120.0)\n",
        "\n",
        "        # Loss weights\n",
        "        self.adaptive = config.get(\"adaptive_weighting\", True)\n",
        "        self.base_time_w = config.get(\"base_time_weight\", 0.5)\n",
        "        self.base_energy_w = config.get(\"base_energy_weight\", 0.5)\n",
        "        self.base_jerk_w = config.get(\"base_jerk_weight\", 0.2)\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Apply the reparameterization trick to sample z ~ N(mu, sigma^2) in a differentiable way.\n",
        "\n",
        "        Args:\n",
        "            mu (Tensor): Mean of latent Gaussian [batch, latent_dim]\n",
        "            logvar (Tensor): Log-variance of latent Gaussian [batch, latent_dim]\n",
        "        Returns:\n",
        "            z (Tensor): Sampled latent vectors [batch, latent_dim]\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std, device=self.device)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cond: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass through CVAE: encode, sample, and decode.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Original feature profiles [batch, input_dim]\n",
        "            cond (Tensor): Condition vectors [batch, condition_dim]\n",
        "        Returns:\n",
        "            recon (Tensor): Reconstructed profiles [batch, input_dim]\n",
        "            mu (Tensor), logvar (Tensor): Latent distribution parameters\n",
        "        \"\"\"\n",
        "        # Encode to latent distribution parameters\n",
        "        mu, logvar = self.encoder(x, cond)\n",
        "        # Sample latent vectors via reparameterization\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        # Decode conditioned on z and conditions\n",
        "        recon = self.decoder(z, cond)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "    def loss(\n",
        "        self,\n",
        "        recon: torch.Tensor,\n",
        "        x: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "        cond: torch.Tensor,\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Compute the composite loss combining reconstruction, KL divergence,\n",
        "        and physics-based constraint penalties.\n",
        "\n",
        "        Steps:\n",
        "        1. Weighted MSE reconstruction loss based on time/energy weights\n",
        "        2. KL divergence term to regularize latent space\n",
        "        3. Physics model computes time, energy, jerk from recon\n",
        "        4. Compute huber losses for time and energy targets\n",
        "        5. Jerk penalty for exceeding comfort threshold\n",
        "\n",
        "        Args:\n",
        "            recon (Tensor): Decoded profiles [batch, input_dim]\n",
        "            x (Tensor): Original profiles [batch, input_dim]\n",
        "            mu, logvar (Tensor): Latent params [batch, latent_dim]\n",
        "            cond (Tensor): Conditions [batch, condition_dim]\n",
        "        Returns:\n",
        "            dict: {\"total\": Tensor, \"recon\":, \"kld\":, \"time\":, \"energy\":, \"jerk\":}\n",
        "        \"\"\"\n",
        "        # Extract dynamic weights if adaptive, else use base\n",
        "        tw = cond[:, -1] if self.adaptive else self.base_time_w\n",
        "        ew = cond[:, -2] if self.adaptive else self.base_energy_w\n",
        "\n",
        "        # Reconstruction loss (MSE) weighted by time and energy preferences\n",
        "        mse = F.mse_loss(recon, x, reduction=\"none\")  # [batch, features]\n",
        "        recon_loss = (mse * torch.stack([tw, ew, tw, ew], dim=1)).mean()\n",
        "\n",
        "        # KL divergence\n",
        "        kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "\n",
        "        # Physics-based metrics on reconstructions\n",
        "        time_pred, energy_pred, mean_jerk, max_jerk = self.physics_model(recon, cond)\n",
        "\n",
        "        # Targets: ideal time and energy based on conditions\n",
        "        speed, batt, dist, _, _ = cond.T\n",
        "        ideal_time = dist / (speed + 1e-6)\n",
        "        ideal_energy = batt * dist * 0.001  # placeholder conversion\n",
        "\n",
        "        time_loss = F.huber_loss(time_pred, ideal_time)\n",
        "        energy_loss = F.huber_loss(energy_pred, ideal_energy)\n",
        "        jerk_loss = F.relu(max_jerk - self.max_jerk).mean()\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = (\n",
        "            recon_loss\n",
        "            + kld\n",
        "            + tw.mean() * time_loss\n",
        "            + ew.mean() * energy_loss\n",
        "            + self.base_jerk_w * jerk_loss\n",
        "        )\n",
        "        return {\n",
        "            \"total\": total_loss,\n",
        "            \"recon\": recon_loss,\n",
        "            \"kld\": kld,\n",
        "            \"time\": time_loss,\n",
        "            \"energy\": energy_loss,\n",
        "            \"jerk\": jerk_loss,\n",
        "        }\n",
        "\n",
        "\n",
        "def train(model: nn.Module, dataloader, config: dict) -> None:\n",
        "    \"\"\"\n",
        "    Train a Conditional Variational Autoencoder (CVAE) model with physics-informed loss.\n",
        "\n",
        "    This routine runs the full training loop, including:\n",
        "      1. Moving the model to the specified device.\n",
        "      2. Iterating over epochs and batches.\n",
        "      3. Performing forward and backward passes.\n",
        "      4. Updating model parameters via AdamW.\n",
        "      5. Scheduling the learning rate based on validation loss.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The CVAE instance to train.\n",
        "        dataloader (DataLoader): Provides batches of dicts with keys:\n",
        "            - \"profile\": Tensor of shape [batch, input_dim]\n",
        "            - \"conditions\": Tensor of shape [batch, condition_dim]\n",
        "        config (dict): Training configuration with entries:\n",
        "            - \"device\": torch.device or string, e.g., \"cuda\" or \"cpu\"\n",
        "            - \"epochs\": int, total number of epochs\n",
        "            - \"lr\": float, initial learning rate\n",
        "            - \"weight_decay\": float, L2 regularization coefficient\n",
        "            - \"batch_size\": int, number of samples per batch\n",
        "            - \"scheduler_patience\": int, epochs to wait for LR plateau\n",
        "            - \"scheduler_factor\": float, LR reduction factor on plateau\n",
        "\n",
        "    Returns:\n",
        "        None: The function trains the model in place and prints progress.\n",
        "    \"\"\"\n",
        "    # Move model to the requested compute device\n",
        "    device = torch.device(config[\"device\"])\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Set up optimizer with weight decay for regularization\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config[\"lr\"],\n",
        "        weight_decay=config.get(\"weight_decay\", 1e-5),\n",
        "    )\n",
        "\n",
        "    # Reduce LR when total loss has plateaued\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        patience=config.get(\"scheduler_patience\", 5),\n",
        "        factor=config.get(\"scheduler_factor\", 0.5),\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, config[\"epochs\"] + 1):\n",
        "        epoch_loss = 0.0\n",
        "        progress = tqdm(dataloader, desc=f\"[Epoch {epoch}/{config['epochs']}]\")\n",
        "\n",
        "        for batch in progress:\n",
        "            # Unpack and move inputs to device\n",
        "            x = batch[\"profile\"].to(device)  # [batch, input_dim]\n",
        "            cond = batch[\"conditions\"].to(device)  # [batch, condition_dim]\n",
        "\n",
        "            # Zero gradients from previous step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through CVAE\n",
        "            recon, mu, logvar = model(x, cond)\n",
        "\n",
        "            # Compute all loss components\n",
        "            losses = model.loss_function(recon, x, mu, logvar, cond)\n",
        "\n",
        "            # Backward pass: gradients flow through reparameterization\n",
        "            losses[\"total\"].backward()\n",
        "\n",
        "            # Gradient clipping for stability\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Parameter update\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate and display per-batch loss\n",
        "            batch_loss = losses[\"total\"].item()\n",
        "            epoch_loss += batch_loss\n",
        "            progress.set_postfix(total_loss=batch_loss / x.size(0))\n",
        "\n",
        "        # Step the scheduler based on epoch’s total loss\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader.dataset)\n",
        "        print(f\"Epoch {epoch:>3}: Avg Loss = {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Utility to select the compute device.\n",
        "\n",
        "    Returns:\n",
        "        torch.device: 'cuda' if available, otherwise 'cpu'.\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "1431b8e8",
      "metadata": {
        "id": "1431b8e8"
      },
      "outputs": [],
      "source": [
        "def plot_latent(autoencoder, data, num_batches=100):\n",
        "    for i, (x, y) in enumerate(data):\n",
        "        z = autoencoder.encoder(x.to(get_device()))\n",
        "        z = z.to(\"cpu\").detach().numpy()\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap=\"tab10\")\n",
        "        if i > num_batches:\n",
        "            plt.colorbar()\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "KG2S6vOU98qu",
      "metadata": {
        "id": "KG2S6vOU98qu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Epoch 1/100]:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'ellipsis'>",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m dataloader = DataLoader(train_data, batch_size=config[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m], shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[32m     42\u001b[39m torch.save(cvae.state_dict(), \u001b[33m\"\u001b[39m\u001b[33mmonocap_cvae.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 457\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, config)\u001b[39m\n\u001b[32m    454\u001b[39m epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m    455\u001b[39m progress = tqdm(dataloader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Unpack and move inputs to device\u001b[39;49;00m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprofile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [batch, input_dim]\u001b[39;49;00m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconditions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# [batch, condition_dim]\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/proj/Pareto-Optimization-/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    232\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    233\u001b[39m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[32m    234\u001b[39m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[32m    235\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    236\u001b[39m                 collate(samples, collate_fn_map=collate_fn_map)\n\u001b[32m    237\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    238\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format.format(elem_type))\n",
            "\u001b[31mTypeError\u001b[39m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'ellipsis'>"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "# Configuration Example\n",
        "config = {\n",
        "    # —— Model dimensions ——————————————————————————————————\n",
        "    \"input_dim\": 200,  # length of accel+decel profile vector\n",
        "    \"output_dim\": 200,  # same as input_dim\n",
        "    \"latent_dim\": 32,  # size of z\n",
        "    \"condition_dim\": 5,  # number of condition features (e.g. [speed, soc, distance, energy_w, time_w])\n",
        "    # —— Training settings ——————————————————————————————\n",
        "    \"device\": get_device(),\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 64,\n",
        "    \"weight_decay\": 1e-5,  # for AdamW\n",
        "    \"beta\": 1.0,  # KLD annealing coefficient (if you use a β–VAE schedule)\n",
        "    \"adaptive_weighting\": True,  # enable condition‐driven time/energy weighting\n",
        "    # —— Physics & Constraint hyperparameters —————————————\n",
        "    \"max_jerk\": 2.5,  # m/s³ comfort threshold\n",
        "    \"max_energy\": 10.0,  # kWh battery capacity\n",
        "    \"max_time\": 120.0,  # minutes or seconds consistent with your loss\n",
        "    # —— Loss base weights (if not adaptive) —————————————\n",
        "    \"base_time_weight\": 0.5,\n",
        "    \"base_energy_weight\": 0.5,\n",
        "    \"base_jerk_weight\": 0.2,\n",
        "    # —— Scheduler & Seed ——————————————————————————————\n",
        "    \"seed\": 42,  # reproducibility\n",
        "    \"scheduler_patience\": 5,  # for ReduceLROnPlateau\n",
        "    \"scheduler_factor\": 0.5,  # LR reduction factor\n",
        "}\n",
        "\n",
        "cvae = CVAE(config)\n",
        "\n",
        "# Create synthetic dataset\n",
        "train_data = [...]  # Implement proper Dataset class\n",
        "dataloader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "# Train model\n",
        "train(cvae, dataloader, config)\n",
        "\n",
        "# Save model\n",
        "torch.save(cvae.state_dict(), \"monocap_cvae.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GKt8rSalw_j3",
      "metadata": {
        "id": "GKt8rSalw_j3"
      },
      "source": [
        "## Visualize latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PHvc2W0oxGOa",
      "metadata": {
        "id": "PHvc2W0oxGOa"
      },
      "outputs": [],
      "source": [
        "def plot_latent(autoencoder, data, num_batches=100):\n",
        "    for i, (x, y) in enumerate(data):\n",
        "        z = autoencoder.encoder(x.to(get_device()))\n",
        "        z = z.to(\"cpu\").detach().numpy()\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap=\"tab10\")\n",
        "        if i > num_batches:\n",
        "            plt.colorbar()\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c47fae3",
      "metadata": {},
      "source": [
        "## Anchor Extraction & Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7786a9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AnchorBuilder:\n",
        "    def __init__(self, cvae: CVAE, dataset: Dataset):\n",
        "        self.cvae = cvae.eval()\n",
        "        self.dataset = dataset\n",
        "        self.anchors = []  # list of (cond, mu)\n",
        "\n",
        "    def build(self, device=\"cpu\"):\n",
        "        for batch in DataLoader(self.dataset, batch_size=64):\n",
        "            x = batch[\"profile\"].to(device)\n",
        "            c = batch[\"conditions\"].to(device)\n",
        "            with torch.no_grad():\n",
        "                mu, _ = self.cvae.encoder(x, c)\n",
        "            for cond_vec, mu_vec in zip(c.cpu().numpy(), mu.cpu().numpy()):\n",
        "                self.anchors.append((cond_vec, mu_vec))\n",
        "        # Save anchors to disk for reuse\n",
        "        np.save(\"anchors.npy\", self.anchors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70730bee",
      "metadata": {},
      "source": [
        "## KD-Tree for Fast NN Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b671ffa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "\n",
        "class ConditionIndex:\n",
        "    def __init__(self, anchors_path=\"anchors.npy\"):\n",
        "        self.anchors = np.load(anchors_path, allow_pickle=True)\n",
        "        conds = np.stack([a[0] for a in self.anchors])\n",
        "        self.tree = KDTree(conds)  # leaf_size defaults to 40\n",
        "\n",
        "    def query(self, c_new, k=3):\n",
        "        dists, idxs = self.tree.query([c_new], k=k)\n",
        "        return [(self.anchors[i][1], dists[0][j]) for j, i in enumerate(idxs[0])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d1ad84",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalPrior(nn.Module):\n",
        "    \"\"\"Train a lightweight MLP to predict encoder means directly from conditions, avoiding NN lookups\"\"\"\n",
        "\n",
        "    def __init__(self, condition_dim, latent_dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(condition_dim, hidden), nn.ReLU(), nn.Linear(hidden, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, c):\n",
        "        return self.net(c)\n",
        "\n",
        "\n",
        "prior = ConditionalPrior(cond_dim, latent_dim).to(device)\n",
        "opt = torch.optim.Adam(prior.parameters(), lr=1e-3)\n",
        "for epoch in range(50):\n",
        "    for cond_vec, mu_vec in DataLoader(anchors_dataset, batch_size=64):\n",
        "        pred = prior(cond_vec.to(device))\n",
        "        loss = F.mse_loss(pred, mu_vec.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0TceaapCtx05",
      "metadata": {
        "id": "0TceaapCtx05"
      },
      "source": [
        "# Resources\n",
        "\n",
        "- [1] [Autoencoder implementation in Pytorch](https://avandekleut.github.io/vae/)\n",
        "- [2] [Deep dive into Conditional VAE](https://beckham.nz/2023/04/27/conditional-vaes.html?utm_source=chatgpt.com#sec_derivation)\n",
        "- [3] [How to implement conditional VAE](https://www.linkedin.com/advice/1/how-do-you-implement-conditional-vae-what-benefits?utm_source=chatgpt.com)\n",
        "- [4] [What about the conditional variational autoencoder?](https://creatis-myriad.github.io/tutorials/2022-09-12-tutorial-cvae.html?utm_source=chatgpt.com)\n",
        "\n",
        "- [5] [Youtub : Variational Auto Encoder (VAE) - Theory](https://www.youtube.com/watch?v=vJo7hiMxbQ8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pareto-optimization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
