%-------------------------------------------------------------------------------
% Introduction
%-------------------------------------------------------------------------------

\chapter{Introduction}

Real-world decision making involves navigating a web of trade-offs. In many
signal-processing and systems contexts—filter design, beamforming, detection,
compression, sensing—practitioners must balance several objectives that often
conflict. This is the remit of multi-objective optimisation (MOO), where
multiple goals are considered simultaneously rather than collapsed into a
single metric~\cite{Tan2023}. Unlike single-objective optimisation, MOO
typically yields a \emph{set of trade-off designs} in both decision and
objective spaces, from which a decision maker must choose according to
preferences and constraints.

The prevailing workflow in MOO is \emph{forward} mapping: given a decision
vector $\vect{x}\in\calX$ of design variables, one evaluates the objective
functions $\vect{f}(\vect{x})$ and uses evolutionary or surrogate-assisted
algorithms to explore attainable trade-offs~\cite{Liu2024}. This mirrors how
simulation models are defined: software implements a complex physics-based or
data-driven map from inputs to outputs. When a designer wishes to understand
how a variable affects performance, they perturb $\vect{x}$ and observe the
change in $\vect{y}$. However, a complementary question frequently arises in
practice: given a desired pattern of objective values $\vect{y}^{\star}$—for
example, a particular combination of resolution and denoising strength in a
medical image—what decision vector $\vect{x}^{\star}$ will realise it? This
\emph{inverse} mapping from objectives to decisions is often ill-posed:
multiple decisions may yield similar outcomes, and some targets may be
unattainable. Common workarounds such as scalarisation or trial-and-error can
be computationally expensive and provide limited insight into the inverse
relationship.

This thesis addresses the inverse decision-mapping problem in multi-objective
settings. The key idea is to learn a data-driven mapping
$\hat{g}\colon \calY \to \calX$ from representative examples of decisions and
their corresponding outcomes. At query time, a user specifies
$\vect{y}^{\star}$; the model proposes candidate $\vect{x}$ values intended to
realise $\vect{y}^{\star}$, which are then refined through a forward
evaluation step. By shifting computation into model construction, the approach
enables responsive, interactive exploration of complex design spaces.

In addressing these challenges, we consider both deterministic and probabilistic modelling strategies. Deterministic models aim to produce a single representative decision for a given target and are typically stabilised through regularisation to handle ill-posedness. Probabilistic models instead represent uncertainty explicitly by learning distributions over decisions (or functions), yielding predictive variability that can better capture multi-valued relationships. Taken together, these perspectives provide complementary tools for inverse exploration: deterministic methods emphasise parsimony and speed, while probabilistic methods quantify uncertainty and support diversity in candidate solutions. 


\section{Contributions}

The contributions of this thesis are as follows:

\begin{itemize}
  \item \textbf{Problem formulation.} We formally define the inverse decision
  mapping problem in the context of MOO and highlight its ill‑posed
  nature.  Building on recent work in Pareto estimation and inverse
  machine learning~\cite{Tan2023}, we specify conditions under
  which a target objective vector is admissible and propose criteria for
  assessing the quality of inverse solutions.

  \item \textbf{Comprehensive background.} A detailed survey of
  multi‑objective optimisation methods, performance indicators and
  surrogate‑assisted algorithms is presented.  We review evolutionary
  algorithms, decomposition techniques and quality indicators such as
  generational distance and hypervolume~\cite{Blank2020}.  We
  further survey inverse modelling approaches, including radial basis
  function networks, Gaussian processes and transfer learning methods
  that map objective vectors back to decision space~\cite{Liu2024}.

  \item \textbf{Modular framework.} We design a modular methodology with
  offline and online phases.  In the offline phase an existing MOO
  algorithm approximates the Pareto front, and a surrogate inverse model is
  trained.  In the online phase the user queries the model with a target
  objective vector, a plausibility check determines proximity to the Pareto
  region and candidate decisions are produced and validated.  The framework
  accommodates different surrogate models and incorporates ranking metrics
  to guide the user.

  \item \textbf{Implementation and prototype.} A reproducible software
  prototype is implemented, including routines for data generation, normal-
  isation, model training, hyperparameter optimisation, interactive
  visualisation and ranking.  The code is modular, making it easy to plug
  in alternative surrogate models or optimisation backends.

  \item \textbf{Empirical evaluation.} Extensive experiments on synthetic
  benchmark functions and a real‑world case study demonstrate that the
  learned inverse models yield decision vectors close to the true Pareto
  set.  We compare Gaussian processes, radial basis functions and
  neural networks under varying training set sizes and analyse trade‑offs
  between accuracy and computation time.  Results indicate that the
  proposed framework significantly reduces the number of forward evaluations
  required to identify satisfactory solutions.

\end{itemize}

\section{Structure of the Thesis}

The remainder of this thesis is organised as follows.  Chapter~\ref{chap:motivation}
provides background on multi‑objective optimisation, introduces definitions of
dominance and Pareto optimality, reviews key algorithms and metrics, and
motivates the need for inverse mapping.  Chapter~\ref{chap:related}
surveys related work on inverse modelling, surrogate‑assisted optimisation,
transfer learning and interactive decision support.  Chapter~\ref{chap:problem}
formalises the inverse decision mapping problem, introduces feasibility and
quality criteria and poses research questions.  Chapter~\ref{chap:method}
describes the proposed methodology in detail, including data generation,
surrogate training and online exploration.  Chapter~\ref{chap:implementation}
presents implementation details and algorithmic components.  Chapter~\ref{chap:experiments}
contains experimental results on synthetic and real problems.  Chapter
\ref{chap:discussion} discusses the insights gained from the experiments and
outlines limitations.  Finally, Chapter~\ref{chap:conclusion} concludes the
thesis and proposes future directions.