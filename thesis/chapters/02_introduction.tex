%-------------------------------------------------------------------------------
% Introduction
%-------------------------------------------------------------------------------

\chapter{Introduction}

Real-world decision making involves navigating a web of trade-offs. In many
signal-processing and systems contexts—filter design, beamforming, detection,
compression, and sensing—practitioners must balance several objectives that
often conflict. This is the remit of multi-objective optimisation (MOO), where
multiple goals are considered simultaneously rather than collapsed into a
single metric~\cite{Tan2023}. Unlike single-objective optimisation, MOO
typically yields a \emph{set of trade-off designs} in both decision and
objective spaces, from which a decision maker must choose according to
preferences and constraints. For a broad overview of MOO concepts and
state-of-the-art algorithmic families, see Deb’s classic introduction and
more recent tutorials.

A natural way to analyse such problems is through the \emph{forward} process:
a model maps hidden or controllable parameters $\vect{x}$ (decisions) to
measurable or evaluable quantities $\vect{y}$ (objectives), reflecting how
simulation tools are usually specified. In many applications the forward map
is well understood, but the complementary \emph{inverse} task—inferring
$\vect{x}$ from a desired pattern of objective values $\vect{y}^\star$—is
substantially harder. Information is typically lost in the forward direction,
so the inverse problem can violate one or more of Hadamard’s criteria
(existence, uniqueness, stability), i.e., it is \emph{ill-posed}; different
decisions may yield indistinguishable outcomes, and small perturbations in
data can lead to large changes in inferred parameters. Regularisation and
statistical formulations are therefore required to make inference meaningful
and robust~\cite{KabanikhinSurvey,BenningBurger2018,Stuart2010}.

From a design perspective, the limitations of purely forward workflows are
well known. When engineers wish to realise a particular objective pattern
(e.g., a specified error–rate profile, resolution–noise compromise, or
spectral mask), they must repeatedly perturb $\vect{x}$ and re-evaluate the
forward model, or they resort to scalarisation tricks that can be sensitive to
weights and may miss diverse solutions. Such procedures are compute-intensive
and offer limited insight into the \emph{structure} of the inverse map,
especially when many distinct decisions produce similar outcomes. In practice,
useful inverse exploration should: (i) acknowledge that solutions may be
non-unique and sometimes unattainable; (ii) expose families of viable designs
rather than a single point; and (iii) integrate smoothly with forward
evaluation when refinement is needed.

\begin{figure}[t]
  \centering
  \input{figures/inverse_mapper_figure}
  \caption{Forward vs.\ inverse viewpoint. Forward mapping evaluates how decisions $\vect{x}$ produce outcomes $\vect{y}$; the inverse task seeks decisions that realise a desired outcome pattern.}
  \label{fig:forward-inverse}
\end{figure}

This thesis addresses the inverse decision–mapping problem in multi-objective
settings. The central idea is to learn a data-driven mapping
$\hat{g}\colon \calY \to \calX$ from representative examples of decisions and
their corresponding outcomes. At query time, a user specifies a desired
objective pattern $\vect{y}^{\star}$; the model proposes candidate $\vect{x}$
values intended to realise $\vect{y}^{\star}$, which can then be verified or
fine-tuned through a forward evaluation step. By shifting effort into model
construction, the workflow enables responsive, interactive exploration of
complex design spaces while remaining agnostic to the source of examples
(e.g., historical runs, prior designs, or samples obtained by exploratory
optimisation).

In addressing these challenges, we consider both deterministic and
probabilistic modelling strategies as complementary tools for inverse
exploration. Deterministic models aim to produce a single representative
decision for a given target, often aided by regularisation to counteract
ill-posedness and to encourage stable, interpretable mappings. They are
appealing when fast, repeatable proposals are required. Probabilistic models,
in contrast, represent uncertainty explicitly by learning distributions over
decisions (or functions). This yields predictive variability that can capture
multi-valued relationships between decisions and objectives, quantify
ambiguity due to noise or limited data, and support diversity in candidate
solutions. In the broader literature, probabilistic formulations (e.g., Bayesian perspectives on inverse problems) provide a principled language for reasoning about non-uniqueness and data
uncertainty, while modern regularisation connects statistical and variational
viewpoints~\cite{Stuart2010,BenningBurger2018}.

Inverse questions arise naturally across signal-processing tasks. In filter
design, engineers may target a specific passband/stopband pattern subject to
resource limits and then seek parameterisations that realise it. In adaptive
beamforming, one might prescribe mainlobe width and sidelobe levels compatible
with interference constraints and search for array weights that achieve these
objectives. In compression, a target operating point in the rate–distortion
plane motivates encoders and transforms that satisfy both fidelity and bitrate
budget. In detection and estimation, practitioners often work backward from
desired receiver operating characteristics to decision rules and system
settings. These scenarios share the same core difficulty: the forward map is
easier to evaluate, whereas the inverse map can be ambiguous or unstable, so
algorithms that \emph{learn to invert} from data are attractive.

% ------------------------------------------------------------------
\section{Problem statement and purpose}

\textbf{Problem.} Given representative examples $\{(\vect{x}_i,\vect{y}_i)\}$ from a multi-objective system with forward map $\vect{f}\!:\calX\!\to\!\calY$, learn a mapping that, for any user-specified target $\vect{y}^\star$, proposes one or more decisions in $\calX$ whose forward evaluations are close to $\vect{y}^\star$ under task-relevant distances. The inverse mapping is generally ill-posed (non-unique and sometimes unattainable).

\textbf{Purpose.} Develop and assess a principled, data-driven approach for inverse decision mapping that is transparent, reproducible, and suitable for interactive use in signal-processing contexts. The goal is to produce target-consistent decisions with minimal extra tuning and clear, application-aligned evaluation.

% ------------------------------------------------------------------
\section{Research questions}

\begin{enumerate}
  \item \textit{Inverse querying.} How can a new target $\mathbf{y}^{\ast}$ be translated into a concrete decision $\widehat{\mathbf{x}}$ using available examples and simulations?
  \item \textit{Quality of generated decisions.} How should the quality of $\widehat{\mathbf{x}}$ be established with respect to $\mathbf{y}^{\ast}$ using forward evaluations or feedback, in a way that is clear and reproducible?
  \item \textit{Modelling strategies.} Which strategies most effectively learn the mapping from outcomes to decisions, and under what data and problem conditions do they generalise?
\end{enumerate}

% ------------------------------------------------------------------
\section{Significance}

A robust inverse-mapping capability reduces dependence on repeated forward search and enables real-time, user-driven exploration of multi-objective trade-offs. In signal-processing applications, this can shorten design cycles, improve transparency around feasible targets, and support collaborative decision making where stakeholders negotiate acceptable compromises.

% ------------------------------------------------------------------
\section{Assumptions, limitations, and delimitations}

We assume access to representative pairs $(\vect{x},\vect{y})$ and that local regularity of $\vect{f}$ allows learning an inverse that generalises within the observed outcome region. We evaluate inverse quality in outcome space (e.g., Euclidean or Mahalanobis distance) and treat feasibility via simple constraint handling where relevant. Limitations include potential distribution shift between training data and user queries, the intrinsic one-to-many nature of inverse solutions, and reliance on a forward check or surrogate for verification in some experiments. We delimit scope to two-objective synthetic benchmarks and a two-objective real case, with methods designed to extend beyond these settings.

% ------------------------------------------------------------------
\section{Methodological overview}

The study follows a two-stage design. First, assemble and normalise representative $(\vect{x},\vect{y})$ examples; fit inverse models that map $\calY\!\to\!\calX$ and encourage forward-consistency so that $\vect{f}(\hat{g}(\vect{y}))$ tracks $\vect{y}$. Second, at query time, translate $\vect{y}^\star$ into one or more candidate decisions via a selection policy (point estimate or samples), and optionally verify/refine with a forward predictor or simulator. Evaluation reports outcome-space discrepancy and tolerance-based success, with secondary diagnostics as needed.

% ------------------------------------------------------------------
\section{Contributions}

\begin{itemize}
  \item \textbf{Problem formulation.} We formalise inverse decision mapping in multi-objective
  settings, treating the inverse as an ill-posed inference task in the sense of Hadamard
  (non-uniqueness, instability, possible non-existence). This framing clarifies when targets
  may be unattainable or ambiguous and motivates regularisation/statistical treatments for
  meaningful reconstruction of decisions from desired outcomes. \cite{KabanikhinSurvey}

  \item \textbf{Comprehensive background.} We survey core concepts in multi-objective
  optimisation (problem structures, algorithmic families, and performance assessment)
  and review inverse-problem perspectives that inform stable learning of inverse maps.
  The survey integrates established MOO tutorials and modern views on regularisation and
  Bayesian inference for inverse problems. \cite{BenningBurger2018,Stuart2010}

  \item \textbf{General modelling approach.} We propose a data-driven approach to inverse
  exploration that learns a mapping $\hat{g}\colon\mathcal{Y}\!\to\!\mathcal{X}$ from representative
  examples (e.g., prior designs, historical runs, or exploratory evaluations). At query time,
  the method returns candidate decisions aligned with a user-specified objective pattern,
  with optional forward evaluation for verification/refinement. The approach is agnostic to
  how examples are obtained and does not rely on a specific optimisation paradigm.

  \item \textbf{Deterministic and probabilistic models.} We develop and compare deterministic
  and probabilistic strategies for inverse exploration. Deterministic models emphasise
  parsimony and speed, using regularisation to counteract ill-posedness; probabilistic models
  represent distributions over decisions to expose uncertainty and multi-valued relationships.
  We highlight when each perspective is advantageous and how they can be combined in practice.

  \item \textbf{Empirical evaluation.} Experiments on synthetic benchmarks and a real-world
  case study show that learned inverse mappings can recover decision candidates that match
  desired objective patterns while substantially reducing the number of forward evaluations
  compared with repeated forward search. We analyse accuracy–effort trade-offs and compare
  models across training-set sizes.
\end{itemize}

% ------------------------------------------------------------------
\section{Structure of the Thesis}

The remainder of this thesis is organised as follows.

Chapter~\ref{chap:motivation} provides background on multi-objective
optimisation and inverse problems: it introduces core MOO concepts and
performance assessment at a high level, reviews Hadamard’s well-posedness
criteria and why inverse mappings are often ill-posed, and motivates a
data-driven inverse viewpoint for design.

Chapter~\ref{chap:related} surveys related work on learning inverse mappings
from examples, including modelling strategies,
surrogate-assisted and model-based approaches, and interactive decision support
systems. Emphasis is placed on methods that are agnostic to data sources and
optimisation paradigms.

Chapter~\ref{chap:problem} formalises the inverse decision-mapping problem,
clarifies assumptions (identifiability, stability), and states the research
questions and evaluation criteria used throughout the thesis.

Chapter~\ref{chap:method} presents the proposed approach for inverse
exploration. We describe how representative \((\vect{x},\vect{y})\) examples
can be collected from historical runs, simulations, or exploratory evaluations;
how a mapping \(\hat{g}\colon \mathcal{Y}\!\to\!\mathcal{X}\) is learned; and how
query-time proposals are generated and optionally verified by forward
evaluation—without committing to a specific optimisation family.

Chapter~\ref{chap:implementation} outlines practical aspects of the reference
implementation used for experiments (data handling, model training/selection,
querying, and visual diagnostics), with an emphasis on modular components.

Chapter~\ref{chap:experiments} reports results on synthetic benchmarks and a
real-world case study, comparing deterministic and probabilistic inverse
models, analysing accuracy–effort trade-offs, and quantifying reductions in
forward evaluations relative to repeated forward search.

Chapter~\ref{chap:discussion} synthesises the empirical findings, discusses
limitations and threats to validity, and reflects on when each modelling
perspective is advantageous. Finally, Chapter~\ref{chap:conclusion} concludes
and outlines avenues for future work.
