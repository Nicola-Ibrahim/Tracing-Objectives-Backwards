%-------------------------------------------------------------------------------
% Related work
%-------------------------------------------------------------------------------

\chapter{Related Work}\label{chap:related}


This chapter reviews research that tackles the reverse direction of design: starting from a desired pattern of objectives and reasoning back to actionable decision suggestions. We organise the discussion around approaches that embed inverse reasoning within evolutionary search, learn inverse surrogates from data for post-hoc or interactive use, adopt probabilistic or generative views to reflect non-uniqueness and uncertainty, and formalise inverse multi-objective inference to address robustness and identifiability. The goal is to clarify the assumptions these works make about data, feasibility, and uncertainty, and to distil what kind of guidance they ultimately offer to a practitioner who sets targets and seeks viable designs.

Early EMO methods relied purely on genetic mechanisms—mutation, crossover, and selection—applied directly in decision space. As engineering problems grew in complexity and evaluation costs increased, model-based approaches emerged. A useful taxonomy distinguishes estimation-of-distribution algorithms, surrogate (forward) modelling, and inverse modelling, the last of which learns a map from the objective space to the decision space~\cite{Gholamnezhad2022}. Inverse modelling \emph{inside} the optimisation loop is exemplified by the IM-MOEA family, where a probabilistic inverse map is trained on nondominated solutions so that new candidates can be generated by proposing target objectives and predicting corresponding decisions~\cite{Farias2024}. Extensions incorporate decomposition and clustering to handle many objectives (IM-MOEA/D), replace the Gaussian process with a random forest regressor, add external archives and biased reproduction, and treat constraints (IM-C-MOEA/D)~\cite{Farias2024,Gholamnezhad2022}. These methods demonstrate that inverse modelling can maintain solution quality while reducing the number of forward evaluations during search, though they remain tied to a population-based, iterative algorithm.

A complementary direction learns inverse surrogates \emph{offline} for post-hoc and interactive use. Here, a regressor (e.g., Gaussian process or random forest) is trained to predict decisions from objectives using data collected once—via historical runs or an initial optimisation—after which users can query new target outcomes without re-running an EMO~\cite{Gholamnezhad2022}. Transfer learning strengthens this idea in small-data regimes: by learning across common objective spaces, inverse models can generalise to new tasks with limited fresh data~\cite{Tan2023}. This offline stance aligns with the goal of real-time, user-driven exploration adopted in the present thesis: train once, then answer inverse queries interactively, verifying with a forward model when needed.

Inverse multi-objective optimisation (IMOP) in operations research studies a different inverse question: inferring the parameters of the objective functions themselves from observed optimal decisions. Recent work formulates distributionally robust IMOP using Wasserstein ambiguity sets, providing finite-sample guarantees and robustness to misspecification~\cite{Dong2021}. While IMOP does not directly produce decisions from target objectives, it offers theoretical guidance on inverse inference under uncertainty and motivates robustness in data-limited settings.

Beyond deterministic regressors, probabilistic and deep generative approaches address the intrinsic multi-valued nature of inverse mappings. Mean-squared error training drives point predictors toward conditional averages that may be physically invalid when multiple designs achieve the same objectives. Mixture-based predictors and conditional generative models instead learn a full conditional distribution over decisions given objectives, supporting multimodality, uncertainty quantification, and sampling of diverse candidates. Tandem forward–inverse training in applications such as nanophotonic design shows that validating each inverse proposal with a forward model mitigates non-uniqueness and stabilises learning; conditional generative models in materials science likewise produce diverse, target-consistent candidates once trained. Despite higher training costs and data demands, these methods provide calibrated uncertainty and controllable diversity that are valuable for inverse design.

In summary, inverse-in-loop EMO reduces evaluations during optimisation but remains coupled to a population and iteration budget; offline inverse surrogates enable interactive, post-hoc exploration provided they are validated against forward models and handle feasibility explicitly; and probabilistic/generative methods contribute principled uncertainty and diversity at greater training cost. The thesis adopts the offline, interactive path: learn an inverse model from an initial optimisation run, expose it for real-time inverse queries, and close the loop with feasibility checks and forward-model validation, thereby bridging optimisation-centric inverse modelling and user-centric decision support.
