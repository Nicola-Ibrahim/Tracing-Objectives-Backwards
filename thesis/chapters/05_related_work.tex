%-------------------------------------------------------------------------------
% Related work
%-------------------------------------------------------------------------------

\chapter{Related Work}\label{chap:related}

The inverse decision mapping problem sits at the intersection of several
research areas, including evolutionary multi‑objective optimisation, surrogate
modelling, inverse multi‑objective algorithms and inverse optimisation in
operations research.  This chapter reviews prior work in these domains to
highlight the context for the thesis and to motivate the proposed framework.

\section{Model‑Based Evolutionary Algorithms}

Early evolutionary algorithms for multi‑objective optimisation relied purely
on genetic search mechanisms such as mutation, crossover and selection.  With
the growing complexity of engineering problems and the high cost of
function evaluations, model‑based approaches emerged.  Gholamnezhad
et~al. classify model‑based multi‑objective evolutionary algorithms into
three groups: estimation of distribution algorithms, inverse modelling
algorithms and surrogate modelling algorithms~\cite{Gholamnezhad2022}.  Estimation
of distribution algorithms build probabilistic models of the decision
variables and sample new solutions; surrogate‑based algorithms learn
forward models of the objective functions to reduce evaluations; and
inverse modelling algorithms learn mappings from the objective space
to the decision space.  While the first two categories have been widely
studied, inverse modelling has received increasing attention only in
recent years.

\section{Inverse Evolutionary Algorithms}

The Inverse Model‑Based Multi‑Objective Evolutionary Algorithm (IM‑MOEA)
introduced by Cheng et~al. couples evolutionary search with a Gaussian
process inverse model to sample candidate solutions directly in the
objective space~\cite{Farias2024}.  The key idea is to construct a
probabilistic mapping from objective values to decision variables based on
previously generated non‑dominated solutions and then use this mapping to
guide variation operators.  This approach reduces the reliance on population
diversity and encourages exploration of sparsely sampled regions.  Since
its proposal, several extensions have been developed.  IM‑MOEA/D
incorporates decomposition and clustering strategies to handle many
objectives~\cite{Farias2024}; IM‑MOEA‑RF replaces the Gaussian process with a random forest regressor~\cite{Gholamnezhad2022}; E‑IM‑MOEA utilises an external archive and biased reproduction; and IM‑C‑MOEA/D extends the framework to constrained problems~\cite{Farias2024}.  These algorithms
demonstrate that inverse modelling can maintain solution quality while
reducing the number of forward evaluations.

Despite these advances, existing inverse evolutionary algorithms operate
within the optimisation loop.  They require a population of solutions and
iteratively update the inverse model alongside the search.  The present
thesis advocates a different paradigm: training an inverse model offline
from an initial optimisation run and then using it in an interactive
environment.  This decoupling enables real‑time exploration and does not
alter the optimisation algorithm itself.

\section{Surrogate‑Assisted Inverse Modelling}

Inverse modelling can be viewed as learning the inverse of a black‑box
function.  Various regression techniques have been explored for this
purpose.  Gaussian process regression (GPR) provides a non‑parametric
Bayesian model that captures both global trends and local variability; it
has been used as the inverse model in IM‑MOEA~\cite{Farias2024}.  Random
forest regression offers an ensemble of decision trees that can approximate
nonlinear relationships and has been shown to improve diversity and
convergence when combined with uniform reference points~\cite{Gholamnezhad2022}.
Radial basis function networks, support‑vector regressors and neural
networks have also been applied as inverse surrogates.  Transfer learning
approaches leverage data from related optimisation tasks to improve
inverse models when training data is scarce~\cite{Tan2023}.

While these methods perform well in the context of evolutionary search,
there is limited work on deploying inverse surrogates for post‑hoc design
exploration.  A notable exception is Tan et~al., who propose learning
across common objective spaces and training inverse machine learning models
to map points on the Pareto front to decision variables~\cite{Tan2023}.
Their work emphasises that multi‑source training can mitigate data
scarcity and improve generalisation~\cite{Tan2023}.  The present
thesis builds on these ideas by combining surrogate inverse models with
interactive user queries and validation via forward surrogates.

\section{Inverse Multi‑Objective Optimisation}

Inverse multi‑objective optimisation (IMOP) is a related but distinct
problem studied in operations research.  Rather than finding decision
variables given objectives, IMOP seeks to infer the parameters of the
objective functions themselves from observed optimal decisions.  Dong and
Zeng formulate a distributionally robust IMOP using the Wasserstein
metric to hedge against uncertainty in the hypothetical decision‑making
problem and show that the estimator has a sub‑linear excess risk~\cite{Dong2021}.
Although IMOP methods are not directly applicable to the inverse decision
mapping considered here, they provide theoretical guarantees for
inverse inference and highlight the importance of robustness when
learning from limited data.

\section{Summary}

Existing work demonstrates the potential of inverse models within
evolutionary algorithms and hints at broader applications in design
exploration.  However, there remains a gap between optimisation‑centric
inverse modelling and user‑centric decision support.  The following
chapters formalise the problem of inverse decision mapping, propose a
modular framework to address it and evaluate various surrogate models for
interactive exploration.

\section{Deep Generative Models and Probabilistic Inverse Design}

Beyond deterministic surrogate regressors, recent advances in deep generative
models and probabilistic machine learning offer promising avenues for
multi‑objective inverse design.  Traditional inverse regressors minimise a
mean‑squared error loss, which encourages the model to approximate the
conditional average of the response variables.  As Bishop notes in his
pioneering report on mixture density networks (MDNs), such conditional
averages are of limited use for multi‑valued inverse problems because
averaging multiple valid targets yields a solution that is itself
invalid.  MDNs overcome this
limitation by coupling a neural network with a mixture model that predicts
a full conditional probability density rather than a single point estimate,
capturing multimodal relationships inherent to inverse mappings.

Deep generative models extend this idea by learning invertible mappings
between a low‑dimensional latent space and complex data distributions.  In the
context of nanophotonic design, Liu et~al. propose a
tandem architecture comprising an inverse network and a forward model.  They
show that naively training an inverse network suffers from data
inconsistency because the mapping from objectives to decisions is
non‑unique; their tandem network learns to predict a design and then
validate it with a pre‑trained forward model, enabling efficient inverse
design despite non‑uniqueness.  This approach demonstrates how
integrating forward and inverse models can stabilise training and yield
accurate predictions.

Generative models have also been applied to materials science.  Debnath
et~al. review the use of deep generative models for the inverse design of
high‑entropy refractory alloys.  They highlight that generative models can
learn complex structure–property relationships and generate novel candidates
on demand; once trained, a generative model maps random noise to the latent
space of valid materials and can thus synthesise new alloys with
targeted properties.  Such methods
provide a powerful tool for inverse design because they approximate the
inverse of the structure–property map and offer controllable sampling via
latent variables.

Conditional variational autoencoders (CVAEs) and their extensions enable
multi‑objective inverse design by conditioning the generative process on
desired properties.  Lee and Min propose the MGCVAE framework for
de novo molecular design.  Their model conditions a graph‑based VAE on two
physical properties (logP and molar refractivity) and demonstrates that
multi‑objective conditioning significantly increases the fraction of
generated molecules that satisfy both targets compared with an
unconditioned VAE.  Generative models of this form
have been extended to engineering domains such as electric machine design
and van der Waals materials, underscoring the versatility of conditional
autoencoders for inverse problems.

Although generative models remain computationally intensive to train and
often require large datasets, they offer several advantages over classical
regressors: they naturally handle multi‑modal inverse mappings, provide
uncertainty estimates through sampling, and can be combined with
preference learning to explore the space of admissible solutions.  The
present thesis focuses on deterministic surrogates due to their simplicity
and interpretability but acknowledges that probabilistic and generative
approaches represent an important future research direction.