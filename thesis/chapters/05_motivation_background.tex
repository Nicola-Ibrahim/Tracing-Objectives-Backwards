%-------------------------------------------------------------------------------
% Background and Motivation
%-------------------------------------------------------------------------------

\chapter{Background and Motivation}\label{chap:motivation}

Inverse decision mapping begins with a basic asymmetry: generating outcomes from decisions is often straightforward, but recovering decisions from outcomes is typically ill-posed. Forward models can be evaluated by analysis, simulation, or experiment; the reverse direction must contend with non-uniqueness, instability, and sometimes infeasibility. Classical inverse-problems theory treats these difficulties as structural and addresses them by injecting additional information---for example through regularisation or Bayesian modelling---so that solutions remain stable under noise and modelling mismatch~\cite{Stuart2010}. The central point is that inverse design is rarely a clean algebraic inversion; it is an inference problem whose answers are shaped by the assumptions one is willing to encode.

Recent work changes how those assumptions are represented. Instead of specifying all structure through handcrafted analytic penalties, learning-based approaches use data to capture recurring patterns in feasible solutions and to accelerate inverse querying at deployment. Surveys of data-driven inversion repeatedly highlight hybrid designs as the most dependable: learned components provide speed or expressive priors, while a trusted forward operator---when available---anchors fidelity by enforcing data consistency and enabling post-hoc verification~\cite{Liu2025Review}. Practically, the forward model also supplies a task-aligned scoring mechanism: it lets one rank candidate decisions by evaluating (or approximating) $f(\cdot)$ and measuring discrepancy in outcome space, even when the inverse model is imperfect away from the training distribution.

This hybrid viewpoint is especially natural when the inverse relationship is one-to-many. In such settings, forcing a single estimate can conceal meaningful ambiguity: multiple distinct decisions may satisfy the same specification, or satisfy it approximately with different trade-offs. Generative modelling instead treats the inverse map as a conditional mechanism that produces \emph{sets} of candidate decisions, often by restricting solutions to a learned low-dimensional range or manifold~\cite{Liu2025Review}. The implication is operational: inverse querying becomes the task of proposing diverse candidates and letting forward verification determine which ones meet the target under the chosen discrepancy measure.

These considerations place unusual pressure on the data used for learning. Paired examples $(\vect{x},\vect{y})$ must cover the outcome region where queries will be posed; otherwise, inverse models extrapolate and may express misleading confidence. In many engineering settings, such pairs arise from simulation sweeps, experimental campaigns, or design traces that intentionally explore trade-offs across objectives; these sources act as data generators rather than commitments to any single optimisation philosophy. Methodologically, successful inverse decision mapping therefore depends as much on coverage-aware data collection and forward-grounded evaluation as it does on model class and training loss.


\section{Towards Inverse Design}\label{sec:inverse_data_eval}

This thesis treats inverse design as a decision-making problem in the inverse direction: the target $\vect{y}^\star$ specifies what should be achieved, and the goal is to identify admissible decisions that meet it. Since the inverse relation is typically one-to-many, the central modelling question is not how to compute a single inverse, but how to represent and exploit the set of plausible designs implied by the available evidence.

The practical shift is to use learning to build an inverse proposal mechanism from paired observations, while reserving correctness for forward-grounded verification. Concretely, instead of committing to a single estimate, we learn a conditional model over decisions given a target outcome and use it to generate a small candidate set that can be checked against the task definition. This aligns with modern perspectives on learned inverse problems and with recent materials-oriented inverse design work that emphasises generating candidates under constraints rather than solving a single deterministic inverse. \cite{Ongie2020}

We express this workflow through a propose-and-verify abstraction. Given a target $\vect{y}^\star$, the inverse model produces candidates from a conditional distribution,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:propose}
\end{equation}
and the forward model in case of availability defined earlier is used to filter and rank them using the deployment discrepancy measure and feasibility checks,
\begin{equation}
  \widehat{k}\in\arg\min_{k\in\{1,\dots,K\}}\ \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\vect{y}^\star\big)
  \quad \text{subject to design constraints in }\calX.
  \label{eq:verify_select}
\end{equation}
This separation makes the role of modelling explicit: $q_\theta(\vect{x}\mid\vect{y})$ is responsible for producing diverse, data-supported proposals, while $\vect{f}$ and $\mathcal{L}$ determine which proposals satisfy the design intent.

The distributional form of $q_\theta$ is intentionally left open at the thesis level. What matters is the capability to represent multi-modality and to sample efficiently. Conditional density estimators and generative models provide practical realisations, including flow-based models and diffusion or score-based constructions that can be adapted to posterior-style sampling in inverse settings. \cite{Papamakarios2021}

Finally, this inverse-design stance clarifies how modelling and data interact without re-litigating data collection. The learned conditional captures regularities present in the observed joint behaviour of decisions and outcomes, and forward verification prevents the inverse model from becoming the sole authority on validity. As a result, inverse design becomes guided exploration in $\calX$ driven by learned proposals and disciplined by forward consistency in $\calY$, which sets up the strategy families introduced next.

This thesis treats inverse design as a decision-making problem in the inverse direction: the target $\vect{y}^\star$ specifies what should be achieved, and the goal is to identify admissible decisions that meet it. Since the inverse relation is typically one-to-many, the central modelling question is not how to compute a single inverse, but how to represent and exploit the set of plausible designs implied by the available evidence.

The practical shift is to use learning to build an inverse proposal mechanism from paired observations, while reserving correctness for forward-grounded verification. Concretely, instead of committing to a single estimate, we learn a conditional model over decisions given a target outcome and use it to generate a small candidate set that can be checked against the task definition. This aligns with modern perspectives on learned inverse problems and with recent work that treats constraint-aware generation and validation as the primitive operation, rather than deterministic inversion. \cite{Ongie2020}

We express this workflow through a propose-and-verify abstraction. Given a target $\vect{y}^\star$, the inverse model produces candidates from a conditional distribution,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:propose}
\end{equation}
and the forward model (when available) is used to filter and rank them using the deployment discrepancy measure and feasibility checks,
\begin{equation}
  \widehat{k}\in\arg\min_{k\in\{1,\dots,K\}}\ \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\vect{y}^\star\big)
  \quad \text{subject to design constraints in }\calX.
  \label{eq:verify_select}
\end{equation}
This separation makes the role of modelling explicit: $q_\theta(\vect{x}\mid\vect{y})$ is responsible for producing diverse, data-supported proposals, while $\vect{f}$ and $\mathcal{L}$ determine which proposals satisfy the design intent.

The distributional form of $q_\theta$ is intentionally left open at the thesis level. What matters is the capability to represent multi-modality and to sample efficiently. Conditional density estimators and generative models provide practical realisations, including flow-based models and diffusion or score-based constructions that can be adapted to posterior-style sampling in inverse settings. \cite{Papamakarios2021}

Finally, this inverse-design stance clarifies how modelling and data interact without re-litigating data collection. The learned conditional captures regularities present in the observed joint behaviour of decisions and outcomes, and forward verification prevents the inverse model from becoming the sole authority on validity. As a result, inverse design becomes guided exploration in $\calX$ driven by learned proposals and disciplined by forward consistency in $\calY$, which sets up the strategy families introduced next.


\subsection{Challenges for learning-enabled inverse design}\label{sec:inverse_challenges}

As inverse design has matured across scientific and engineering domains, the practical question has shifted from whether inverse querying is possible to whether it is reliable, informative, and cost-effective when embedded in real workflows. Moving from purely iterative search to learning-enabled inversion amplifies this question, because the output is no longer a single recommended decision but a distribution of plausible candidates that must be judged under limited compute and imperfect models. This thesis adopts a propose-and-verify stance precisely to make those reliability questions explicit.

A central difficulty is that utility is defined at the level of a candidate set. When an inverse model returns multiple proposals for the same target, the usual point-wise error summaries say little about whether the set contains genuinely useful alternatives, whether the conditioning on $\vect{y}^\star$ is respected, and whether the proposals cover distinct modes of the inverse relation rather than repeating minor variations. Work on evaluation for generative design models argues that design-native criteria are needed because standard statistical similarity scores often fail to track the quantities engineers actually act on. In the present setting, this motivates evaluating inverse models using set-level notions of target achievement, diversity, and admissibility, measured under the same discrepancy logic that will be used for selection at deployment. 

Moreover, propose-and-verify makes the verification signal a first-order modelling component. The selection rule in \eqref{eq:verify_select} inherits any bias, under-resolution, or mismatch present in the forward evaluator, and classical inverse problems perspectives emphasise that noise and modelling discrepancy can dominate conclusions even when the inverse representation is expressive. In contrast to treating verification as a definitive oracle, the more defensible interpretation is to treat it as a disciplined filter whose limitations remain visible, so that ranking decisions can be justified in the presence of approximation error. This framing aligns with the broader view that learned components should be coupled to physical or forward-grounded structure rather than replacing it. 

Further, learning-enabled inversion is vulnerable to distribution shift. Training data typically covers only a subset of the joint behaviour of decisions and outcomes, so changes in target regimes, operating conditions, or even the effective admissible region of $\calX$ can push queries outside the support where $q_\theta(\vect{x}\mid\vect{y})$ is trustworthy. Surveys of data-driven inverse problems highlight that such shifts can produce outputs that look plausible while being systematically wrong, especially when the model has no mechanism for recognising extrapolation. In this thesis, this motivates treating the learned proposer as amortised guidance for exploration, while relying on forward checks and targeted additional evaluation to defend against out-of-distribution requests. \cite{Ongie2020}

Closely linked to shift is the role of uncertainty. In inverse design, outputs trigger action, so the pipeline must support rejection and refinement when evidence is weak, not merely selection when evidence appears strong. Bayesian perspectives treat uncertainty as part of the solution object because decisions require an explicit notion of risk, and learning-based inverse-problem surveys similarly identify robustness and failure detection as central deployment concerns. Within the propose-and-verify abstraction, this suggests attaching uncertainty to candidate scores, to the forward check, or to both, so that acceptance is justified under a stated risk posture rather than an implicit assumption of correctness.

Finally, representation and computation determine what inverse querying can deliver in practice. Candidate throughput depends on how $\calX$ is parameterised, how efficiently $q_\theta$ can sample, and how expensive verification is, which introduces coupled trade-offs between expressivity, tractability, and fidelity. Perspectives that connect inverse problems with model reduction emphasise exploiting low-dimensional structure without discarding the physical meaning carried by the forward relation, while reviews of flow-based probabilistic modelling make the computational costs of expressivity and sampling explicit. For this thesis, this motivates evaluating representation choices, verifier fidelity, and sampling strategy jointly, since improvements in one component can be negated by bottlenecks in another. \cite{Papamakarios2021}

Together, these challenges motivate organising inverse-design methods by how they allocate inductive bias between proposal and verification, and by how they manage set-level evaluation, mismatch, generalisation risk, and computational cost under realistic budgets.




% Most materials workflows are built for the \emph{forward} question $\,\vect{x}\!\mapsto\!\vect{y}$—given a candidate, what will it do? Design asks the converse: specify a target response $\vect{y}^{\star}$ and identify admissible decisions $\vect{x}$ that realise it under physical and process constraints. Because many $\vect{x}$ can yield similar $\vect{y}$, the inverse task is generically ill-posed. We therefore pose it explicitly as a regularised/Bayesian inverse problem (Eqs.~\ref{eq:tikhonov}–\ref{eq:posterior}), which affords (i) fast, feasible point proposals consistent with prior knowledge and constraints, and (ii) calibrated distributions over plausible designs that make non-uniqueness and uncertainty first-class citizens~\cite{BenningBurger2018,Stuart2010}.


\subsection{Inverse-design strategies}

Inverse design starts from a target response and searches the (typically vast and constrained) space of compositions, structures, and processes for feasible solutions. Compared with forward modeling, inverse problems are often ill-posed (one-to-many mappings) and data-limited, amplifying concerns around generalization, uncertainty, and reproducibility in machine-learning (ML) workflows~\cite{KabanikhinSurvey}. In practice, three complementary strategy families are prevalent: exploration-based (agent- or heuristic-driven search with minimal labels), model-based (learning bidirectional or generative structure–property surrogates), and optimization-based (treating inverse design as an explicit optimization over design variables) \cite{Liu2025Review, Melati2025_InverseDesignPIC_Tutorial}. Below we outline their core ideas, typical algorithms, representative materials applications, and practical trade-offs.

\subsubsection{Exploration-based inverse design:}
Exploration-first approaches iteratively probe unknown design regions to discover candidates that satisfy performance constraints under sparse supervision. Reinforcement learning (RL) agents optimize sequences of design decisions by interacting with a simulator or learned environment; Monte Carlo Tree Search (MCTS) supplies strong look-ahead priors; and particle-swarm methods provide robust heuristic global search. For photonic device geometry, Hwang \emph{et~al.} combined an Advantage Actor–Critic (A2C) agent (IDEA) with a critic-value branch tree (CVBT) to diversify high-scoring candidate designs~\cite{Hwang2022_ASOC}. CASTING extends MCTS to continuous actions for materials discovery, improving exploration efficiency in high-dimensional spaces~\cite{Banik2023_NPJCM}, while MCTS has also accelerated polymer sequence design under astronomical combinatorics~\cite{Patra2020_Nanoscale}. When physics solvers are expensive or gradients are unavailable, population heuristics such as Particle Swarm Optimization (PSO) remain effective global explorers; notably, PSO coupled with self-consistent field theory (SCFT) has realized bulk copolymer morphologies meeting target patterns~\cite{Khadilkar2017_Macromolecules,Wang2018_SoftComput}. RL has likewise guided combinatorial chemistry to reach molecules with extreme property targets that confound distribution-learning models~\cite{Kim2024_ChemSci}. Strengths of exploration methods include label frugality, no need for bijective mappings, and natural diversity; typical limitations are high compute budgets (many simulator calls), reward shaping sensitivity, and difficulty enforcing hard constraints without additional mechanism design.

\subsubsection{Model-based inverse design:}
Model-based strategies learn data-driven or physics-informed maps that enable inference from desired properties back to candidate designs. A pragmatic pattern is \emph{forward–inverse coupling}: Liu \emph{et~al.} introduced a tandem neural architecture that mitigates non-uniqueness by training an inverse network cascaded with a forward predictor, so only property-consistent designs survive~\cite{Liu2018_ACSPhotonics}. Industrial alloy workflows have operationalized this idea: the ML Design System (MLDS) generates property$\to$composition (P2C) proposals that are validated by a more reliable composition$\to$property (C2P) forward model; iterations continue until target errors are met, enabling copper and aluminum alloy discoveries~\cite{Wang2019_NPJCM,Jiang2022_JMST}. 
Surrogate modeling is the other mainstay: random-forest or neural surrogates approximate expensive simulators and are inverted with classical optimizers. In Li-ion cathodes, a learned surrogate over synthesis descriptors enabled inverse ``retrosynthesis'' of processing conditions achieving high discharge capacity, validated experimentally~\cite{Liow2022_NanoEnergy}. Transfer learning further bolsters small-data surrogates; e.g., TLOpt leverages pretraining and then couples the surrogate to genetic and Bayesian optimizers to match target spectra in optical materials~\cite{Dong2021_CMS}. 
Finally, \emph{generative models} (VAEs, GANs, autoregressive flows) map low-dimensional latent variables to design manifolds, providing smooth spaces for search and conditional sampling. VAEs have been used to traverse continuous microstructure spaces to optimize mechanical response~\cite{Kim2021_MatDes}, and generative pipelines have supported inverse design of high-entropy refractory alloys~\cite{Debnath2021_JMI}. GAN-based inverse mappers have also produced morphing composite beams that realize prescribed shapes under actuation~\cite{Brzin2024_EAAI}. Model-based methods excel in sample efficiency and amortized inference once trained, but must explicitly manage non-uniqueness (e.g., via forward validators or conditional priors), distribution shift, and uncertainty quantification.

\subsubsection{Optimization-based inverse design:}
Here the inverse task is posed as optimizing one or more objectives (e.g., error to a target spectrum) over design variables, subject to constraints. \emph{Bayesian Optimization} (BO) offers strong sample efficiency by balancing exploration and exploitation with acquisition functions; in combination with graph deep-learning energy models, BO has led to experimentally realized superhard compounds and efficient exploration of hypothetical crystals~\cite{Zuo2021_MaterialsToday}. BO/active-learning loops have also delivered high-performance Mg--Mn alloys with few experiments~\cite{Mi2024_JMagAlloys}. Gaussian/Bayesian hybrids can tackle metamaterial inverse design with uncertainty-aware updates~\cite{Zheng2020_JAP}, and deep-learning Bayesian frameworks support attribute-driven molecular design under priors and constraints~\cite{Tagade2019_NPJCM}. 
\emph{Genetic algorithms} (GA) remain a strong baseline for discrete or constrained spaces and can be hybridized with surrogates; e.g., GA+NN co-optimization achieved efficient photonic device design with reduced data needs~\cite{Ren2021_PhotonicsResearch}. When full-wave or continuum physics is differentiable, \emph{topology optimization} (adjoint gradients) provides a powerful PDE-constrained inverse design tool widely adopted in photonics~\cite{Christiansen2021_JOSAB,Jensen2011_LPR}. Optimization-based schemes provide principled multi-objective trade-offs, constraint handling, and sample-efficient search, but depend on accurate surrogates/acquisitions, careful problem parameterization, and (for gradient methods) differentiable solvers and single-valued adjoints.

In practice, hybrid pipelines perform best: exploration agents query model-based surrogates (\emph{RL $\leftrightarrow$ surrogate}); generative latents are optimized with BO/GA (\emph{gen. model $\rightarrow$ optimizer}); and forward–inverse couplings screen P2C proposals through trusted C2P evaluators before simulation or experiment. Which path to prefer depends on data regime, simulator cost, constraints, and whether gradients are available. Table~\ref{tab:inv_compare} summarizes the trade-space.

\begin{table}[H]
\centering
\caption{Compact comparison of inverse-design strategies.}
\label{tab:inv_compare}
\setlength{\tabcolsep}{4pt}           % tighten horizontal padding
\renewcommand{\arraystretch}{1.12}    % subtle vertical compaction
\footnotesize                         % or \scriptsize if still wide
\begin{tabularx}{\linewidth}{
  >{\raggedright\arraybackslash}p{2.6cm}
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X}
\toprule
\textbf{Strategy} & \textbf{Typical algorithms} & \textbf{Strengths} & \textbf{Common caveats} \\
\midrule
\emph{Exploration-based}
& RL (A2C/PPO + simulators); MCTS (discrete/continuous); PSO and other swarm heuristics
& Label-frugal; discovers diverse solutions; robust to one-to-many mappings
& Many simulator calls; reward-shaping sensitivity; constraint enforcement can be nontrivial \\
\addlinespace[2pt]
\emph{Model-based}
& Forward--inverse (tandem) nets; supervised surrogates (RF/NN); transfer learning; VAEs/GANs
& Sample-efficient; amortized inference; possible uncertainty handling via calibrated models
& Non-uniqueness requires forward validation; distribution shift; data curation and retraining loops \\
\addlinespace[2pt]
\emph{Optimization-based}
& Bayesian optimization / active learning; genetic algorithms; adjoint (topology) optimization
& Strong sample-efficiency (BO); handles constraints and multi-objective trade-offs; scalable with gradients
& Surrogate bias; local minima; need differentiable solvers/valid adjoints; parameterization sensitivity \\
\bottomrule
\end{tabularx}
\end{table}


\section{Data Sources}\label{sec:database}

A learning-based inverse model relies on paired examples
\(\mathcal{D}=\{(\vect{x}_i,\vect{y}_i)\}_{i=1}^{N}\), where outcomes arise from the forward process
\begin{equation}
  \vect{y}_i \;=\; \vect{f}(\vect{x}_i) \;+\; \boldsymbol{\varepsilon}_i,
  \qquad \vect{x}_i\in\calX,\ \vect{y}_i\in\calY .
  \label{eq:database_forward}
\end{equation}
We treat \(\mathcal{D}\) as an empirical sample of the joint behaviour of decisions and outcomes, without committing to a single data-generation philosophy. 

In practice, suitable pairs can come from two broad channels:
\begin{itemize}
  \item Curated and measured datasets: historical logs, experimental archives, or precomputed simulation sets, including design-of-experiments sweeps aimed at broad coverage of \(\calX\) and the induced outcome region in \(\calY\).
  \item Optimisation traces: decision--outcome pairs produced as a by-product of exploratory search, such as multiobjective optimisation runs, surrogate-assisted procedures, or Bayesian optimisation loops, which naturally collect diverse trade-offs across objectives and constraints. 
\end{itemize}

Because inverse decision mapping is often one-to-many, diversity in \(\mathcal{D}\) is valuable, but reliability is local in outcome space: if targets \(\vect{y}^\star\) lie outside the data-supported region, the learned inverse may propose plausible decisions that fail forward verification.


\section{Modeling Background}\label{sec:modelling_background}


\subsection{Learning-Based Mapping}\label{sec:learning_based_mapping}

Learning-based mapping approaches treat inverse decision mapping as an inference problem driven by data. Rather than assuming that the inverse relation can be written as a stable function, they learn statistical relationships between decisions and outcomes and use these relationships to answer inverse queries. This viewpoint is consistent with the inverse-problems literature: the reverse direction is often ill-posed, meaning that solutions may be non-unique, sensitive to perturbations, or absent for some targets. In decision mapping this is not exceptional; many distinct decisions can induce outcomes that are indistinguishable at the resolution implied by the discrepancy measure and the noise level. \cite{Ongie2020,Stuart2010}

We describe the setting through a forward relation between a decision $\vect{x}\in\calX$ and an outcome $\vect{y}\in\calY$,
\begin{equation}
  \vect{y} \;=\; \vect{f}(\vect{x}) \;+\; \boldsymbol{\varepsilon},
  \label{eq:forward}
\end{equation}
and an inverse query that specifies a target outcome $\vect{y}^\star$ and asks for decisions whose forward response matches it approximately,
\begin{equation}
  \text{find }\vect{x}\in\calX \text{ such that } \mathcal{L}\!\big(\vect{f}(\vect{x}),\vect{y}^\star\big)\ \text{is small}.
  \label{eq:inverse_query}
\end{equation}
This formulation makes explicit that inverse decision mapping is defined relative to a task metric $\mathcal{L}$ and to the uncertainty model $\boldsymbol{\varepsilon}$, not solely by algebraic invertibility of $\vect{f}$.

One way learning enters is by modelling an inverse map as a predictor $g:\calY\!\to\!\calX$ selected by regularised risk minimisation on paired data $\mathcal{D}=\{(\vect{y}_i,\vect{x}_i)\}_{i=1}^N$,
\begin{equation}
  \widehat{g}
  \;\in\;
  \arg\min_{g\in\mathcal{G}}
  \frac{1}{N}\sum_{i=1}^{N}\ell\!\left(g(\vect{y}_i),\,\vect{x}_i\right)
  \;+\;
  \lambda\,\Omega(g),
  \label{eq:erm_inverse_bg}
\end{equation}
where $\ell$ measures decision-space discrepancy and $\Omega$ encodes inductive bias that improves stability and generalisation. A limitation of pure decision-space supervision is that, under non-uniqueness, multiple distinct decisions may be equally compatible with the same target. In such settings, a point predictor can collapse ambiguity into a single selection rule and can be penalised for proposing alternatives that are valid but differ from the recorded design. \cite{Ongie2020}

A second, more expressive route models the inverse relation as a conditional distribution over decisions given outcomes. In Bayesian inverse problems this appears as a posterior distribution over $\vect{x}$ conditioned on the target, while in data-driven settings it is natural to fit a conditional density model from paired samples,
\begin{equation}
  q_\theta(\vect{x}\mid\vect{y}) \approx p(\vect{x}\mid\vect{y}),
  \qquad
  \theta^\star \in \arg\min_\theta \sum_{i=1}^N -\log q_\theta(\vect{x}_i\mid\vect{y}_i),
  \label{eq:cond_mle_bg}
\end{equation}
so that uncertainty and multi-modality are represented directly through sampling and conditional variability. This conditional viewpoint is also central in simulation-based inference, where the goal is to learn conditionals from samples generated by a forward mechanism rather than to derive analytic inverses. \cite{Cranmer2020,Papamakarios2021}

Learning-based inversion is typically coupled to a forward-grounded notion of validity. Given a target $\vect{y}^\star$, a conditional model can generate candidate decisions,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:candidate_sampling}
\end{equation}
which are then assessed by the task discrepancy through the forward relation, using either $\vect{f}$ itself or a learned approximation when direct evaluation is costly,
\begin{equation}
  \text{score}\big(\widehat{\vect{x}}^{(k)}\big)
  \;=\;
  \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\,\vect{y}^\star\big),
  \qquad
  \phi^\star \in \arg\min_\phi \sum_{i=1}^N \mathcal{L}\!\big(\widehat{\vect{f}}_\phi(\vect{x}_i),\,\vect{y}_i\big).
  \label{eq:verify_surrogate_bg}
\end{equation}
This coupling clarifies a general principle: learning proposes, while forward consistency defines acceptance. It also highlights a persistent limitation. Any learned inverse, whether point-valued or distributional, is supported by the regions of $(\vect{x},\vect{y})$ space represented in the available data; queries outside that region can induce confident-looking proposals that fail when checked forward. \cite{Arridge2019,Ongie2020}

Inverse exploration therefore relies on models as its inner loop: given a candidate decision $\vect{x}$, one must anticipate the corresponding outcome $\vect{y}$ and, when possible, quantify uncertainty in that anticipation. Deterministic predictors provide fast point estimates, while probabilistic models represent conditional variability and enable uncertainty-aware selection. Both perspectives sit naturally within statistical learning and decision-theoretic principles and provide the modelling basis for inverse decision mapping. \cite{RasmussenWilliams2006,Bishop2006PRML}


\subsection{Probabilistic View}

The probabilistic view replaces single-point predictions with conditional distributions, making uncertainty an explicit modelling object and providing a natural way to represent one-to-many relationships. In inverse decision mapping this matters because ambiguity is often structural: multiple distinct decisions can be compatible with the same target outcome within the resolution of the task discrepancy, and small perturbations or noise can change which decisions appear optimal. A probabilistic model can represent this ambiguity directly and, crucially, turns it into a mechanism for generating multiple plausible candidates rather than forcing an arbitrary single choice. 

Given paired observations $\mathcal{D}=\{(\vect{x}_i,\vect{y}_i)\}_{i=1}^N$, a generic likelihood-based training principle learns a conditional distribution by maximising regularised log-likelihood,
\begin{equation}
  \widehat{\theta}
  \;\in\;
  \arg\max_{\theta}
  \Bigg[
    \sum_{i=1}^{N}\log p_{\theta}\!\big(\vect{x}_i \mid \vect{y}_i\big)
    \;-\;
    \gamma\,\mathcal{R}(\theta)
  \Bigg],
  \label{eq:prob_generic}
\end{equation}
where $\mathcal{R}(\theta)$ controls complexity and encodes modelling assumptions, and $\gamma\ge 0$ balances fit and regularisation. The purpose of this formulation in the present context is not to prescribe a specific estimator, but to emphasise the modelling consequence: the output of inference is a distribution over decisions conditioned on a target, rather than a single deterministic proposal. \cite{Murphy2022PML1}

This distributional output supports candidate-set generation by sampling. For a query $\vect{y}^{\star}$, one draws a collection of candidates,
\begin{equation}
  \vect{x}^{(r)} \sim p_{\widehat{\theta}}(\vect{x}\mid\vect{y}^{\star}),\qquad r=1,\dots,R,
  \label{eq:prob_sampling}
\end{equation}
and then ranks or filters them using a task discrepancy that reflects the design intent. Sampling separates the question of plausibility from the question of selection: the learned conditional determines which candidates are supported by the data, while the task metric determines which of those candidates best satisfy the target. This separation is particularly valuable when the inverse relation is multi-modal, because it allows the procedure to surface multiple, qualitatively different alternatives instead of collapsing them into a single averaged solution.

Uncertainty is therefore not an auxiliary statistic but a functional part of the inverse pipeline. The spread of $p_{\widehat{\theta}}(\vect{x}\mid\vect{y}^{\star})$ reflects how concentrated the evidence is around particular decisions for the specified target, and it provides a natural basis for deciding how many candidates to generate and how conservative selection should be. Likelihood-based training and evaluation also align with this role, because they reward distributions that are calibrated as well as informative.


\subsection{MDN, CVAE, INN}
Write abou these estimators in details and how each one define the problem and what we are optimising, loss function, modelling distribution.




% \subsection{Deterministic Modelling}\label{sec:deterministic_modelling}

% In the deterministic setting, the inverse model $g:\mathcal{Y}\!\to\!\mathcal{X}$ returns a single design $\hat{\vect{x}}=g(\vect{y}^{\star})$ for any target $\vect{y}^{\star}$. Training uses data $\mathcal{D}=\{(\vect{y}_i,\vect{x}_i)\}_{i=1}^{N}$ and a regularised objective to promote stability and generalisation. A basic formulation treats inverse learning as empirical risk minimisation in decision space,
% \begin{equation}
%   \widehat{g}
%   \;\in\;
%   \arg\min_{g\in\mathcal{G}}
%   \frac{1}{N}\sum_{i=1}^{N}\ell_{\mathcal{X}}\!\big(g(\vect{y}_i),\,\vect{x}_i\big)
%   \;+\; \lambda\,\Omega(g),
%   \label{eq:det_inv}
% \end{equation}
% where $\ell_{\mathcal{X}}$ penalises deviation from reference designs (e.g., $\|\hat{\vect{x}}-\vect{x}\|_2^2$ for continuous variables), $\Omega$ encodes inductive bias (e.g., weight decay, Jacobian control, early stopping), and $\lambda\!\ge\!0$ trades fit for complexity. This objective is effective when the mapping from $\vect{y}$ to a preferred $\vect{x}$ is essentially single-valued or when reproducing known recipes is desirable.

% Inverse problems are often one-to-many, however, so it is natural to measure success in outcome space using a forward model $\vect{f}:\mathcal{X}\!\to\!\mathcal{Y}$ (a simulator or a frozen surrogate). A forward-validated or “tandem” objective trains $g$ so that its proposals \emph{produce} the targets:
% \begin{equation}
%   \widehat{g}
%   \;\in\;
%   \arg\min_{g\in\mathcal{G}}
%   \frac{1}{N}\sum_{i=1}^{N}
%   \ell_{\mathcal{Y}}\!\big(\,\vect{f}(g(\vect{y}_i))\,,\,\vect{y}_i\big)
%   \;+\; \lambda\,\Omega(g),
%   \label{eq:det_tandem}
% \end{equation}
% with $\ell_{\mathcal{Y}}$ an application-appropriate discrepancy in $\mathcal{Y}$ (e.g., scaled $\ell_2$, Mahalanobis, or a task metric). This objective naturally accommodates non-uniqueness by accepting any design whose forward response matches the target.

% When one wishes to retain some preference for observed designs while enforcing outcome fidelity, a simple interpolation combines the two losses:
% \begin{equation}
%   \widehat{g}
%   \;\in\;
%   \arg\min_{g\in\mathcal{G}}
%   \frac{1}{N}\sum_{i=1}^{N}
%   \Big[
%     \alpha\,\ell_{\mathcal{X}}\!\big(g(\vect{y}_i),\,\vect{x}_i\big)
%     \;+\;
%     (1-\alpha)\,\ell_{\mathcal{Y}}\!\big(\vect{f}(g(\vect{y}_i)),\,\vect{y}_i\big)
%   \Big]
%   \;+\; \lambda\,\Omega(g),
%   \qquad \alpha\in[0,1].
%   \label{eq:det_hybrid}
% \end{equation}
% Small $\alpha$ emphasises “any valid preimage” (useful under strong non-uniqueness); larger $\alpha$ softly anchors solutions near known designs (useful for manufacturability or established process windows). Hyperparameters (architecture, $\lambda$, and, if used, $\alpha$) are selected on validation data. At inference, a single forward pass yields $\hat{\vect{x}}=g(\vect{y}^{\star})$, which can be verified by evaluating $\vect{f}(\hat{\vect{x}})$ against $\vect{y}^{\star}$.

% Deterministic training yields fast, reproducible proposals but collapses potentially multi-valued inverse relations to a point and does not natively quantify uncertainty or support diversity of candidates. In the broader framework of this thesis, these objectives are complemented by probabilistic models that learn conditional distributions (e.g., $p(\vect{x}\mid\vect{y})$ or $p(\vect{y}\mid\vect{x})$), enabling uncertainty estimates, calibrated scoring, and sampling-based exploration when multiple designs can realise the same target.




% \subsection{Inverse-centric evaluation metrics}

% Evaluation reflects the inverse goal: \emph{propose decisions that realise a desired outcome $\vect{y}^{\star}$}. In this thesis, each method returns a single decision per target (e.g., any probabilistic output is collapsed to a point estimate such as a mean, median, or MAP), and we therefore assess the quality of that proposed decision, irrespective of how it was generated.

% We first quantify how close a proposed decision $\widehat{\vect{x}}$ comes to the target by measuring a discrepancy in the outcome space with a task-appropriate distance $d$:
% \begin{equation}
%   \mathcal{E}_{\mathcal{Y}}(\widehat{\vect{x}},\vect{y}^{\star})
%   \;=\;
%   d\!\left(\,\vect{f}(\widehat{\vect{x}})\,,\,\vect{y}^{\star}\right),
%   \label{eq:target_error_clean}
% \end{equation}
% where $\vect{f}$ denotes the forward map from decision to outcome. The choice of $d$ should match the semantics and scales of the outcomes. In many settings, the Euclidean distance (the $\ell_2$ norm) is a natural default, especially after standardising outcome dimensions; see, for example, \cite{BoydVandenberghe2004}. When correlations between outcome components matter, the Mahalanobis distance provides a principled alternative by incorporating the outcome covariance; see the original development in \cite{Mahalanobis1936} and a modern tutorial in \cite{DeMaesschalck2000}. In application-driven contexts, $d$ may be defined by an accepted domain metric; in all cases, the definition of $d$ and any normalisation or weighting should be stated to support interpretability and reproducibility.

% To complement the continuous error, we also report a tolerance-based success measure. For each target, we record a binary success indicator that answers the question “did the single proposed decision meet the specification?”:
% \begin{equation}
%   \mathrm{succ}^{(m)}_\epsilon
%   \;=\;
%   \mathbb{I}\!\left[\,d\!\left(\vect{f}\!\big(\widehat{\vect{x}}^{(m)}\big),\,\vect{y}^{\star (m)}\right)\le \epsilon\,\right],
%   \label{eq:succ_eps_single}
% \end{equation}

% The tolerance $\epsilon$ should reflect domain limits (e.g., engineering tolerances or user-acceptable error). When such limits differ by component, it is helpful to define $d$ using per-component scaling or to report $\mathrm{Succ}_\epsilon$ at several tolerances (e.g., tight and relaxed bands) for a more complete picture. Alongside aggregate success, summary statistics of $\mathcal{E}_{\mathcal{Y}}$ across targets (e.g., median and interquartile range) convey both typical performance and variability.


% In sum, $\mathcal{E}_{\mathcal{Y}}$ captures \emph{how close} we get to the target, while $\mathrm{Succ}_\epsilon$ captures \emph{whether} we satisfy a practically meaningful tolerance. Together they provide a concise, implementation-agnostic summary of decision quality that is easy to interpret and straightforward to reproduce.
