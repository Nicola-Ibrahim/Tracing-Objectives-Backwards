%-------------------------------------------------------------------------------
% Background and Motivation
%-------------------------------------------------------------------------------

\chapter{Background and Motivation}\label{chap:motivation}

Inverse decision mapping begins with a basic asymmetry: generating outcomes from decisions is often straightforward, but recovering decisions from outcomes is typically ill-posed. Forward models can be evaluated by analysis, simulation, or experiment; the reverse direction must contend with non-uniqueness, instability, and sometimes infeasibility. Classical inverse-problems theory treats these difficulties as structural and addresses them by injecting additional information---for example through regularisation or Bayesian modelling---so that solutions remain stable under noise and modelling mismatch~\cite{Stuart2010}. The central point is that inverse design is rarely a clean algebraic inversion; it is an inference problem whose answers are shaped by the assumptions one is willing to encode.

Recent work changes how those assumptions are represented. Instead of specifying all structure through handcrafted analytic penalties, learning-based approaches use data to capture recurring patterns in feasible solutions and to accelerate inverse querying at deployment. Surveys of data-driven inversion repeatedly highlight hybrid designs as the most dependable: learned components provide speed or expressive priors, while a trusted forward operator---when available---anchors fidelity by enforcing data consistency and enabling post-hoc verification~\cite{Liu2025Review}. Practically, the forward model also supplies a task-aligned scoring mechanism: it lets one rank candidate decisions by evaluating (or approximating) $f(\cdot)$ and measuring discrepancy in outcome space, even when the inverse model is imperfect away from the training distribution.

This hybrid viewpoint is especially natural when the inverse relationship is one-to-many. In such settings, forcing a single estimate can conceal meaningful ambiguity: multiple distinct decisions may satisfy the same specification, or satisfy it approximately with different trade-offs. Generative modelling instead treats the inverse map as a conditional mechanism that produces \emph{sets} of candidate decisions, often by restricting solutions to a learned low-dimensional range or manifold~\cite{Liu2025Review}. The implication is operational: inverse querying becomes the task of proposing diverse candidates and letting forward verification determine which ones meet the target under the chosen discrepancy measure.

These considerations place unusual pressure on the data used for learning. Paired examples $(\vect{x},\vect{y})$ must cover the outcome region where queries will be posed; otherwise, inverse models extrapolate and may express misleading confidence. In many engineering settings, such pairs arise from simulation sweeps, experimental campaigns, or design traces that intentionally explore trade-offs across objectives; these sources act as data generators rather than commitments to any single optimisation philosophy. Methodologically, successful inverse decision mapping therefore depends as much on coverage-aware data collection and forward-grounded evaluation as it does on model class and training loss.


\section{Towards Inverse Design}\label{sec:inverse_data_eval}

This thesis treats inverse design as a decision-making problem in the inverse direction: the target $\vect{y}^\star$ specifies what should be achieved, and the goal is to identify admissible decisions that meet it. Since the inverse relation is typically one-to-many, the central modelling question is not how to compute a single inverse, but how to represent and exploit the set of plausible designs implied by the available evidence.

The practical shift is to use learning to build an inverse proposal mechanism from paired observations, while reserving correctness for forward-grounded verification. Concretely, instead of committing to a single estimate, we learn a conditional model over decisions given a target outcome and use it to generate a small candidate set that can be checked against the task definition. This aligns with modern perspectives on learned inverse problems and with recent materials-oriented inverse design work that emphasises generating candidates under constraints rather than solving a single deterministic inverse. \cite{Ongie2020}

We express this workflow through a propose-and-verify abstraction. Given a target $\vect{y}^\star$, the inverse model produces candidates from a conditional distribution,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:propose}
\end{equation}
and the forward model in case of availability defined earlier is used to filter and rank them using the deployment discrepancy measure and feasibility checks,
\begin{equation}
  \widehat{k}\in\arg\min_{k\in\{1,\dots,K\}}\ \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\vect{y}^\star\big)
  \quad \text{subject to design constraints in }\calX.
  \label{eq:verify_select}
\end{equation}
This separation makes the role of modelling explicit: $q_\theta(\vect{x}\mid\vect{y})$ is responsible for producing diverse, data-supported proposals, while $\vect{f}$ and $\mathcal{L}$ determine which proposals satisfy the design intent.

The distributional form of $q_\theta$ is intentionally left open at the thesis level. What matters is the capability to represent multi-modality and to sample efficiently. Conditional density estimators and generative models provide practical realisations, including flow-based models and diffusion or score-based constructions that can be adapted to posterior-style sampling in inverse settings. \cite{Papamakarios2021}

Finally, this inverse-design stance clarifies how modelling and data interact without re-litigating data collection. The learned conditional captures regularities present in the observed joint behaviour of decisions and outcomes, and forward verification prevents the inverse model from becoming the sole authority on validity. As a result, inverse design becomes guided exploration in $\calX$ driven by learned proposals and disciplined by forward consistency in $\calY$, which sets up the strategy families introduced next.

This thesis treats inverse design as a decision-making problem in the inverse direction: the target $\vect{y}^\star$ specifies what should be achieved, and the goal is to identify admissible decisions that meet it. Since the inverse relation is typically one-to-many, the central modelling question is not how to compute a single inverse, but how to represent and exploit the set of plausible designs implied by the available evidence.

The practical shift is to use learning to build an inverse proposal mechanism from paired observations, while reserving correctness for forward-grounded verification. Concretely, instead of committing to a single estimate, we learn a conditional model over decisions given a target outcome and use it to generate a small candidate set that can be checked against the task definition. This aligns with modern perspectives on learned inverse problems and with recent work that treats constraint-aware generation and validation as the primitive operation, rather than deterministic inversion. \cite{Ongie2020}

We express this workflow through a propose-and-verify abstraction. Given a target $\vect{y}^\star$, the inverse model produces candidates from a conditional distribution,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:propose}
\end{equation}
and the forward model (when available) is used to filter and rank them using the deployment discrepancy measure and feasibility checks,
\begin{equation}
  \widehat{k}\in\arg\min_{k\in\{1,\dots,K\}}\ \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\vect{y}^\star\big)
  \quad \text{subject to design constraints in }\calX.
  \label{eq:verify_select}
\end{equation}
This separation makes the role of modelling explicit: $q_\theta(\vect{x}\mid\vect{y})$ is responsible for producing diverse, data-supported proposals, while $\vect{f}$ and $\mathcal{L}$ determine which proposals satisfy the design intent.

The distributional form of $q_\theta$ is intentionally left open at the thesis level. What matters is the capability to represent multi-modality and to sample efficiently. Conditional density estimators and generative models provide practical realisations, including flow-based models and diffusion or score-based constructions that can be adapted to posterior-style sampling in inverse settings. \cite{Papamakarios2021}

Finally, this inverse-design stance clarifies how modelling and data interact without re-litigating data collection. The learned conditional captures regularities present in the observed joint behaviour of decisions and outcomes, and forward verification prevents the inverse model from becoming the sole authority on validity. As a result, inverse design becomes guided exploration in $\calX$ driven by learned proposals and disciplined by forward consistency in $\calY$, which sets up the strategy families introduced next.


\subsection{Challenges}\label{sec:inverse_challenges}

As inverse design has matured across scientific and engineering domains, the practical question has shifted from whether inverse querying is possible to whether it is reliable, informative, and cost-effective when embedded in real workflows. Moving from purely iterative search to learning-enabled inversion amplifies this question, because the output is no longer a single recommended decision but a distribution of plausible candidates that must be judged under limited compute and imperfect models. This thesis adopts a propose-and-verify stance precisely to make those reliability questions explicit.

A central difficulty is that utility is defined at the level of a candidate set. When an inverse model returns multiple proposals for the same target, the usual point-wise error summaries say little about whether the set contains genuinely useful alternatives, whether the conditioning on $\vect{y}^\star$ is respected, and whether the proposals cover distinct modes of the inverse relation rather than repeating minor variations. Work on evaluation for generative design models argues that design-native criteria are needed because standard statistical similarity scores often fail to track the quantities engineers actually act on. In the present setting, this motivates evaluating inverse models using set-level notions of target achievement, diversity, and admissibility, measured under the same discrepancy logic that will be used for selection at deployment. 

Moreover, propose-and-verify makes the verification signal a first-order modelling component. The selection rule in \eqref{eq:verify_select} inherits any bias, under-resolution, or mismatch present in the forward evaluator, and classical inverse problems perspectives emphasise that noise and modelling discrepancy can dominate conclusions even when the inverse representation is expressive. In contrast to treating verification as a definitive oracle, the more defensible interpretation is to treat it as a disciplined filter whose limitations remain visible, so that ranking decisions can be justified in the presence of approximation error. This framing aligns with the broader view that learned components should be coupled to physical or forward-grounded structure rather than replacing it. 

Further, learning-enabled inversion is vulnerable to distribution shift. Training data typically covers only a subset of the joint behaviour of decisions and outcomes, so changes in target regimes, operating conditions, or even the effective admissible region of $\calX$ can push queries outside the support where $q_\theta(\vect{x}\mid\vect{y})$ is trustworthy. Surveys of data-driven inverse problems highlight that such shifts can produce outputs that look plausible while being systematically wrong, especially when the model has no mechanism for recognising extrapolation. In this thesis, this motivates treating the learned proposer as amortised guidance for exploration, while relying on forward checks and targeted additional evaluation to defend against out-of-distribution requests. \cite{Ongie2020}

Closely linked to shift is the role of uncertainty. In inverse design, outputs trigger action, so the pipeline must support rejection and refinement when evidence is weak, not merely selection when evidence appears strong. Bayesian perspectives treat uncertainty as part of the solution object because decisions require an explicit notion of risk, and learning-based inverse-problem surveys similarly identify robustness and failure detection as central deployment concerns. Within the propose-and-verify abstraction, this suggests attaching uncertainty to candidate scores, to the forward check, or to both, so that acceptance is justified under a stated risk posture rather than an implicit assumption of correctness.

Finally, representation and computation determine what inverse querying can deliver in practice. Candidate throughput depends on how $\calX$ is parameterised, how efficiently $q_\theta$ can sample, and how expensive verification is, which introduces coupled trade-offs between expressivity, tractability, and fidelity. Perspectives that connect inverse problems with model reduction emphasise exploiting low-dimensional structure without discarding the physical meaning carried by the forward relation, while reviews of flow-based probabilistic modelling make the computational costs of expressivity and sampling explicit. For this thesis, this motivates evaluating representation choices, verifier fidelity, and sampling strategy jointly, since improvements in one component can be negated by bottlenecks in another. \cite{Papamakarios2021}

Together, these challenges motivate organising inverse-design methods by how they allocate inductive bias between proposal and verification, and by how they manage set-level evaluation, mismatch, generalisation risk, and computational cost under realistic budgets.




% Most materials workflows are built for the \emph{forward} question $\,\vect{x}\!\mapsto\!\vect{y}$—given a candidate, what will it do? Design asks the converse: specify a target response $\vect{y}^{\star}$ and identify admissible decisions $\vect{x}$ that realise it under physical and process constraints. Because many $\vect{x}$ can yield similar $\vect{y}$, the inverse task is generically ill-posed. We therefore pose it explicitly as a regularised/Bayesian inverse problem (Eqs.~\ref{eq:tikhonov}–\ref{eq:posterior}), which affords (i) fast, feasible point proposals consistent with prior knowledge and constraints, and (ii) calibrated distributions over plausible designs that make non-uniqueness and uncertainty first-class citizens~\cite{BenningBurger2018,Stuart2010}.


\subsection{Strategies}

Inverse design starts from a target response and searches the (typically vast and constrained) space of compositions, structures, and processes for feasible solutions. Compared with forward modeling, inverse problems are often ill-posed (one-to-many mappings) and data-limited, amplifying concerns around generalization, uncertainty, and reproducibility in machine-learning (ML) workflows~\cite{KabanikhinSurvey}. In practice, three complementary strategy families are prevalent: exploration-based (agent- or heuristic-driven search with minimal labels), model-based (learning bidirectional or generative structure–property surrogates), and optimization-based (treating inverse design as an explicit optimization over design variables) \cite{Liu2025Review, Melati2025_InverseDesignPIC_Tutorial}. Below we outline their core ideas, typical algorithms, representative materials applications, and practical trade-offs.

\subsubsection{Exploration-based inverse design:}
Exploration-first approaches iteratively probe unknown design regions to discover candidates that satisfy performance constraints under sparse supervision. Reinforcement learning (RL) agents optimize sequences of design decisions by interacting with a simulator or learned environment; Monte Carlo Tree Search (MCTS) supplies strong look-ahead priors; and particle-swarm methods provide robust heuristic global search. For photonic device geometry, Hwang \emph{et~al.} combined an Advantage Actor–Critic (A2C) agent (IDEA) with a critic-value branch tree (CVBT) to diversify high-scoring candidate designs~\cite{Hwang2022_ASOC}. CASTING extends MCTS to continuous actions for materials discovery, improving exploration efficiency in high-dimensional spaces~\cite{Banik2023_NPJCM}, while MCTS has also accelerated polymer sequence design under astronomical combinatorics~\cite{Patra2020_Nanoscale}. When physics solvers are expensive or gradients are unavailable, population heuristics such as Particle Swarm Optimization (PSO) remain effective global explorers; notably, PSO coupled with self-consistent field theory (SCFT) has realized bulk copolymer morphologies meeting target patterns~\cite{Khadilkar2017_Macromolecules,Wang2018_SoftComput}. RL has likewise guided combinatorial chemistry to reach molecules with extreme property targets that confound distribution-learning models~\cite{Kim2024_ChemSci}. Strengths of exploration methods include label frugality, no need for bijective mappings, and natural diversity; typical limitations are high compute budgets (many simulator calls), reward shaping sensitivity, and difficulty enforcing hard constraints without additional mechanism design.

\subsubsection{Model-based inverse design:}
Model-based strategies learn data-driven or physics-informed maps that enable inference from desired properties back to candidate designs. A pragmatic pattern is \emph{forward–inverse coupling}: Liu \emph{et~al.} introduced a tandem neural architecture that mitigates non-uniqueness by training an inverse network cascaded with a forward predictor, so only property-consistent designs survive~\cite{Liu2018_ACSPhotonics}. Industrial alloy workflows have operationalized this idea: the ML Design System (MLDS) generates property$\to$composition (P2C) proposals that are validated by a more reliable composition$\to$property (C2P) forward model; iterations continue until target errors are met, enabling copper and aluminum alloy discoveries~\cite{Wang2019_NPJCM,Jiang2022_JMST}. 
Surrogate modeling is the other mainstay: random-forest or neural surrogates approximate expensive simulators and are inverted with classical optimizers. In Li-ion cathodes, a learned surrogate over synthesis descriptors enabled inverse ``retrosynthesis'' of processing conditions achieving high discharge capacity, validated experimentally~\cite{Liow2022_NanoEnergy}. Transfer learning further bolsters small-data surrogates; e.g., TLOpt leverages pretraining and then couples the surrogate to genetic and Bayesian optimizers to match target spectra in optical materials~\cite{Dong2021_CMS}. 
Finally, \emph{generative models} (VAEs, GANs, autoregressive flows) map low-dimensional latent variables to design manifolds, providing smooth spaces for search and conditional sampling. VAEs have been used to traverse continuous microstructure spaces to optimize mechanical response~\cite{Kim2021_MatDes}, and generative pipelines have supported inverse design of high-entropy refractory alloys~\cite{Debnath2021_JMI}. GAN-based inverse mappers have also produced morphing composite beams that realize prescribed shapes under actuation~\cite{Brzin2024_EAAI}. Model-based methods excel in sample efficiency and amortized inference once trained, but must explicitly manage non-uniqueness (e.g., via forward validators or conditional priors), distribution shift, and uncertainty quantification.

\subsubsection{Optimization-based inverse design:}
Here the inverse task is posed as optimizing one or more objectives (e.g., error to a target spectrum) over design variables, subject to constraints. \emph{Bayesian Optimization} (BO) offers strong sample efficiency by balancing exploration and exploitation with acquisition functions; in combination with graph deep-learning energy models, BO has led to experimentally realized superhard compounds and efficient exploration of hypothetical crystals~\cite{Zuo2021_MaterialsToday}. BO/active-learning loops have also delivered high-performance Mg--Mn alloys with few experiments~\cite{Mi2024_JMagAlloys}. Gaussian/Bayesian hybrids can tackle metamaterial inverse design with uncertainty-aware updates~\cite{Zheng2020_JAP}, and deep-learning Bayesian frameworks support attribute-driven molecular design under priors and constraints~\cite{Tagade2019_NPJCM}. 
\emph{Genetic algorithms} (GA) remain a strong baseline for discrete or constrained spaces and can be hybridized with surrogates; e.g., GA+NN co-optimization achieved efficient photonic device design with reduced data needs~\cite{Ren2021_PhotonicsResearch}. When full-wave or continuum physics is differentiable, \emph{topology optimization} (adjoint gradients) provides a powerful PDE-constrained inverse design tool widely adopted in photonics~\cite{Christiansen2021_JOSAB,Jensen2011_LPR}. Optimization-based schemes provide principled multi-objective trade-offs, constraint handling, and sample-efficient search, but depend on accurate surrogates/acquisitions, careful problem parameterization, and (for gradient methods) differentiable solvers and single-valued adjoints.

In practice, hybrid pipelines perform best: exploration agents query model-based surrogates (\emph{RL $\leftrightarrow$ surrogate}); generative latents are optimized with BO/GA (\emph{gen. model $\rightarrow$ optimizer}); and forward–inverse couplings screen P2C proposals through trusted C2P evaluators before simulation or experiment. Which path to prefer depends on data regime, simulator cost, constraints, and whether gradients are available. Table~\ref{tab:inv_compare} summarizes the trade-space.

\begin{table}[H]
\centering
\caption{Compact comparison of inverse-design strategies.}
\label{tab:inv_compare}
\setlength{\tabcolsep}{4pt}           % tighten horizontal padding
\renewcommand{\arraystretch}{1.12}    % subtle vertical compaction
\footnotesize                         % or \scriptsize if still wide
\begin{tabularx}{\linewidth}{
  >{\raggedright\arraybackslash}p{2.6cm}
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X
  >{\raggedright\arraybackslash}X}
\toprule
\textbf{Strategy} & \textbf{Typical algorithms} & \textbf{Strengths} & \textbf{Common caveats} \\
\midrule
\emph{Exploration-based}
& RL (A2C/PPO + simulators); MCTS (discrete/continuous); PSO and other swarm heuristics
& Label-frugal; discovers diverse solutions; robust to one-to-many mappings
& Many simulator calls; reward-shaping sensitivity; constraint enforcement can be nontrivial \\
\addlinespace[2pt]
\emph{Model-based}
& Forward--inverse (tandem) nets; supervised surrogates (RF/NN); transfer learning; VAEs/GANs
& Sample-efficient; amortized inference; possible uncertainty handling via calibrated models
& Non-uniqueness requires forward validation; distribution shift; data curation and retraining loops \\
\addlinespace[2pt]
\emph{Optimization-based}
& Bayesian optimization / active learning; genetic algorithms; adjoint (topology) optimization
& Strong sample-efficiency (BO); handles constraints and multi-objective trade-offs; scalable with gradients
& Surrogate bias; local minima; need differentiable solvers/valid adjoints; parameterization sensitivity \\
\bottomrule
\end{tabularx}
\end{table}


\section{Data Acquisition}\label{sec:database}

A learning-based inverse model relies on paired examples
\(\mathcal{D}=\{(\vect{x}_i,\vect{y}_i)\}_{i=1}^{N}\), where outcomes arise from the forward process
\begin{equation}
  \vect{y}_i \;=\; \vect{f}(\vect{x}_i) \;+\; \boldsymbol{\varepsilon}_i,
  \qquad \vect{x}_i\in\calX,\ \vect{y}_i\in\calY .
  \label{eq:database_forward}
\end{equation}
We treat \(\mathcal{D}\) as an empirical sample of the joint behaviour of decisions and outcomes, without committing to a single data-generation philosophy. 

In practice, suitable pairs can come from two broad channels:
\begin{itemize}
  \item Curated and measured datasets: historical logs, experimental archives, or precomputed simulation sets, including design-of-experiments sweeps aimed at broad coverage of \(\calX\) and the induced outcome region in \(\calY\).
  \item Optimisation traces: decision--outcome pairs produced as a by-product of exploratory search, such as multiobjective optimisation runs, surrogate-assisted procedures, or Bayesian optimisation loops, which naturally collect diverse trade-offs across objectives and constraints. 
\end{itemize}

Because inverse decision mapping is often one-to-many, diversity in \(\mathcal{D}\) is valuable, but reliability is local in outcome space: if targets \(\vect{y}^\star\) lie outside the data-supported region, the learned inverse may propose plausible decisions that fail forward verification.


\section{Modeling Background}\label{sec:modelling_background}

Learning-based mapping approaches treat inverse decision mapping as an inference problem driven by data. Rather than assuming that the inverse relation can be written as a stable function, they learn statistical relationships between decisions and outcomes and use these relationships to answer inverse queries. This viewpoint is consistent with the inverse-problems literature: the reverse direction is often ill-posed, meaning that solutions may be non-unique, sensitive to perturbations, or absent for some targets. In decision mapping this is not exceptional; many distinct decisions can induce outcomes that are indistinguishable at the resolution implied by the discrepancy measure and the noise level. \cite{Ongie2020,Stuart2010}

We describe the setting through a forward relation between a decision $\vect{x}\in\calX$ and an outcome $\vect{y}\in\calY$,
\begin{equation}
  \vect{y} \;=\; \vect{f}(\vect{x}) \;+\; \boldsymbol{\varepsilon},
  \label{eq:forward}
\end{equation}
and an inverse query that specifies a target outcome $\vect{y}^\star$ and asks for decisions whose forward response matches it approximately,
\begin{equation}
  \text{find }\vect{x}\in\calX \text{ such that } \mathcal{L}\!\big(\vect{f}(\vect{x}),\vect{y}^\star\big)\ \text{is small}.
  \label{eq:inverse_query}
\end{equation}
This formulation makes explicit that inverse decision mapping is defined relative to a task metric $\mathcal{L}$ and to the uncertainty model $\boldsymbol{\varepsilon}$, not solely by algebraic invertibility of $\vect{f}$.

One way learning enters is by modelling an inverse map as a predictor $g:\calY\!\to\!\calX$ selected by regularised risk minimisation on paired data $\mathcal{D}=\{(\vect{y}_i,\vect{x}_i)\}_{i=1}^N$,
\begin{equation}
  \widehat{g}
  \;\in\;
  \arg\min_{g\in\mathcal{G}}
  \frac{1}{N}\sum_{i=1}^{N}\ell\!\left(g(\vect{y}_i),\,\vect{x}_i\right)
  \;+\;
  \lambda\,\Omega(g),
  \label{eq:erm_inverse_bg}
\end{equation}
where $\ell$ measures decision-space discrepancy and $\Omega$ encodes inductive bias that improves stability and generalisation. A limitation of pure decision-space supervision is that, under non-uniqueness, multiple distinct decisions may be equally compatible with the same target. In such settings, a point predictor can collapse ambiguity into a single selection rule and can be penalised for proposing alternatives that are valid but differ from the recorded design. \cite{Ongie2020}

A second, more expressive route models the inverse relation as a conditional distribution over decisions given outcomes. In Bayesian inverse problems this appears as a posterior distribution over $\vect{x}$ conditioned on the target, while in data-driven settings it is natural to fit a conditional density model from paired samples,
\begin{equation}
  q_\theta(\vect{x}\mid\vect{y}) \approx p(\vect{x}\mid\vect{y}),
  \qquad
  \theta^\star \in \arg\min_\theta \sum_{i=1}^N -\log q_\theta(\vect{x}_i\mid\vect{y}_i),
  \label{eq:cond_mle_bg}
\end{equation}
so that uncertainty and multi-modality are represented directly through sampling and conditional variability. This conditional viewpoint is also central in simulation-based inference, where the goal is to learn conditionals from samples generated by a forward mechanism rather than to derive analytic inverses. \cite{Cranmer2020,Papamakarios2021}

Learning-based inversion is typically coupled to a forward-grounded notion of validity. Given a target $\vect{y}^\star$, a conditional model can generate candidate decisions,
\begin{equation}
  \widehat{\vect{x}}^{(k)} \sim q_\theta(\vect{x}\mid\vect{y}^\star),\qquad k=1,\dots,K,
  \label{eq:candidate_sampling}
\end{equation}
which are then assessed by the task discrepancy through the forward relation, using either $\vect{f}$ itself or a learned approximation when direct evaluation is costly,
\begin{equation}
  \text{score}\big(\widehat{\vect{x}}^{(k)}\big)
  \;=\;
  \mathcal{L}\!\big(\vect{f}(\widehat{\vect{x}}^{(k)}),\,\vect{y}^\star\big),
  \qquad
  \phi^\star \in \arg\min_\phi \sum_{i=1}^N \mathcal{L}\!\big(\widehat{\vect{f}}_\phi(\vect{x}_i),\,\vect{y}_i\big).
  \label{eq:verify_surrogate_bg}
\end{equation}
This coupling clarifies a general principle: learning proposes, while forward consistency defines acceptance. It also highlights a persistent limitation. Any learned inverse, whether point-valued or distributional, is supported by the regions of $(\vect{x},\vect{y})$ space represented in the available data; queries outside that region can induce confident-looking proposals that fail when checked forward. \cite{Arridge2019,Ongie2020}

Inverse exploration therefore relies on models as its inner loop: given a candidate decision $\vect{x}$, one must anticipate the corresponding outcome $\vect{y}$ and, when possible, quantify uncertainty in that anticipation. Deterministic predictors provide fast point estimates, while probabilistic models represent conditional variability and enable uncertainty-aware selection. Both perspectives sit naturally within statistical learning and decision-theoretic principles and provide the modelling basis for inverse decision mapping. \cite{RasmussenWilliams2006,Bishop2006PRML}


\subsection{Probabilistic View}

The probabilistic view replaces single-point predictions with conditional distributions, making uncertainty an explicit modelling object and providing a natural way to represent one-to-many relationships. In inverse decision mapping this matters because ambiguity is often structural: multiple distinct decisions can be compatible with the same target outcome within the resolution of the task discrepancy, and small perturbations or noise can change which decisions appear optimal. A probabilistic model can represent this ambiguity directly and, crucially, turns it into a mechanism for generating multiple plausible candidates rather than forcing an arbitrary single choice. 

Given paired observations $\mathcal{D}=\{(\vect{x}_i,\vect{y}_i)\}_{i=1}^N$, a generic likelihood-based training principle learns a conditional distribution by maximising regularised log-likelihood,
\begin{equation}
  \widehat{\theta}
  \;\in\;
  \arg\max_{\theta}
  \Bigg[
    \sum_{i=1}^{N}\log p_{\theta}\!\big(\vect{x}_i \mid \vect{y}_i\big)
    \;-\;
    \gamma\,\mathcal{R}(\theta)
  \Bigg],
  \label{eq:prob_generic}
\end{equation}
where $\mathcal{R}(\theta)$ controls complexity and encodes modelling assumptions, and $\gamma\ge 0$ balances fit and regularisation. The purpose of this formulation in the present context is not to prescribe a specific estimator, but to emphasise the modelling consequence: the output of inference is a distribution over decisions conditioned on a target, rather than a single deterministic proposal. \cite{Murphy2022PML1}

This distributional output supports candidate-set generation by sampling. For a query $\vect{y}^{\star}$, one draws a collection of candidates,
\begin{equation}
  \vect{x}^{(r)} \sim p_{\widehat{\theta}}(\vect{x}\mid\vect{y}^{\star}),\qquad r=1,\dots,R,
  \label{eq:prob_sampling}
\end{equation}
and then ranks or filters them using a task discrepancy that reflects the design intent. Sampling separates the question of plausibility from the question of selection: the learned conditional determines which candidates are supported by the data, while the task metric determines which of those candidates best satisfy the target. This separation is particularly valuable when the inverse relation is multi-modal, because it allows the procedure to surface multiple, qualitatively different alternatives instead of collapsing them into a single averaged solution.

Uncertainty is therefore not an auxiliary statistic but a functional part of the inverse pipeline. The spread of $p_{\widehat{\theta}}(\vect{x}\mid\vect{y}^{\star})$ reflects how concentrated the evidence is around particular decisions for the specified target, and it provides a natural basis for deciding how many candidates to generate and how conservative selection should be. Likelihood-based training and evaluation also align with this role, because they reward distributions that are calibrated as well as informative.


\subsection{Why we choose the following Modeling approaches}
Write about each modelling and why it is used and what problem it solves.

\subsection{Mixture Density Networks}\label{sec:mdn}

Mixture density networks model a conditional distribution by representing it as a finite mixture whose parameters depend on the conditioning variable. This is particularly useful when the inverse relation is multi-valued: multiple distinct decisions can legitimately correspond to the same target outcome, so learning a single conditional mean is not an adequate description of the inverse map. For a $K$-component Gaussian mixture, the conditional density is
\begin{equation}
  q_\theta(\vect{x}\mid\vect{y})
  \;=\;
  \sum_{k=1}^{K}\pi_k(\vect{y};\theta)\,
  \mathcal{N}\!\big(\vect{x}\,;\,\boldsymbol{\mu}_k(\vect{y};\theta),\boldsymbol{\Sigma}_k(\vect{y};\theta)\big),
  \label{eq:mdn_conditional}
\end{equation}
where $\pi_k(\vect{y};\theta)\ge 0$ and $\sum_{k=1}^{K}\pi_k(\vect{y};\theta)=1$.
A neural network outputs the mixture weights, means, and covariance parameters as functions of $\vect{y}$, using standard constraints such as a softmax for $\pi_k$ and positive-definite parameterisations for $\boldsymbol{\Sigma}_k$ (e.g., diagonal variances via exponentiation, or full covariances via a Cholesky factor).

The parameters are learned by maximum conditional likelihood.
Equivalently, we solve the empirical risk minimisation problem
\begin{equation}
  \theta^\star
  \;=\;
  \arg\min_{\theta}\;\mathcal{L}_{\mathrm{MDN}}(\theta)
  \;=\;
  \arg\min_{\theta}\left(
  -\sum_{i=1}^{N}\log q_\theta(\vect{x}_i\mid\vect{y}_i)
  \right),
  \label{eq:mdn_opt_problem}
\end{equation}
where the negative log-likelihood (NLL) expands to
\begin{equation}
  \mathcal{L}_{\mathrm{MDN}}(\theta)
  \;=\;
  -\sum_{i=1}^{N}
  \log
  \Bigg(
    \sum_{k=1}^{K}\pi_k(\vect{y}_i;\theta)\,
    \mathcal{N}\!\big(\vect{x}_i\,;\,\boldsymbol{\mu}_k(\vect{y}_i;\theta),\boldsymbol{\Sigma}_k(\vect{y}_i;\theta)\big)
  \Bigg).
  \label{eq:mdn_nll}
\end{equation}
In practice, optimisation proceeds with stochastic gradient methods on mini-batches $B$.
Let $\ell_i(\theta) = -\log \sum_{k=1}^{K}\pi_k(\vect{y}_i;\theta)\,\mathcal{N}(\vect{x}_i;\boldsymbol{\mu}_k(\vect{y}_i;\theta),\boldsymbol{\Sigma}_k(\vect{y}_i;\theta))$ denote the per-sample NLL.
Then the mini-batch objective is
\begin{equation}
  \mathcal{L}_{B}(\theta)
  \;=\;
  \frac{1}{|B|}\sum_{i\in B}\ell_i(\theta),
  \label{eq:mdn_minibatch_loss}
\end{equation}
and parameters are updated by
\begin{equation}
  \theta_{t+1}
  \;=\;
  \theta_t
  \;-\;
  \eta_t\,\nabla_\theta \mathcal{L}_{B}(\theta_t),
  \label{eq:mdn_sgd_update}
\end{equation}
with gradients computed by backpropagation through the network outputs.

A useful way to see what the NLL is encouraging is through the component responsibilities (soft assignments)
\begin{equation}
  \gamma_{i,k}
  \;=\;
  \frac{
    \pi_k(\vect{y}_i;\theta)\,
    \mathcal{N}\!\big(\vect{x}_i;\boldsymbol{\mu}_k(\vect{y}_i;\theta),\boldsymbol{\Sigma}_k(\vect{y}_i;\theta)\big)
  }{
    \sum_{j=1}^{K}\pi_j(\vect{y}_i;\theta)\,
    \mathcal{N}\!\big(\vect{x}_i;\boldsymbol{\mu}_j(\vect{y}_i;\theta),\boldsymbol{\Sigma}_j(\vect{y}_i;\theta)\big)
  }.
  \label{eq:mdn_responsibilities}
\end{equation}
Each $\gamma_{i,k}$ measures how much component $k$ explains the observation $(\vect{x}_i,\vect{y}_i)$ under the current parameters.
During training, these responsibilities modulate the gradient signal: components that explain the data point well receive stronger updates to their weights, means, and covariances, while implausible components are pushed away.
This mechanism is precisely what allows an MDN to fit multi-modal conditional distributions instead of collapsing to a single averaged inverse.

Candidate generation is obtained directly from the mixture representation.
For a query $\vect{y}^\star$, one samples a component index
$k \sim \mathrm{Categorical}(\pi_1(\vect{y}^\star),\dots,\pi_K(\vect{y}^\star))$
and then samples
$\vect{x}\sim\mathcal{N}(\boldsymbol{\mu}_k(\vect{y}^\star),\boldsymbol{\Sigma}_k(\vect{y}^\star))$.
Repeating this procedure produces a candidate set whose diversity is controlled by the learned mixture weights and component spreads.
MDNs therefore provide an explicit, likelihood-trained mechanism for modelling multimodality in conditional candidate generation \cite{bishop1994mixture}.

In the context of materials inverse design, this capability addresses the core difficulty that the property-to-structure map is rarely one-to-one: different compositions, microstructures, or process conditions can yield similar target properties, and the forward relation is typically nonlinear and scale dependent.
An MDN supports this setting by returning multiple distinct candidates for the same target property vector, while the mixture weights provide a data-driven notion of which solution families are more probable under the learned model.
This makes MDNs a practical choice when the goal is not only to hit a target, but also to expose alternative feasible design routes for subsequent screening or constraint checking.

\begin{figure}[t]
  \centering
  \input{figures/mdn_architecture}
  \caption[MDN architecture]{Mixture density network conditioned on the target $\vect{y}$. A shared backbone outputs mixture weights $\pi_k(\vect{y})$ and component parameters $(\boldsymbol{\mu}_k(\vect{y}),\boldsymbol{\Sigma}_k(\vect{y}))$, enabling multimodal sampling of decision candidates $\vect{x}$ for a fixed target.}
  \label{fig:mdn_architecture}
\end{figure}



\subsection{Conditional Variational Autoencoders}\label{sec:cvae}

Conditional variational autoencoders represent conditional variability through a latent variable $\vect{z}\in\mathbb{R}^d$ and define a conditional latent-variable model in which the conditional density is obtained by marginalising $\vect{z}$:
\begin{equation}
  p_\theta(\vect{x}\mid\vect{y})
  \;=\;
  \int p_\theta(\vect{x}\mid\vect{y},\vect{z})\,p_\theta(\vect{z}\mid\vect{y})\,\mathrm{d}\vect{z}.
  \label{eq:cvae_marginal}
\end{equation}
In practice, the decoder $p_\theta(\vect{x}\mid\vect{y},\vect{z})$ and the (possibly conditional) prior $p_\theta(\vect{z}\mid\vect{y})$ are parameterised by neural networks. A common choice for continuous decision variables is a Gaussian decoder,
\[
  p_\theta(\vect{x}\mid\vect{y},\vect{z})
  \;=\;
  \mathcal{N}\!\big(\vect{x};\,g_\theta(\vect{y},\vect{z}),\,\sigma_x^2 \mathbf{I}\big),
\]
so that the reconstruction term corresponds (up to constants) to a weighted squared error between $\vect{x}$ and the decoder output $g_\theta(\vect{y},\vect{z})$. The conditional prior is often taken as a standard normal (independent of $\vect{y}$) or as a learned Gaussian whose parameters depend on $\vect{y}$; the latter can better match heterogeneous conditional variability in inverse mappings \cite{Sohn2015CVAE}.

Because the marginal likelihood is generally intractable, training proceeds by maximising an evidence lower bound using an approximate posterior (encoder) $q_\phi(\vect{z}\mid\vect{x},\vect{y})$:
\begin{equation}
  \log p_\theta(\vect{x}\mid\vect{y})
  \;\ge\;
  \mathbb{E}_{q_\phi(\vect{z}\mid\vect{x},\vect{y})}\!\big[\log p_\theta(\vect{x}\mid\vect{y},\vect{z})\big]
  \;-\;
  \mathrm{KL}\!\big(q_\phi(\vect{z}\mid\vect{x},\vect{y})\ \|\ p_\theta(\vect{z}\mid\vect{y})\big),
  \label{eq:cvae_elbo}
\end{equation}
so the optimisation target is the negative of the right-hand side summed over the dataset. The reconstruction term encourages $\vect{x}$ to be well explained given $(\vect{y},\vect{z})$, while the KL term regularises the encoder distribution toward the conditional prior so that sampling remains meaningful. Candidate generation follows directly from the generative structure: for a query $\vect{y}^\star$, sample $\vect{z}\sim p_\theta(\vect{z}\mid\vect{y}^\star)$ and then sample or decode $\vect{x}\sim p_\theta(\vect{x}\mid\vect{y}^\star,\vect{z})$, repeating to obtain multiple candidates. Conditioning fixes the target context, while variation in $\vect{z}$ induces diversity in $\vect{x}$ under a fixed $\vect{y}^\star$. \cite{Sohn2015CVAE}

To make the optimisation explicit, define the per-sample ELBO
\[
  \mathcal{J}_i(\theta,\phi)
  \;=\;
  \mathbb{E}_{q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)}\!\big[\log p_\theta(\vect{x}_i\mid\vect{y}_i,\vect{z})\big]
  \;-\;
  \mathrm{KL}\!\big(q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)\ \|\ p_\theta(\vect{z}\mid\vect{y}_i)\big),
\]
and the training problem
\begin{equation}
  (\theta^\star,\phi^\star)
  \;=\;
  \arg\max_{\theta,\phi}\sum_{i=1}^{N}\mathcal{J}_i(\theta,\phi)
  \;\equiv\;
  \arg\min_{\theta,\phi}\;\mathcal{L}_{\mathrm{CVAE}}(\theta,\phi),
  \label{eq:cvae_opt_problem}
\end{equation}
where the negative-ELBO loss is
\begin{equation}
  \mathcal{L}_{\mathrm{CVAE}}(\theta,\phi)
  \;=\;
  \sum_{i=1}^{N}
  \left(
    -\,\mathbb{E}_{q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)}\!\big[\log p_\theta(\vect{x}_i\mid\vect{y}_i,\vect{z})\big]
    \;+\;
    \mathrm{KL}\!\big(q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)\ \|\ p_\theta(\vect{z}\mid\vect{y}_i)\big)
  \right).
  \label{eq:cvae_loss}
\end{equation}
A standard parameterisation uses a Gaussian encoder
$q_\phi(\vect{z}\mid\vect{x},\vect{y})=\mathcal{N}(\boldsymbol{\mu}_\phi(\vect{x},\vect{y}),\mathrm{diag}(\boldsymbol{\sigma}^2_\phi(\vect{x},\vect{y})))$,
and training employs the reparameterisation trick,
\[
  \vect{z}
  \;=\;
  \boldsymbol{\mu}_\phi(\vect{x},\vect{y})
  \;+\;
  \boldsymbol{\sigma}_\phi(\vect{x},\vect{y})\odot \boldsymbol{\epsilon},
  \qquad
  \boldsymbol{\epsilon}\sim\mathcal{N}(\mathbf{0},\mathbf{I}),
\]
which turns the stochastic expectation in Eq.~\eqref{eq:cvae_loss} into a differentiable Monte Carlo estimator. Optimisation then proceeds with mini-batch stochastic gradients: for a batch $B$,
\[
  \mathcal{L}_{B}(\theta,\phi)
  \;=\;
  \frac{1}{|B|}\sum_{i\in B}
  \left(
    -\,\mathbb{E}_{q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)}\!\big[\log p_\theta(\vect{x}_i\mid\vect{y}_i,\vect{z})\big]
    \;+\;
    \mathrm{KL}\!\big(q_\phi(\vect{z}\mid\vect{x}_i,\vect{y}_i)\ \|\ p_\theta(\vect{z}\mid\vect{y}_i)\big)
  \right),
\]
and the parameter update takes the form
\[
  (\theta_{t+1},\phi_{t+1})
  \;=\;
  (\theta_t,\phi_t)
  \;-\;
  \eta_t\,\nabla_{\theta,\phi}\mathcal{L}_{B}(\theta_t,\phi_t),
\]
with gradients computed by backpropagation.

In inverse design problems, the property-to-decision relation is typically nonlinear and non-unique: distinct structures or process parameters can satisfy the same target property vector. CVAEs are attractive in this setting because they learn a structured latent space that supports one-to-many conditional generation: holding $\vect{y}^\star$ fixed while sampling $\vect{z}$ yields diverse candidates that remain consistent with the target context. This allows inverse exploration to surface alternative feasible design routes for downstream screening, constraint checking, or synthesis planning, rather than collapsing to a single averaged solution.

\begin{figure}[t]
  \centering
  \input{figures/cvae_architecture}
  \caption[CVAE architecture]{Conditional VAE for candidate generation. An encoder learns a latent representation from $(\vect{x},\vect{y})$ during training, and a decoder generates $\vect{x}$ from $(\vect{y},\vect{z})$; diversity comes from sampling $\vect{z}$ while holding $\vect{y}^{\star}$ fixed.}
  \label{fig:cvae_architecture}
\end{figure}



\subsection{Invertible Neural Networks (INN)}\label{sec:inn}

Invertible neural networks enforce an exact bijection by augmenting the target with latent variables that capture the information not determined by the conditioning signal. This is particularly useful in inverse design settings, where the forward map can be well-defined but information-losing: many distinct designs can yield essentially the same target response. Rather than forcing a single ``best guess'' in such one-to-many regimes, INNs introduce a latent variable $\vect{z}$ to represent the missing degrees of freedom and to make sampling of alternative solutions explicit.

A common construction defines an invertible map between $\vect{x}$ and the pair $(\vect{y},\vect{z})$,
\begin{equation}
  (\widehat{\vect{y}},\vect{z}) \;=\; f_\theta(\vect{x}),
  \qquad
  \vect{x} \;=\; f_\theta^{-1}(\vect{y},\vect{z}),
  \label{eq:inn_bijection}
\end{equation}
where $\vect{z}$ is assigned a simple reference distribution, typically $\mathcal{N}(\vect{0},\mathbf{I})$. The practical goal is then to learn parameters $\theta$ such that: (i) the forward pass predicts outcomes consistently, $\widehat{\vect{y}}\approx \vect{y}$; and (ii) the additional latent output behaves like a clean ``reservoir'' of uncertainty, i.e., it matches the chosen base distribution and does not carry spurious structure that should be explained by $\vect{y}$.

Training couples a supervised term that forces the forward pass to match the observed $\vect{y}$ with a distribution-matching term that shapes the latent variables. One representative objective is
\begin{equation}
  \min_\theta\;
  \mathcal{L}_{\mathrm{INN}}(\theta)
  \;=\;
  \mathbb{E}\!\left[\,
    \|\vect{y}-f_{\theta,y}(\vect{x})\|_2^2
  \right]
  \;+\;
  \lambda_z\,
  \mathrm{MMD}\!\Big(q_\theta(\vect{y},\vect{z}),\; p(\vect{y})\,p(\vect{z})\Big),
  \label{eq:inn_loss}
\end{equation}
where $q_\theta(\vect{y},\vect{z})$ denotes the joint distribution induced by pushing data through the forward direction of the network and $\mathrm{MMD}$ is a kernel-based discrepancy between distributions. In words, the first term ensures forward consistency (so the inverse samples do not drift away from the intended target), while the second term encourages the induced joint to behave like an independent product $p(\vect{y})p(\vect{z})$: the network should ``explain'' what it can through $\vect{y}$ and delegate the remaining variability to $\vect{z}$, shaped to match a simple prior.

A standard definition is
\begin{equation}
  \mathrm{MMD}^2(P,Q)
  \;=\;
  \mathbb{E}_{u,u'\sim P}[k(u,u')]
  \;+\;
  \mathbb{E}_{v,v'\sim Q}[k(v,v')]
  \;-\;
  2\,\mathbb{E}_{u\sim P,\ v\sim Q}[k(u,v)],
  \label{eq:mmd_def}
\end{equation}
for a characteristic kernel $k$. In implementation, we minimise an empirical approximation of \eqref{eq:inn_loss} over a dataset $\{(\vect{x}_i,\vect{y}_i)\}_{i=1}^{N}$ using minibatches $\mathcal{B}$:
\begin{equation}
  \widehat{\theta}
  \;=\;
  \arg\min_{\theta}\;
  \frac{1}{|\mathcal{B}|}\sum_{i\in\mathcal{B}}
  \|\vect{y}_i-f_{\theta,y}(\vect{x}_i)\|_2^2
  \;+\;
  \lambda_z\,
  \widehat{\mathrm{MMD}}^2\!\Big(\{(\widehat{\vect{y}}_i,\vect{z}_i)\}_{i\in\mathcal{B}},\ \{(\vect{y}_i,\tilde{\vect{z}}_i)\}_{i\in\mathcal{B}}\Big),
  \label{eq:inn_empirical_objective}
\end{equation}
where $(\widehat{\vect{y}}_i,\vect{z}_i)=f_\theta(\vect{x}_i)$ are samples from the model-induced joint and $\tilde{\vect{z}}_i\sim\mathcal{N}(\vect{0},\mathbf{I})$. To approximate samples from the product distribution $p(\vect{y})p(\vect{z})$, one can pair observed $\vect{y}_i$ with independently drawn $\tilde{\vect{z}}_i$ (or equivalently, shuffle $\vect{z}$ across the batch to break dependence). A commonly used unbiased minibatch estimator is
\begin{align}
  \widehat{\mathrm{MMD}}^2(P,Q)
  \;=\;&
  \frac{1}{m(m-1)}\sum_{i\neq j} k(u_i,u_j)
  \;+\;
  \frac{1}{n(n-1)}\sum_{i\neq j} k(v_i,v_j)
  \;-\;
  \frac{2}{mn}\sum_{i=1}^{m}\sum_{j=1}^{n} k(u_i,v_j),
  \label{eq:mmd_unbiased_estimator}
\end{align}
with $\{u_i\}_{i=1}^{m}\sim P$ and $\{v_j\}_{j=1}^{n}\sim Q$. Because all terms are differentiable in $\theta$ through $u_i=f_\theta(\vect{x}_i)$, we optimise \eqref{eq:inn_empirical_objective} with standard stochastic gradient methods by backpropagating through the forward pass,
\begin{equation}
  \theta_{t+1}
  \;=\;
  \theta_t \;-\; \eta_t\,\nabla_{\theta}\,\mathcal{L}_{\mathrm{INN}}(\theta_t),
  \label{eq:inn_sgd_update}
\end{equation}
where $\eta_t$ is the step size (in practice typically via an adaptive optimiser).

It is worth noting that many INN architectures are built from coupling blocks that make both $f_\theta$ and $f_\theta^{-1}$ cheap to evaluate. In related flow-based formulations, one may also replace distribution-matching with an explicit likelihood objective derived from the change-of-variables formula; the appeal is the same: a tractable training signal, exact sampling, and a latent space whose structure controls diversity.

Candidate generation is explicit and does not require approximate inference: for a query $\vect{y}^\star$, sample $\vect{z}\sim \mathcal{N}(\vect{0},\mathbf{I})$ and compute $\vect{x}=f_\theta^{-1}(\vect{y}^\star,\vect{z})$, repeating to obtain a diverse candidate set. The invertibility constraint makes the mapping from latent variation to candidate diversity transparent and supports stable sampling for fixed conditioning. In inverse design contexts such as materials or photonic structures, where distinct microstructures can match the same target property vector, this ``latent-augmented inverse'' provides a principled way to return multiple high-fidelity alternatives rather than collapsing to an averaged, non-physical design. \cite{Ardizzone2019INN}



\subsection{Invertible Neural Networks (INN)}\label{sec:inn}

Invertible neural networks enforce an exact bijection by augmenting the target with latent variables that capture the information not determined by the conditioning signal. A common construction defines an invertible map between $\vect{x}$ and the pair $(\vect{y},\vect{z})$,
\begin{equation}
  (\widehat{\vect{y}},\vect{z}) \;=\; f_\theta(\vect{x}),
  \qquad
  \vect{x} \;=\; f_\theta^{-1}(\vect{y},\vect{z}),
  \label{eq:inn_bijection}
\end{equation}
where $\vect{z}$ is assigned a simple reference distribution, typically $\mathcal{N}(\vect{0},\mathbf{I})$. Training couples a supervised term that forces the forward pass to match the observed $\vect{y}$ with a distribution-matching term that shapes the latent variables. One representative objective is
\begin{equation}
  \min_\theta\;
  \mathcal{L}_{\mathrm{INN}}(\theta)
  \;=\;
  \mathbb{E}\!\left[\,
    \|\vect{y}-f_{\theta,y}(\vect{x})\|_2^2
  \right]
  \;+\;
  \lambda_z\,
  \mathrm{MMD}\!\Big(q_\theta(\vect{y},\vect{z}),\; p(\vect{y})\,p(\vect{z})\Big),
  \label{eq:inn_loss}
\end{equation}
where $q_\theta(\vect{y},\vect{z})$ denotes the joint distribution induced by pushing data through the forward direction of the network and $\mathrm{MMD}$ is a kernel-based discrepancy between distributions. A standard definition is
\begin{equation}
  \mathrm{MMD}^2(P,Q)
  \;=\;
  \mathbb{E}_{u,u'\sim P}[k(u,u')]
  \;+\;
  \mathbb{E}_{v,v'\sim Q}[k(v,v')]
  \;-\;
  2\,\mathbb{E}_{u\sim P,\ v\sim Q}[k(u,v)],
  \label{eq:mmd_def}
\end{equation}
for a characteristic kernel $k$. Candidate generation is explicit and does not require approximate inference: for a query $\vect{y}^\star$, sample $\vect{z}\sim \mathcal{N}(\vect{0},\mathbf{I})$ and compute $\vect{x}=f_\theta^{-1}(\vect{y}^\star,\vect{z})$, repeating to obtain a diverse candidate set. The invertibility constraint makes the mapping from latent variation to candidate diversity transparent and supports stable sampling for fixed conditioning. \cite{Ardizzone2019INN}


\begin{figure}[t]
  \centering
  \input{figures/inn_architecture}
  \caption[INN architecture]{Invertible neural network with latent augmentation. The model learns a bijection between $\vect{x}$ and $(\vect{y},\vect{z})$, so candidates are generated by fixing $\vect{y}^{\star}$, sampling $\vect{z}$, and applying the inverse pass to obtain $\vect{x}$.}
  \label{fig:inn_architecture}
\end{figure}

% In sum, $\mathcal{E}_{\mathcal{Y}}$ captures \emph{how close} we get to the target, while $\mathrm{Succ}_\epsilon$ captures \emph{whether} we satisfy a practically meaningful tolerance. Together they provide a concise, implementation-agnostic summary of decision quality that is easy to interpret and straightforward to reproduce.
