%-------------------------------------------------------------------------------
% Introduction
%-------------------------------------------------------------------------------

\chapter{Introduction}

Real‑world decision making involves navigating a web of trade‑offs.  Power
engineers balance reliability, efficiency and cost; policy makers weigh
economic growth against environmental impact; biomedical imaging experts tune
denoising strength and detail preservation.  Each scenario exemplifies
multi‑objective optimisation (MOO), where multiple conflicting objectives are
considered simultaneously rather than aggregated into a single scalar
 function~\cite{Tan2023}.  Unlike single‑objective optimisation, MOO
does not yield a unique optimum but a set of non‑dominated solutions forming
the Pareto set in decision space and its image, the Pareto front, in
objective space.  From this set, a decision maker must choose a design
according to personal preferences and practical constraints.

The dominant paradigm in MOO is forward mapping: given a decision vector
\(\vect{x}\in\calX\) of design variables, one evaluates the objective
functions \(\vect{f}(\vect{x})\) and uses evolutionary or surrogate‑assisted
 algorithms to approximate the Pareto front~\cite{Liu2024}.  This
direction reflects how simulation models are typically defined; software
implements a complex physics or data‑driven forward map from inputs to
outputs.  When a designer wishes to see how changing a variable affects the
trade‑off, she perturbs \(\vect{x}\) and observes the change in \(\vect{y}\).
However, a complementary question often arises in practice: if one has a
desired objective vector \(\vect{y}^{\star}\)—for example a particular
combination of resolution and denoising strength in a medical image—what
decision vector \(\vect{x}^{\star}\) will achieve it?  The inverse mapping
from objectives to decisions is ill‑posed: multiple decision vectors may
produce the same objective values, and some target objectives may not be
attainable due to feasibility or Pareto dominance.  Current practice relies
on scalarisation or repeated forward evaluations, which are computationally
expensive and provide little insight into the structure of the inverse
relationship.

This thesis tackles the inverse decision mapping problem for multi‑objective
systems.  The key idea is to learn a surrogate inverse model from data
generated by an initial optimisation run.  Once a set of pairs
\(\{(\vect{x}_i,\vect{y}_i)\}\) sampling the Pareto front has been collected,
a machine learning model is trained to approximate the mapping
\(\hat{g}\colon \calY\to\calX\).  During an online phase a user specifies
\(\vect{y}^{\star}\); the model predicts candidate \(\vect{x}\) values that
should realise \(\vect{y}^{\star}\), and these candidates are refined via
forward evaluation.  By shifting computational effort to an offline training
phase, the proposed approach enables interactive exploration of the
multi‑objective trade‑off landscape.

Recent advances in probabilistic modelling and deep generative networks have
highlighted the potential to move beyond point estimates.  Mixture density
networks predict full conditional probability densities instead of single
averages, enabling them to capture multi‑valued inverse mappings【616414878159156†L169-L232】.
Generative architectures such as conditional variational autoencoders can
sample diverse candidates conditioned on desired objectives and thus provide
rich design spaces【917105453207985†L10-L38】.  Although this thesis primarily
utilises deterministic surrogates due to their simplicity and interpretability,
we discuss these probabilistic and generative techniques as promising
directions for future research.

\section{Contributions}

The contributions of this thesis are as follows:

\begin{itemize}
  \item \textbf{Problem formulation.} We formally define the inverse decision
  mapping problem in the context of MOO and highlight its ill‑posed
  nature.  Building on recent work in Pareto estimation and inverse
  machine learning~\cite{Tan2023}, we specify conditions under
  which a target objective vector is admissible and propose criteria for
  assessing the quality of inverse solutions.

  \item \textbf{Comprehensive background.} A detailed survey of
  multi‑objective optimisation methods, performance indicators and
  surrogate‑assisted algorithms is presented.  We review evolutionary
  algorithms, decomposition techniques and quality indicators such as
  generational distance and hypervolume~\cite{Blank2020}.  We
  further survey inverse modelling approaches, including radial basis
  function networks, Gaussian processes and transfer learning methods
  that map objective vectors back to decision space~\cite{Liu2024}.

  \item \textbf{Modular framework.} We design a modular methodology with
  offline and online phases.  In the offline phase an existing MOO
  algorithm approximates the Pareto front, and a surrogate inverse model is
  trained.  In the online phase the user queries the model with a target
  objective vector, a plausibility check determines proximity to the Pareto
  region and candidate decisions are produced and validated.  The framework
  accommodates different surrogate models and incorporates ranking metrics
  to guide the user.

  \item \textbf{Implementation and prototype.} A reproducible software
  prototype is implemented, including routines for data generation, normal-
  isation, model training, hyperparameter optimisation, interactive
  visualisation and ranking.  The code is modular, making it easy to plug
  in alternative surrogate models or optimisation backends.

  \item \textbf{Empirical evaluation.} Extensive experiments on synthetic
  benchmark functions and a real‑world case study demonstrate that the
  learned inverse models yield decision vectors close to the true Pareto
  set.  We compare Gaussian processes, radial basis functions and
  neural networks under varying training set sizes and analyse trade‑offs
  between accuracy and computation time.  Results indicate that the
  proposed framework significantly reduces the number of forward evaluations
  required to identify satisfactory solutions.

\end{itemize}

\section{Structure of the Thesis}

The remainder of this thesis is organised as follows.  Chapter~\ref{chap:motivation}
provides background on multi‑objective optimisation, introduces definitions of
dominance and Pareto optimality, reviews key algorithms and metrics, and
motivates the need for inverse mapping.  Chapter~\ref{chap:related}
surveys related work on inverse modelling, surrogate‑assisted optimisation,
transfer learning and interactive decision support.  Chapter~\ref{chap:problem}
formalises the inverse decision mapping problem, introduces feasibility and
quality criteria and poses research questions.  Chapter~\ref{chap:method}
describes the proposed methodology in detail, including data generation,
surrogate training and online exploration.  Chapter~\ref{chap:implementation}
presents implementation details and algorithmic components.  Chapter~\ref{chap:experiments}
contains experimental results on synthetic and real problems.  Chapter
\ref{chap:discussion} discusses the insights gained from the experiments and
outlines limitations.  Finally, Chapter~\ref{chap:conclusion} concludes the
thesis and proposes future directions.